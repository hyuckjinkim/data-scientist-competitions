{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f399afe2-31e0-4d6a-bb9f-891a02d1af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khj/anaconda3/envs/torch_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Volumes/KHJ/Github/hyuckjinkim/lib-python/torch')\n",
    "from torch_seed import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da5c216-2cbf-42d0-82f4-9b253f5ba226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> torch version  : 1.13.1\n",
      "> cuda available : False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "print('> torch version  :',torch.__version__)\n",
    "print('> cuda available :',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab1a6f9-8198-47b1-a514-079b81ee392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jimmy-ai.tistory.com/342\n",
    "# https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path=None, trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            if self.path is not None:\n",
    "                torch.save(model.state_dict(), self.path)\n",
    "                save_message = 'Saving model ...'\n",
    "            else:\n",
    "                save_message = ''\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). {save_message}')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "# # https://github.com/pytorch/pytorch/issues/21987\n",
    "# def nanmean(v, *args, inplace=False, **kwargs):\n",
    "#     if not inplace:\n",
    "#         v = v.clone()\n",
    "#     is_nan = torch.isnan(v)\n",
    "#     v[is_nan] = 0\n",
    "#     return v.sum(*args, **kwargs) / (~is_nan).float().sum(*args, **kwargs)\n",
    "\n",
    "# def seq2list_cuda(seq,device):\n",
    "#     nan_value = -99999\n",
    "#     ret_seq = []\n",
    "#     k=0\n",
    "#     N=len(seq)\n",
    "#     for x in seq:\n",
    "#         start_seq = torch.tensor([nan_value]*k).to(device).float()\n",
    "#         end_seq   = torch.tensor([nan_value]*(N-k-1)).to(device).float()\n",
    "#         x = x.to(device)\n",
    "        \n",
    "#         if len(start_seq)==0:\n",
    "#             _seq  = torch.cat([x,end_seq],axis=0)\n",
    "#         elif len(end_seq)==0:\n",
    "#             _seq  = torch.cat([start_seq,x],axis=0)\n",
    "#         else:\n",
    "#             _seq  = torch.cat([start_seq,x,end_seq],axis=0)\n",
    "            \n",
    "#         _seq[_seq==nan_value] = float('nan')\n",
    "#         ret_seq.append(_seq)\n",
    "#         k+=1\n",
    "#     ret_seq = torch.stack(ret_seq,dim=0)\n",
    "#     #print('(1)',ret_seq)\n",
    "#     ret_seq = nanmean(ret_seq,dim=0)\n",
    "#     #print('(2)',ret_seq)\n",
    "#     return ret_seq\n",
    "        \n",
    "def train(\n",
    "    model, optimizer, train_loader, valid_loader, epochs, criterion,\n",
    "    early_stopping=None, device='cpu', scheduler=None, metric_period=1, \n",
    "    verbose=True, print_shape=False, save_model_path = './mc/best_model.pt',\n",
    "    transform_y='identity',\n",
    "):\n",
    "    assert transform_y in ['identity','log','sqrt'], \\\n",
    "        \"transform_y must be one of ['identity','log','sqrt']\"\n",
    "    is_early_stopping = False if early_stopping is None else True\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    # great is better\n",
    "    best_loss  = np.inf\n",
    "    best_epoch = 1\n",
    "    best_model = None\n",
    "    is_best    = np.nan\n",
    "    \n",
    "    start_time = time.time()\n",
    "    epoch_s = time.time()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for X, Y in iter(train_loader):\n",
    "\n",
    "            X = X.float().to(device)\n",
    "            Y = Y.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X).float()\n",
    "            \n",
    "            #Y = seq2list_cuda(Y,device)\n",
    "            #output = seq2list_cuda(output,device)\n",
    "            \n",
    "            if transform_y=='log':\n",
    "                output = torch.exp(output)\n",
    "                Y      = torch.exp(Y)\n",
    "            elif transform_y=='sqrt':\n",
    "                output = output**2\n",
    "                Y      = Y**2\n",
    "                \n",
    "            if print_shape:\n",
    "                    if epoch==1:\n",
    "                        print(output.shape,Y.shape) # torch.Size([16, 1]) torch.Size([16, 1])\n",
    "                        print(output[:2],Y[:2])\n",
    "            \n",
    "            loss = criterion(output, Y)\n",
    "            #loss = torch.sqrt(loss) # MSE -> RMSE\n",
    "            \n",
    "            loss.backward() # Getting gradients\n",
    "            optimizer.step() # Updating parameters\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        valid_loss = validation(model, valid_loader, criterion, device, transform_y)\n",
    "\n",
    "        epoch_e = time.time()\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        # update the best epoch & best loss\n",
    "        if (best_loss > valid_loss) | (epoch==1):\n",
    "            best_epoch = epoch\n",
    "            best_loss = valid_loss\n",
    "            best_model = model\n",
    "            is_best = 1\n",
    "            torch.save(best_model.state_dict(), save_model_path)\n",
    "        else:\n",
    "            is_best = 0\n",
    "            \n",
    "        # 결과물 printing\n",
    "        if (verbose) & (epoch % metric_period == 0):\n",
    "            mark = '*' if is_best else ' '\n",
    "            epoch_str = str(epoch).zfill(len(str(epochs)))\n",
    "            progress = '{}[{}/{}] tr_loss: {:.5f}, val_loss: {:.5f}, best_epoch: {}, elapsed: {:.2f}s, total: {:.2f}s, remaining: {:.2f}s'\\\n",
    "                .format(\n",
    "                    mark,\n",
    "                    epoch_str,\n",
    "                    epochs,\n",
    "                    np.mean(train_loss),\n",
    "                    valid_loss,\n",
    "                    best_epoch,\n",
    "                    epoch_e-epoch_s,\n",
    "                    epoch_e-start_time,\n",
    "                    (epoch_e-epoch_s)*(epochs-epoch)/metric_period,\n",
    "                )\n",
    "            epoch_s = time.time()\n",
    "            print(progress)\n",
    "\n",
    "        # early stopping 여부를 체크. 현재 과적합 상황 추적\n",
    "        if is_early_stopping:\n",
    "            early_stopping(valid_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def validation(model, valid_loader, criterion, device, transform_y):\n",
    "    valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for X, Y in iter(valid_loader):\n",
    "            X = X.float().to(device)\n",
    "            Y = Y.float().to(device)\n",
    "            \n",
    "            output = model(X).float()\n",
    "            \n",
    "            #Y = seq2list_cuda(Y,device)\n",
    "            #output = seq2list_cuda(output,device)\n",
    "            \n",
    "            if transform_y=='log':\n",
    "                output = torch.exp(output)\n",
    "                Y      = torch.exp(Y)\n",
    "            elif transform_y=='sqrt':\n",
    "                output = output**2\n",
    "                Y      = Y**2\n",
    "            \n",
    "            loss = criterion(output, Y)\n",
    "            valid_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(valid_loss)\n",
    "\n",
    "def predict(best_model,loader,device,transform_y):\n",
    "    best_model.to(device)\n",
    "    \n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for data,label in iter(loader):\n",
    "            data = data.float().to(device)\n",
    "\n",
    "            output = best_model(data).cpu().numpy().tolist()\n",
    "            label  = label.cpu().numpy().tolist()\n",
    "\n",
    "            if transform_y=='log':\n",
    "                output = np.exp(output).tolist()\n",
    "                label  = np.exp(label).tolist()\n",
    "            elif transform_y=='sqrt':\n",
    "                output = np.square(output).tolist()\n",
    "                label  = np.square(label).tolist()\n",
    "\n",
    "            true_list += label\n",
    "            pred_list += output\n",
    "\n",
    "    return true_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a96bb1-06f5-446e-ac7c-637b4bec3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f4e4415-714b-48a9-9289-40f3ac2f2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 42\n",
    "    TARGET = 'ECLO'\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9095df64-e0fd-479e-bc20-d0fbdcd988b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('./out/train_data_identity.parquet')\n",
    "test_df  = pd.read_parquet('./out/test_data_identity.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a875af0-6f78-4351-b19e-03e47c710319",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(CFG.TARGET,axis=1)\n",
    "y = train_df[CFG.TARGET]\n",
    "X_test = test_df.copy()\n",
    "\n",
    "unique_info = X.nunique()\n",
    "unique_cols = unique_info[unique_info==1].index.tolist()\n",
    "\n",
    "if len(unique_cols)>0:\n",
    "    X     .drop(unique_cols,axis=1,inplace=True)\n",
    "    X_test.drop(unique_cols,axis=1,inplace=True)\n",
    "    print(f'delete unique columns: {len(unique_cols)}\\ndetail: {unique_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf7a19e6-19d6-4448-9db6-4660f8944a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=CFG.SEED,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "994d6341-8dff-4c63-a8a0-1af026bdcffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train.values, dtype=torch.float32),\n",
    "    torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1),\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(X_val.values, dtype=torch.float32),\n",
    "    torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1),\n",
    ")\n",
    "\n",
    "train_loader  = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=CFG.NUM_WORKERS)\n",
    "val_loader    = DataLoader(val_dataset  , batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=CFG.NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f43bd9de-0008-4eaa-ada6-e713a987b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self,input_size,output_size,hidden_sizes,dropout_rate):\n",
    "        super(DNN,self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_sizes[0])])\n",
    "        self.hidden_layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "        self.output = nn.Linear(hidden_sizes[-1], output_size)\n",
    "        self.activation = nn.GELU()\n",
    "        self.bn = nn.ModuleList([nn.BatchNorm1d(hidden_sizes[i]) for i in range(len(hidden_sizes))])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for linear in self.hidden_layers:\n",
    "            x = linear(x)\n",
    "            #x = self.bn[i](x)\n",
    "            x = self.activation(x)\n",
    "            #x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a89d5679-5458-4d2d-84b5-d541e8c98f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size,output_size,hidden_size,dropout_rate):\n",
    "        super(MLP,self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_size , hidden_size), self.activation, #self.dropout,\n",
    "            nn.Linear(hidden_size, hidden_size), self.activation, #self.dropout,\n",
    "            nn.Linear(hidden_size, hidden_size), self.activation, #self.dropout,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "            elif 'fc' in name:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'bias' in name:\n",
    "                    p.data.fill_(0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b5eafb2-1b4c-4e60-959c-1ce4ba21859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        pred, actual = F.relu(pred), F.relu(actual)\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0003b4a9-da30-4dc4-97fb-2d0648711ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "epochs = 256\n",
    "lr = 1e-3\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b28b755f-f439-4ed1-be95-51f483a1c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = 1\n",
    "hidden_sizes = [128,256,128,64,32]\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# model = DNN(input_size,output_size,hidden_sizes,dropout_rate)\n",
    "model = MLP(input_size,output_size,hidden_sizes[0],dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8e219b1-b964-413c-9f11-4e0327b6d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = [x for x,y in train_loader][0]\n",
    "# y1 = [y for x,y in train_loader][0]\n",
    "# yhat = model(x1).float()\n",
    "# criterion(yhat,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8092f46f-ef66-4ccf-a860-f34bde7a409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.SEED)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e28cfc3-b089-4ae1-ae72-1aae533d5a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[001/256] tr_loss: 1.69377, val_loss: 1.68972, best_epoch: 1, elapsed: 1.00s, total: 1.00s, remaining: 255.80s\n",
      " [002/256] tr_loss: 1.69380, val_loss: 1.68972, best_epoch: 1, elapsed: 0.91s, total: 1.91s, remaining: 230.41s\n",
      " [003/256] tr_loss: 1.69380, val_loss: 1.68972, best_epoch: 1, elapsed: 0.91s, total: 2.83s, remaining: 231.48s\n",
      " [004/256] tr_loss: 1.69380, val_loss: 1.68972, best_epoch: 1, elapsed: 0.90s, total: 3.73s, remaining: 225.82s\n",
      " [005/256] tr_loss: 1.69380, val_loss: 1.68972, best_epoch: 1, elapsed: 0.89s, total: 4.62s, remaining: 223.99s\n",
      "*[006/256] tr_loss: 1.39040, val_loss: 1.24232, best_epoch: 6, elapsed: 0.96s, total: 5.58s, remaining: 240.82s\n",
      "*[007/256] tr_loss: 1.00300, val_loss: 0.47728, best_epoch: 7, elapsed: 1.09s, total: 6.67s, remaining: 270.30s\n",
      "*[008/256] tr_loss: 0.45298, val_loss: 0.44632, best_epoch: 8, elapsed: 1.06s, total: 7.74s, remaining: 264.06s\n",
      "*[009/256] tr_loss: 0.45155, val_loss: 0.44586, best_epoch: 9, elapsed: 1.07s, total: 8.81s, remaining: 264.30s\n",
      "*[010/256] tr_loss: 0.45061, val_loss: 0.44575, best_epoch: 10, elapsed: 1.07s, total: 9.88s, remaining: 263.56s\n",
      " [011/256] tr_loss: 0.45061, val_loss: 0.44577, best_epoch: 10, elapsed: 1.07s, total: 10.95s, remaining: 261.50s\n",
      "*[012/256] tr_loss: 0.45041, val_loss: 0.44575, best_epoch: 12, elapsed: 1.07s, total: 12.03s, remaining: 261.29s\n",
      "*[013/256] tr_loss: 0.45015, val_loss: 0.44572, best_epoch: 13, elapsed: 1.07s, total: 13.10s, remaining: 260.63s\n",
      " [014/256] tr_loss: 0.45020, val_loss: 0.44580, best_epoch: 13, elapsed: 1.06s, total: 14.17s, remaining: 257.00s\n",
      "*[015/256] tr_loss: 0.44990, val_loss: 0.44569, best_epoch: 15, elapsed: 1.08s, total: 15.25s, remaining: 260.73s\n",
      "*[016/256] tr_loss: 0.44969, val_loss: 0.44569, best_epoch: 16, elapsed: 1.07s, total: 16.32s, remaining: 257.61s\n",
      " [017/256] tr_loss: 0.44991, val_loss: 0.44579, best_epoch: 16, elapsed: 1.08s, total: 17.41s, remaining: 259.26s\n",
      " [018/256] tr_loss: 0.45057, val_loss: 0.45267, best_epoch: 16, elapsed: 1.08s, total: 18.49s, remaining: 256.96s\n",
      " [019/256] tr_loss: 0.45081, val_loss: 0.44570, best_epoch: 16, elapsed: 1.06s, total: 19.55s, remaining: 251.65s\n",
      " [020/256] tr_loss: 0.44972, val_loss: 0.44570, best_epoch: 16, elapsed: 1.08s, total: 20.63s, remaining: 253.82s\n",
      " [021/256] tr_loss: 0.44958, val_loss: 0.44572, best_epoch: 16, elapsed: 1.09s, total: 21.71s, remaining: 255.39s\n",
      " [022/256] tr_loss: 0.44946, val_loss: 0.44584, best_epoch: 16, elapsed: 1.07s, total: 22.78s, remaining: 249.56s\n",
      " [023/256] tr_loss: 0.44950, val_loss: 0.44569, best_epoch: 16, elapsed: 1.07s, total: 23.85s, remaining: 249.49s\n",
      " [024/256] tr_loss: 0.44972, val_loss: 0.44574, best_epoch: 16, elapsed: 1.08s, total: 24.93s, remaining: 249.70s\n",
      "*[025/256] tr_loss: 0.44961, val_loss: 0.44567, best_epoch: 25, elapsed: 1.06s, total: 25.99s, remaining: 246.00s\n",
      " [026/256] tr_loss: 0.44939, val_loss: 0.44597, best_epoch: 25, elapsed: 1.07s, total: 27.06s, remaining: 245.65s\n",
      " [027/256] tr_loss: 0.44934, val_loss: 0.44579, best_epoch: 25, elapsed: 1.08s, total: 28.14s, remaining: 246.42s\n",
      " [028/256] tr_loss: 0.44932, val_loss: 0.44583, best_epoch: 25, elapsed: 1.08s, total: 29.22s, remaining: 246.00s\n",
      " [029/256] tr_loss: 0.44929, val_loss: 0.44581, best_epoch: 25, elapsed: 1.10s, total: 30.32s, remaining: 250.82s\n",
      " [030/256] tr_loss: 0.44913, val_loss: 0.44601, best_epoch: 25, elapsed: 1.08s, total: 31.41s, remaining: 244.45s\n",
      " [031/256] tr_loss: 0.44912, val_loss: 0.44582, best_epoch: 25, elapsed: 1.12s, total: 32.52s, remaining: 251.74s\n",
      " [032/256] tr_loss: 0.44907, val_loss: 0.44576, best_epoch: 25, elapsed: 1.13s, total: 33.65s, remaining: 252.30s\n",
      " [033/256] tr_loss: 0.44893, val_loss: 0.44582, best_epoch: 25, elapsed: 1.08s, total: 34.73s, remaining: 240.14s\n",
      " [034/256] tr_loss: 0.44903, val_loss: 0.44576, best_epoch: 25, elapsed: 1.07s, total: 35.80s, remaining: 237.49s\n",
      " [035/256] tr_loss: 0.44906, val_loss: 0.44571, best_epoch: 25, elapsed: 1.06s, total: 36.86s, remaining: 235.23s\n",
      " [036/256] tr_loss: 0.44936, val_loss: 0.44581, best_epoch: 25, elapsed: 1.07s, total: 37.93s, remaining: 235.78s\n",
      " [037/256] tr_loss: 0.44918, val_loss: 0.44580, best_epoch: 25, elapsed: 1.06s, total: 39.00s, remaining: 232.89s\n",
      " [038/256] tr_loss: 0.44889, val_loss: 0.44583, best_epoch: 25, elapsed: 1.15s, total: 40.15s, remaining: 251.43s\n",
      " [039/256] tr_loss: 0.44894, val_loss: 0.44575, best_epoch: 25, elapsed: 1.10s, total: 41.25s, remaining: 238.61s\n",
      " [040/256] tr_loss: 0.44911, val_loss: 0.44762, best_epoch: 25, elapsed: 1.09s, total: 42.34s, remaining: 235.54s\n",
      " [041/256] tr_loss: 0.44918, val_loss: 0.44579, best_epoch: 25, elapsed: 1.10s, total: 43.44s, remaining: 237.05s\n",
      " [042/256] tr_loss: 0.44895, val_loss: 0.44585, best_epoch: 25, elapsed: 1.09s, total: 44.54s, remaining: 234.23s\n",
      " [043/256] tr_loss: 0.44912, val_loss: 0.44579, best_epoch: 25, elapsed: 1.17s, total: 45.71s, remaining: 249.28s\n",
      " [044/256] tr_loss: 0.44914, val_loss: 0.46401, best_epoch: 25, elapsed: 1.08s, total: 46.79s, remaining: 229.10s\n",
      " [045/256] tr_loss: 0.44897, val_loss: 0.44574, best_epoch: 25, elapsed: 1.10s, total: 47.89s, remaining: 231.30s\n",
      " [046/256] tr_loss: 0.44887, val_loss: 0.44577, best_epoch: 25, elapsed: 1.10s, total: 48.99s, remaining: 231.43s\n",
      " [047/256] tr_loss: 0.44887, val_loss: 0.44576, best_epoch: 25, elapsed: 1.08s, total: 50.07s, remaining: 226.23s\n",
      " [048/256] tr_loss: 0.44879, val_loss: 0.44578, best_epoch: 25, elapsed: 1.10s, total: 51.17s, remaining: 228.48s\n",
      " [049/256] tr_loss: 0.44892, val_loss: 0.44575, best_epoch: 25, elapsed: 1.08s, total: 52.25s, remaining: 223.59s\n",
      " [050/256] tr_loss: 0.44870, val_loss: 0.44726, best_epoch: 25, elapsed: 1.09s, total: 53.33s, remaining: 223.72s\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion = RMSLELoss().to(device)\n",
    "# criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# optimizer = torch.optim.SGD(params = model.parameters(), lr = 1e-2, momentum=0.9)\n",
    "scheduler = None\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs',min_lr=1e-7, verbose=True)\n",
    "early_stopping = EarlyStopping(patience=epochs//10,verbose=False,path=None)\n",
    "# early_stopping = None\n",
    "\n",
    "best_model = train(\n",
    "    model, optimizer, train_loader, val_loader, epochs, criterion,\n",
    "    early_stopping, device, scheduler,\n",
    "    metric_period=1,\n",
    "    verbose=True,\n",
    "    print_shape=False,\n",
    "    save_model_path = './mc/best_model.pt',\n",
    "    transform_y='identity',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee79b9-0663-49d6-be40-769a0cfc9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MLP(input_size,output_size,hidden_sizes[0],dropout_rate)\n",
    "best_model.load_state_dict(torch.load('./mc/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c8fb5-1c12-4872-baef-3bef034c225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true,pred = predict(best_model,val_loader,device,'identity')\n",
    "RMSLELoss()(torch.tensor(true),torch.tensor(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83520665-015a-449a-9d22-52ed9ba5e3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412e2f9-cb50-400f-ade1-e7a4e56b23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env_3.10.13",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
