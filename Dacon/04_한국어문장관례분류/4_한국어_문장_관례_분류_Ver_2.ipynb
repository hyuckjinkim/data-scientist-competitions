{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hyuckjinkim/Dacon/blob/main/%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%AC%B8%EC%9E%A5_%EA%B4%80%EB%A1%80_%EB%B6%84%EB%A5%98_Ver_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Hpltte_O7sZ"
   },
   "source": [
    "--- \n",
    "\n",
    "# **코드설명**\n",
    "\n",
    "---\n",
    "\\\n",
    "\n",
    "- 파 일 명 : 한국어 문장 관례 분류 Ver 1 <br>\n",
    "- 시작날짜 : 2022.02.04 <br>\n",
    "- 수정날짜 : 2022.02.04 <br>\n",
    "- 작 성 자 : 김혁진 <br>\n",
    "- 작성주제 : 한국어 문장 관례 분류 <br>\n",
    "\n",
    "- 주제상세 : \\\n",
    "\\\n",
    "한 쌍의 문장은 Premise와 Hypothesis로 구성되어 있습니다. \\\n",
    "premise 문장을 참고해 hypothesis 문장이 참인지(Entailment), 거짓인지(Contradiction), \\\n",
    "혹은 참/거짓 여부를 알 수 없는 문장인지(Neutral)를 판별해야 합니다. \n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "- **참조**\n",
    "\n",
    "  (1) 대회 홈페이지 : [Dacon](https://dacon.io/competitions/official/235875/overview/description) <br>\n",
    "  (2) 하이퍼 파리미터 설명 : [Naver Blog](https://blog.naver.com/wideeyed/221333529176) <br>\n",
    "  (3) Class문 설명 : [Github](https://zzsza.github.io/development/2020/07/05/python-class/) <br>\n",
    "  (4) GPU 설정 : [Medium](https://medium.com/@am.sharma/lgbm-on-colab-with-gpu-c1c09e83f2af) <br>\n",
    "  (5) RAM 모두사용으로 세션다운 : [Tistory](https://somjang.tistory.com/entry/Google-Colab-%EC%9E%90%EC%A3%BC%EB%81%8A%EA%B8%B0%EB%8A%94-%EB%9F%B0%ED%83%80%EC%9E%84-%EB%B0%A9%EC%A7%80%ED%95%98%EA%B8%B0)\n",
    "\n",
    "---\n",
    "\n",
    "- **고려사항** <br>\n",
    "  (1) AutoEncoder로 파생변수 생성해보기 <br>\n",
    "  (2) 하이퍼파라미터 탐색 : grid-search, bayesian-optimization, [optuna](https://dacon.io/competitions/official/235713/codeshare/2704?page=1&dtype=recent) <br>\n",
    "  (3) RandomForest, XGBoost, Lightgbm, CatBoost 설명 [블로그](https://jhkim0759.tistory.com/12)\n",
    "\n",
    "---\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XQlKuksQEiS"
   },
   "source": [
    "# 1.&nbsp;기본설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2wIV1OVJM8x"
   },
   "source": [
    "\\\n",
    "## 1.1.&nbsp;colab 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvOe15pZIoWN"
   },
   "outputs": [],
   "source": [
    "# # 출처: https://schulwin.tistory.com/entry/Google-Colab-설정하기-런타임-연결-끊김-방지 [Diary of Schul]\n",
    "# # Google Colab을 실행시키는 크롬 브라우저 창에서 F12 (혹은 Ctrl-Shift-i)를 눌러서 개발자 도구 창을 열고 \n",
    "# # Console 창에서 아래와 같이 입력을 해주면 된다.\n",
    "\n",
    "# # (1) 런타임 연결 끊김 방지\n",
    "# function ClickConnect() { \n",
    "#     // 백엔드를 할당하지 못했습니다. \n",
    "#     // GPU이(가) 있는 백엔드를 사용할 수 없습니다. 가속기가 없는 런타임을 사용하시겠습니까? \n",
    "#     // 취소 버튼을 찾아서 클릭 \n",
    "#     var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); \n",
    "#     buttons.forEach(function(btn) { \n",
    "#         btn.click(); \n",
    "#     }); \n",
    "#     console.log(\"1분마다 자동 재연결\"); \n",
    "#     document.querySelector(\"#top-toolbar > colab-connect-button\").click(); \n",
    "# } \n",
    "# setInterval(ClickConnect,1000*60);\n",
    "\n",
    "# # (2) Google Colab에서 30분마다 현재 출력창 지우기\n",
    "# function CleanCurrentOutput(){ \n",
    "#     var btn = document.querySelector(\".output-icon.clear_outputs_enabled.output-icon-selected[title$='현재 실행 중...'] iron-icon[command=clear-focused-or-selected-outputs]\"); \n",
    "#     if(btn) { \n",
    "#         console.log(\"30분마다 출력 지우기\"); btn.click(); \n",
    "#     } \n",
    "# } \n",
    "# setInterval(CleanCurrentOutput,1000*60*30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uSRUFV2Qme4"
   },
   "source": [
    "\\\n",
    "## 1.2.&nbsp;Query Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45OvrRVvP0ai"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "query_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToVOSlCGR0LC"
   },
   "source": [
    "\\\n",
    "## 1.3.&nbsp;Markdown : Tabular Left Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65cy46RtPxwj"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UG44JqsSNRF"
   },
   "source": [
    "\\\n",
    "## 1.4.&nbsp;Jupyter Notebook Style : Theme, Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9Xo5fobQTyO"
   },
   "outputs": [],
   "source": [
    "# # theme 설치\n",
    "# !pip install jupyterthemes\n",
    "\n",
    "# # jupyter notebook 최신버전\n",
    "# !pip install --upgrade notebook\n",
    "\n",
    "# # jupyter notebook 최신버전\n",
    "# !pip install --upgrade jupyterthemes\n",
    "\n",
    "# 2.2.1. 테마바꾸기(customizing)\n",
    "# !jt -t onedork -fs 115 -nfs 125 -tfs 115 -dfs 115 -ofs 115 -cursc r -cellw 80% -lineh 115 -altmd  -kl -T -N\n",
    "\n",
    "# 2.2.2. 쥬피터 노트북 화면 넓게 사용\n",
    "# 출처: https://taehooh.tistory.com/entry/Jupyter-Notebook-주피터노트북-화면-넓게-쓰는방법\n",
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# # 2.2.3. 좌측 TOC 만들기\n",
    "# # 출처 : https://gmnam.tistory.com/246\n",
    "# !pip install jupyter_nbextensions_configurator\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "\n",
    "# !jupyter nbextensions_configurator enable --user\n",
    "# !jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOObpAz_QYTT"
   },
   "outputs": [],
   "source": [
    "# # 2.3.1 Google Drive Mount\n",
    "# # (Google Drive 사용 시 설정)\n",
    "from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "# # 새로운 창에서 key 를 받아서 입력해야합니다.\n",
    "# drive.mount('/content/drive') # , force_remount = True\n",
    "\n",
    "# colab 패키지 영구적으로 저장\n",
    "# 심볼릭링크 : https://com-flex.tistory.com/12\n",
    "pg_path = '/content/packages'  \n",
    "os.symlink('/content/drive/MyDrive/Colab Notebooks', pg_path) \n",
    "sys.path.insert(0, pg_path)  \n",
    "\n",
    "# # 2.3.2. 메모리 에러\n",
    "# https://growingsaja.tistory.com/477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uq-Wd0mbQhjs"
   },
   "outputs": [],
   "source": [
    "# # 2.3.3. GPU 사용 (6분)\n",
    "# !git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "# !mkdir build\n",
    "# %cd /content/LightGBM\n",
    "# !cmake -DUSE_GPU=1 #avoid ..\n",
    "# !make -j$(nproc)\n",
    "# !sudo apt-get -y install python-pip\n",
    "# !sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
    "# %cd /content/LightGBM/python-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6yrneqSQjfC"
   },
   "outputs": [],
   "source": [
    "# !pip install --target=$pg_path pandasql\n",
    "# !pip install --target=$pg_path seaborn\n",
    "# !pip install --target=$pg_path plotnine\n",
    "# !pip install --target=$pg_path pandasql\n",
    "\n",
    "# # lightgbm 에러떴는데, 콘다에서 실행하면 해결됨\n",
    "# # conda install -c conda-forge lightgbm \n",
    "\n",
    "# # bayesian optimization 설치\n",
    "# !pip install --target=$pg_path bayesian-optimization\n",
    "\n",
    "# # xgboost 설치\n",
    "# !pip install --target=$pg_path xgboost\n",
    "\n",
    "# # catboost 설치\n",
    "# !pip install --target=$pg_path catboost\n",
    "\n",
    "# !pip install --target=$pg_path tall_path dill\n",
    "\n",
    "# # pycaret 에러떴는데, --user 붙이니깐 해결됨\n",
    "# !pip install --target=$pg_path --user pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMGa5g0CmPEr"
   },
   "outputs": [],
   "source": [
    "# !pip install --target=$pg_path lightgbm --install-option=--gpu\n",
    "\n",
    "# !pip install transformers # --target=$pg_path\n",
    "\n",
    "# !pip install --user optuna # --target=$pg_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guJRT41kS2rq"
   },
   "source": [
    "\\\n",
    "## 1.5.&nbsp;Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IhxhoKdP-tz"
   },
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp4rpiyDS92N"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# jupyter notebook 전용\n",
    "#------------------------------------------------------------------------------#\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# basic modules\n",
    "#------------------------------------------------------------------------------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "# value_counts() 범용적인 버전\n",
    "from collections import Counter as cnt\n",
    "\n",
    "# # sqldf\n",
    "# from pandasql import sqldf\n",
    "# sql = lambda q: sqldf(q, globals())\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# save env.\n",
    "#------------------------------------------------------------------------------#\n",
    "# import dill\n",
    "\n",
    "# #------------------------------------------------------------------------------#\n",
    "# # plotting\n",
    "# #------------------------------------------------------------------------------#\n",
    "# import seaborn as sns\n",
    "# sns.set(rc={'figure.figsize':(11.7, 8.27)})\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = [11.7, 8.27] # [15, 10] # [11.7,8.27] - A4 size\n",
    "# plt.style.use('dark_background')\n",
    "\n",
    "# from plotnine import *\n",
    "\n",
    "# #------------------------------------------------------------------------------#\n",
    "# # modeling\n",
    "# #------------------------------------------------------------------------------#\n",
    "# import sklearn\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder, PolynomialFeatures\n",
    "# from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,train_test_split\n",
    "# from sklearn.metrics import f1_score,make_scorer,r2_score\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.linear_model import LinearRegression, LogisticRegression, RidgeClassifier, Ridge, Lasso, ElasticNet\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor, AdaBoostClassifier\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from xgboost import XGBRegressor, XGBClassifier\n",
    "# from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "# import lightgbm as lgb\n",
    "# from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# # Hyperparameter Optimization\n",
    "# from bayes_opt import BayesianOptimization\n",
    "# import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkeGgu0VTQga"
   },
   "source": [
    "\\\n",
    "## 1.6.&nbsp;Initial Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eci_EVYNTOws"
   },
   "outputs": [],
   "source": [
    "# 2.5.1. Data Path\n",
    "DATA_PATH = '/content/drive/MyDrive/Python/4. 한국어 문장 관계 분류/DAT/'\n",
    "OUT_PATH  = '/content/drive/MyDrive/Python/4. 한국어 문장 관계 분류/OUT/'\n",
    "PARA_PATH = '/content/drive/MyDrive/Python/4. 한국어 문장 관계 분류/best_para/'\n",
    "\n",
    "# 2.5.2. set seed\n",
    "SEED = 777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW48y_NrUf7l"
   },
   "source": [
    "\\\n",
    "## 1.7.&nbsp;Set Off the Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1W8Nyy6Uj1N"
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXvFb-ChUstU"
   },
   "source": [
    "\\\n",
    "## 1.8.&nbsp;User Defined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--lvfs-nUn5_"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.1. Seed Fix\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def seed_everything(seed: int = 1):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    # torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    # torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "seed_everything(SEED)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.2. View all columns\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def View(data):\n",
    "\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    \n",
    "    print(data)\n",
    "\n",
    "    pd.set_option('display.max_rows', 0)\n",
    "    pd.set_option('display.max_columns', 0)\n",
    "    pd.set_option('display.width', 0)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.3. minmax function\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def minmax(x, digit=None):\n",
    "    if round is None:\n",
    "        return min(x),max(x)\n",
    "    else:\n",
    "        return round(min(x),digit),round(max(x),digit)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.4. 컬럼dict에서 target 제거\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# - dict : 기준 dict\n",
    "# - key  : 삭제할 key\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def rmkey(dict, key):\n",
    "    tmp = dict.copy()\n",
    "    del tmp[key]\n",
    "    return tmp\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.5. 각 컬럼의 missing 개수를 파악하는 함수\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# - data     : 기준 data\n",
    "# - col_type : {column명 : type}로 이루어진 dictionary\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def missing_column_check(df, col_type):\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    n_na = []\n",
    "    n_na_type = []\n",
    "    for col_nm in data.columns:\n",
    "        data[col_nm] = data[col_nm].astype(col_type[col_nm])\n",
    "\n",
    "        # str인 경우에는 blank(공백)도 있는지 확인\n",
    "        if col_type[col_nm]==str:\n",
    "\n",
    "            isnull_cnt = data[col_nm].str.strip().isnull().sum()\n",
    "            blank_cnt  = sum(data[col_nm].str.strip()=='')\n",
    "            nan_cnt    = sum(data[col_nm].str.strip()=='nan')\n",
    "            null_cnt   = sum(data[col_nm].str.strip()=='null')\n",
    "\n",
    "            n_na_x = isnull_cnt+blank_cnt+nan_cnt+null_cnt\n",
    "            n_na.append(n_na_x)\n",
    "            \n",
    "            if n_na_x>0:\n",
    "                n_na_type_x=[]\n",
    "                if isnull_cnt>0: n_na_type_x.append('isnull')\n",
    "                if blank_cnt >0: n_na_type_x.append('blank')\n",
    "                if nan_cnt   >0: n_na_type_x.append('nan')\n",
    "                if null_cnt  >0: n_na_type_x.append('null')\n",
    "                n_na_type_x = '+'.join(n_na_type_x)\n",
    "            else:\n",
    "                n_na_type_x = ''\n",
    "            n_na_type.append(n_na_type_x)\n",
    "            \n",
    "\n",
    "        # numeric인 경우에는 null의 개수만 확인\n",
    "        else:\n",
    "            n_na_x = data[col_nm].isnull().sum()\n",
    "            n_na.append(n_na_x)\n",
    "            \n",
    "            if n_na_x>0:\n",
    "                n_na_type.append('isnull')\n",
    "            else:\n",
    "                n_na_type.append('')\n",
    "            \n",
    "    res_df = pd.DataFrame({\n",
    "        'col'  : data.columns,\n",
    "        'n_na' : n_na,\n",
    "        'n_n_ratio' : [str(round(n/len(data)*100,1))+'%' for n in n_na],\n",
    "        'na_type' : n_na_type,\n",
    "        'col_type' : [COL_TYPE[col].__name__ for col in data.columns]\n",
    "        })\n",
    "\n",
    "    res_df = res_df[res_df['n_na']>0]\n",
    "    if len(res_df)==0:\n",
    "        return('Dataset does not have a null value')\n",
    "    else:\n",
    "        return(res_df)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.6. 교호작용항 추가\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# - data     : 기준 data\n",
    "# - num_vari : 숫자형 변수 list\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def interaction_term(df,num_vari):\n",
    "    \n",
    "    data = df.copy()\n",
    "\n",
    "    num_var = list(set(num_vari) - set(['id']))\n",
    "\n",
    "    for i in range(0,len(num_var)):\n",
    "        for j in range(i,len(num_var)):\n",
    "            data[f'{num_var[i]}*{num_var[j]}'] = data[f'{num_var[i]}']*data[f'{num_var[j]}']\n",
    "\n",
    "    return(data)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.7. color when print\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "class color:\n",
    "    PURPLE    = '\\033[95m'\n",
    "    CYAN      = '\\033[96m'\n",
    "    DARKCYAN  = '\\033[36m'\n",
    "    BLUE      = '\\033[94m'\n",
    "    GREEN     = '\\033[92m'\n",
    "    YELLOW    = '\\033[93m'\n",
    "    RED       = '\\033[91m'\n",
    "    BOLD      = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END       = '\\033[0m'\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.8. density plot : histogram + density plot\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# - data : 기준 data\n",
    "# - vars : hist + kde를 그릴 숫자형 변수\n",
    "# - hue  : group화 변수\n",
    "# - binwidth_adj_ratio : binwidth 조정 비율\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def density_plot(df, vars, \n",
    "                 binwidths = None, hue = None,\n",
    "                 binwidth_adj_ratio = None):\n",
    "\n",
    "    from matplotlib.ticker import PercentFormatter\n",
    "    \n",
    "    data = df.copy()\n",
    "\n",
    "    # 1) vars가 1개뿐일 때 에러발생\n",
    "    #    -> 1개     : type = str\n",
    "    #    -> 2개이상 : type = ndarray, ...\n",
    "    if type(vars)==str:\n",
    "        vars = [vars]\n",
    "    \n",
    "    # 2) plotting (nrow,ncol) 설정\n",
    "    nrow = math.ceil(len(vars)**(1/2))\n",
    "    ncol = nrow\n",
    "\n",
    "    # 3) binwidths가 없을 때, binwidth 설정\n",
    "    # 출처 : http://www.aistudy.co.kr/paper/pdf/histogram_jeon.pdf\n",
    "    if binwidths is None:\n",
    "        binwidths = []\n",
    "        for col in data[vars].columns:\n",
    "            n_bin = math.ceil(1 + 3.32*math.log10(len(data)))\n",
    "            binwidth = ( data[col].max() - data[col].min() ) / n_bin\n",
    "            binwidths.append(binwidth)\n",
    "            del binwidth\n",
    "    \n",
    "    # 4) 설정한 binwidth를 조정하는 비율\n",
    "    if binwidth_adj_ratio is not None:\n",
    "        binwidths = [binwidth * binwidth_adj_ratio for binwidth in binwidths]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    # 5) vars 별로 plot 생성\n",
    "    for iter,var in enumerate(vars):\n",
    "        \n",
    "        binwidth = binwidths[iter]\n",
    "        \n",
    "        # (1) histogram\n",
    "        ax1 = fig.add_subplot(nrow, ncol, iter+1)\n",
    "        g1 = sns.histplot(data = data, x = var, hue = hue,\n",
    "                          kde = True, stat = 'probability', \n",
    "                          color = 'lightskyblue',\n",
    "                          binwidth = binwidth, ax = ax1)\n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        # (2) density plot\n",
    "        g2 = sns.kdeplot(data = data, x = var, hue = hue,\n",
    "                         color = 'red', lw = 2, ax = ax2)\n",
    "        ax2.set_ylim(0, ax1.get_ylim()[1] / binwidth)                  # similir limits on the y-axis to align the plots\n",
    "        #ax2.yaxis.set_major_formatter(PercentFormatter(1 / binwidth))  # show axis such that 1/binwidth corresponds to 100%\n",
    "        ax2.grid(False)\n",
    "        \n",
    "        # (3) density plot y축 없애기\n",
    "        g2.set(yticklabels=[]) \n",
    "        g2.set(ylabel=None)\n",
    "        g2.tick_params(right=False)\n",
    "        \n",
    "        a,b = divmod(iter,ncol)\n",
    "        if b!=0:\n",
    "            g1.set(ylabel=None)\n",
    "        \n",
    "    # 안겹치도록 설정\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# example : density_plot(train, vars=num_vari)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.9. density plot : histogram + density plot\n",
    "#\n",
    "# (1) grp_var vs hue_var 막대그래프\n",
    "# (2) grp_var(x축), hue_var에 따른 각 num_var들의 barplot, violineplot, box+swarmplot + kdeplot\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "#- grp_var : x축 구분할 그룹변수 (text)\n",
    "#- num_vari : 숫자형 변수 (list)\n",
    "#- data : 기준 data\n",
    "#- title_text : plot title (text)\n",
    "#- hue_var : hue 그루핑변수\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def plot_num(grp_var, num_vari, df, title_text=None, hue_var=None):\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    # (1)번 그래프 setting\n",
    "    fig0 = plt.figure(figsize=(3,3))\n",
    "    ax0  = fig0.add_subplot(1,1,1)\n",
    "    \n",
    "    if title_text is None:\n",
    "        title_text = grp_var\n",
    "        \n",
    "    plt.title(title_text, loc='left', pad=20, fontdict={'fontsize' : 30,\n",
    "                                                        'fontweight' : 'bold',\n",
    "                                                        'color' : 'c'})\n",
    "    \n",
    "    # grp_var와 hue_var가 겹치는 경우, hue를 나누지 않음\n",
    "    if (grp_var!=hue_var) and (hue_var is not None):\n",
    "\n",
    "        ct = pd.crosstab(data[grp_var],data[hue_var])\n",
    "        ax = ct.plot(kind='bar', stacked=False, rot=0, ax=ax0)\n",
    "        ax.legend(title=hue_var, bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "        \n",
    "    else:\n",
    "        ct = data[grp_var].value_counts()\n",
    "        ax = ct.plot(kind='bar', stacked=False, rot=0, ax=ax0)\n",
    "        \n",
    "    # show\n",
    "    plt.xlabel('')\n",
    "    plt.show()\n",
    "    \n",
    "    # 숫자변수중에 [grp,id]변수가 있으면 제외\n",
    "    num_vari_x = list(set(num_vari) - set([grp_var,'id']))\n",
    "    \n",
    "    # plt 생성\n",
    "    fig = plt.figure(figsize=(15,15)) # figsize=(15,7)\n",
    "    plt.axis('off') # 안끄면 x축에 0~1까지 축생김\n",
    "    \n",
    "    for iter,var in enumerate(num_vari_x):\n",
    "\n",
    "        # hue랑 grp_var랑 같으면 hue를 넣지않음\n",
    "        hue_x = [None if grp_var==hue_var else hue_var][0]\n",
    "\n",
    "        # (n,4) plot\n",
    "        ax1 = fig.add_subplot(len(num_vari_x),4,4*iter+1)\n",
    "        ax2 = fig.add_subplot(len(num_vari_x),4,4*iter+2)\n",
    "        ax3 = fig.add_subplot(len(num_vari_x),4,4*iter+3)\n",
    "        ax4 = fig.add_subplot(len(num_vari_x),4,4*iter+4)\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        # (2-1) 3번째 : box + swarm plot (ylim가져오기위해서 제일 먼저 실행)\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        g11=sns.swarmplot(x=grp_var, y=var, data=data, ax = ax3, color='crimson', marker='*', s = 7)\n",
    "        g12=sns.boxplot  (x=grp_var, y=var, data=data, ax = ax3)\n",
    "        g12.set(ylabel=None)\n",
    "        g12.set(yticklabels=[])\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        # (2-2) 1번째 : barplot\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        ax1.set_ylim(ax3.get_ylim())\n",
    "        g21=sns.barplot(x=grp_var, y=var, data=data, ax=ax1, hue=hue_x)\n",
    "        # g21.set(ylabel=None)\n",
    "        # g21.set(yticklabels=[])\n",
    "        # g21.axes.set_title(str(iter+1) + ':' + var, fontsize=20, weight='bold', ha='left', x=-.05)\n",
    "        g21.set_ylabel(var,fontsize=20)\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        # (2-3) 2번째 : violinplot\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        ax2.set_ylim(ax3.get_ylim())\n",
    "        g31=sns.violinplot(x=grp_var, y=var, data=data, ax=ax2, legend=False, hue=hue_x)\n",
    "        g31.set(ylabel=None)\n",
    "        g31.set(yticklabels=[])\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        # (2-4) 4번째 : density plot\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        ax4.set_ylim(ax3.get_ylim())\n",
    "        g41=sns.kdeplot(y=var, hue=grp_var, data=data, ax=ax4)\n",
    "        g41.set(ylabel=None)\n",
    "        g41.set(yticklabels=[])\n",
    "        g41.tick_params(right=False)\n",
    "        g41.set(xlabel=None)\n",
    "        g41.set(xticklabels=[])\n",
    "        \n",
    "        # 맨 아래에만 x축이 생성되도록 setting\n",
    "        if (iter+1) != len(num_vari_x):\n",
    "            \n",
    "            g12.set(xlabel=None)\n",
    "            g12.set(xticklabels=[])\n",
    "\n",
    "            g21.set(xlabel=None)\n",
    "            g21.set(xticklabels=[])\n",
    "\n",
    "            g31.set(xlabel=None)\n",
    "            g31.set(xticklabels=[])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# # example\n",
    "# plot_num(grp_var = 'sex', num_vari = num_vari, hue_var = 'target',\n",
    "#          data = train, title_text = 'sex')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.10. onehot encoding\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "#- data\n",
    "#- col_types\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def onehot_encoding(data, col_types):\n",
    "\n",
    "    raw_data = data.copy()\n",
    "    \n",
    "    cols = list(set(data.columns) - set(['target']))\n",
    "\n",
    "    for col in cols:\n",
    "        if col_types[col]==str:\n",
    "\n",
    "            data = pd.concat([\n",
    "                data.drop([col],axis=1).reset_index(drop=True),\n",
    "                pd.get_dummies(data[col], prefix = col).reset_index(drop=True).apply(lambda x:x.astype(float))\n",
    "                ],\n",
    "                axis=1)\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.10. onehot encoding : str들 모두 int/category로 바꾸기\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "#- data\n",
    "#- col_types\n",
    "#- convert : int / category\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def str_convert(data, col_types, convert = [int,'category']):\n",
    "\n",
    "    cols = list(set(data.columns) - set(['target']))\n",
    "\n",
    "    for col in cols:\n",
    "        if col_types[col]==str:\n",
    "            data[col] = data[col].astype(convert)\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "# 2.6.11. setdiff\n",
    "#-------------------------------------------------------------------------------------------------------#\n",
    "def setdiff(x,y):\n",
    "    return(list(set(x)-set(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c00sN2A2U-EJ"
   },
   "source": [
    "\\\n",
    "## 1.9.&nbsp;버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uj_iFXBVFh3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SRGCpIBlBw4"
   },
   "source": [
    "\\\n",
    "# 2.&nbsp;Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8T9DnEn0WFeK"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH + 'train_data.csv')\n",
    "test  = pd.read_csv(DATA_PATH + 'test_data.csv')\n",
    "sub   = pd.read_csv(DATA_PATH + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-uQ6CL8Wd0_"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEidWF99Wf6f"
   },
   "outputs": [],
   "source": [
    "example_num = 1001\n",
    "print(f'{color.CYAN}> premise\\t{color.END}: {train[\"premise\"][example_num]}')\n",
    "print(f'{color.CYAN}> hypothesis\\t{color.END}: {train[\"hypothesis\"][example_num]}')\n",
    "print(f'{color.CYAN}> label\\t\\t{color.END}: {train[\"label\"][example_num]}\\n')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxoxrwdUYd9n"
   },
   "outputs": [],
   "source": [
    "print(train.isnull().values.any()) # Null 값이 존재하는지 확인\n",
    "\n",
    "# train = train.dropna(how='any') # Null 값이 존재하는 행 제거\n",
    "# train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQHtqE5aYnLV"
   },
   "outputs": [],
   "source": [
    "print(f'{color.CYAN}> train{color.END}')\n",
    "print(f'premise    최소,최대 길이 : ({train[\"premise\"].map(len).min()},{train[\"premise\"].map(len).max()})')\n",
    "print(f'hypothesis 최소,최대 길이 : ({train[\"hypothesis\"].map(len).min()},{train[\"hypothesis\"].map(len).max()})')\n",
    "\n",
    "print('')\n",
    "\n",
    "print(f'{color.CYAN}> test{color.END}')\n",
    "print(f'premise    최소,최대 길이 : ({test[\"premise\"].map(len).min()},{test[\"premise\"].map(len).max()})')\n",
    "print(f'hypothesis 최소,최대 길이 : ({test[\"hypothesis\"].map(len).min()},{test[\"hypothesis\"].map(len).max()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NF4IKZx077Wh"
   },
   "outputs": [],
   "source": [
    "print(f'\\n{\"-\"*200}\\n')\n",
    "\n",
    "print(f'{color.CYAN}> premise min ({train[\"premise\"].map(len).min()}){color.END}')\n",
    "print(f'premise    : {train[\"premise\"][train[\"premise\"].map(len).argmin()]}')\n",
    "print(f'hypothesis : {train[\"hypothesis\"][train[\"premise\"].map(len).argmin()]}')\n",
    "print(f'label      : {train[\"label\"][train[\"premise\"].map(len).argmin()]}\\n')\n",
    "\n",
    "print(f'{color.CYAN}> premise max ({train[\"premise\"].map(len).max()}){color.END}')\n",
    "print(f'premise    : {train[\"premise\"][train[\"premise\"].map(len).argmax()]}')\n",
    "print(f'hypothesis : {train[\"hypothesis\"][train[\"premise\"].map(len).argmax()]}')\n",
    "print(f'label      : {train[\"label\"][train[\"premise\"].map(len).argmax()]}')\n",
    "\n",
    "print(f'\\n{\"-\"*200}\\n')\n",
    "\n",
    "print(f'{color.CYAN}> hypothesis min ({train[\"hypothesis\"].map(len).min()}){color.END}')\n",
    "print(f'premise    : {train[\"premise\"][train[\"hypothesis\"].map(len).argmin()]}')\n",
    "print(f'hypothesis : {train[\"hypothesis\"][train[\"hypothesis\"].map(len).argmin()]}')\n",
    "print(f'label      : {train[\"label\"][train[\"hypothesis\"].map(len).argmin()]}\\n')\n",
    "\n",
    "print(f'{color.CYAN}> hypothesis min ({train[\"hypothesis\"].map(len).max()}){color.END}')\n",
    "print(f'premise    : {train[\"premise\"][train[\"hypothesis\"].map(len).argmax()]}')\n",
    "print(f'hypothesis : {train[\"hypothesis\"][train[\"hypothesis\"].map(len).argmax()]}')\n",
    "print(f'label      : {train[\"label\"][train[\"hypothesis\"].map(len).argmax()]}')\n",
    "\n",
    "print(f'\\n{\"-\"*200}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJIrTym2lLqJ"
   },
   "source": [
    "\\\n",
    "# 3.&nbsp;Modelling - BERT by optuna\n",
    "\n",
    "- What is BERT : [Link1](https://riverkangg.github.io/nlp/nlp-bertWordEmbedding/), [Link2](https://ebbnflow.tistory.com/151), [Link3](https://riverkangg.github.io/nlp/nlp-bertWordEmbedding/) \\\n",
    "\n",
    "- model 선택 : [huggingface](https://huggingface.co/) \\\n",
    "- with optuna : [github](https://thigm85.github.io/blog/search/cord19/bert/transformers/optuna/2020/11/07/bert-training-optuna-tuning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9MC56xuLRvi"
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.25\n",
    "model_name_list = [\n",
    "  \"klue/roberta-base\",\n",
    "  \"Huffon/klue-roberta-base-nli\",\n",
    "  \"roberta-large-mnli\",          \n",
    "]\n",
    "model_name = model_name_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQQY52qZF9U8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(f'{color.CYAN}is_gpu_avlilable     {color.END}: {tf.test.is_gpu_available()}')\n",
    "print(f'{color.CYAN}gpu_device_name      {color.END}: {tf.test.gpu_device_name()}')\n",
    "print(f'{color.CYAN}gpu_device_name_list {color.END}: {tf.config.experimental.list_physical_devices(device_type=\"GPU\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sbJXwkxLL_s"
   },
   "outputs": [],
   "source": [
    "X = train.drop('label',axis=1)\n",
    "y = train['label']\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qbt9JcgyLZY9"
   },
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n",
    "\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "def model_init():\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 20),\n",
    "        \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32, 64]),\n",
    "    }\n",
    "def my_objective(metrics):\n",
    "    return metrics[\"eval_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUjqb1QvLqL8"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    train_dataset=X_tr,               # training dataset\n",
    "    eval_dataset=X_va,                # evaluation dataset\n",
    "    compute_metrics=compute_metrics,  # metrics to be computed\n",
    "    model_init=model_init             # Instantiate model before training starts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjJdDFUwMAIN"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "best_run = trainer.hyperparameter_search(direction=\"minimize\", hp_space=my_hp_space, compute_objective=my_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukSGONtVMNSO"
   },
   "outputs": [],
   "source": [
    "with open(PARA_PATH + \"best_run.json\", \"w+\") as f:\n",
    "  f.write(json.dumps(best_run.hyperparameters))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhDr8pn5Ms8mm5+Imz32uR",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Zoz0uixodzJ8GVBoilpwtORNCHXhX5WF",
   "name": "한국어 문장 관례 분류 Ver 2",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
