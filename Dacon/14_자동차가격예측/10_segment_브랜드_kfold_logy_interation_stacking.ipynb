{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b987cd1-0680-4fb8-a482-f5567577e80f",
   "metadata": {},
   "source": [
    "# Library Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eeab870-95ed-41a6-b815-1bdf2dee38fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b6f33-3b7d-401a-a710-ea0f089f95a7",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b54b8f-874d-49c7-95db-a535b984b01d",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe03a3b-5d80-448f-ad15-50e77c5128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 0\n",
    "    \n",
    "    SUBSET_DEPTH = 1\n",
    "    INTERACTION = True\n",
    "    FS_ALPHA = 0.01\n",
    "    \n",
    "    N_SPLITS = 5\n",
    "    TARGET_TRANSFORMATION = True\n",
    "    \n",
    "    LR = 0.003\n",
    "    EPOCHS = 30000\n",
    "    ES = 300\n",
    "    XGB_LR = 0.01     # default=0.3\n",
    "    XGB_EPOCHS = 1000 # default=100\n",
    "    XGB_ES = 100\n",
    "    XTRATREES_EPOCHS = 100 #default=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f2cfe-7bf1-4cc3-b7e3-90b0886eab54",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbf58b-29ed-4ab7-9a2c-f51c6b08c00a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8ae59-c4c3-47f8-854a-6cfc780a2adc",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a824834-ad27-424a-8f55-7c4ca73eaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df  = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da88a595-b068-4b4b-97a9-4e6bcf863305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57920, 15), (14480, 14))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d6f038-af80-42c0-a33e-e62dcd8bdfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>생산년도</th>\n",
       "      <th>모델출시년도</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>차량모델명</th>\n",
       "      <th>판매도시</th>\n",
       "      <th>판매구역</th>\n",
       "      <th>주행거리</th>\n",
       "      <th>배기량</th>\n",
       "      <th>압축천연가스(CNG)</th>\n",
       "      <th>경유</th>\n",
       "      <th>가솔린</th>\n",
       "      <th>하이브리드</th>\n",
       "      <th>액화석유가스(LPG)</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>2018</td>\n",
       "      <td>2014</td>\n",
       "      <td>skoda</td>\n",
       "      <td>fabia</td>\n",
       "      <td>KAT</td>\n",
       "      <td>SLA</td>\n",
       "      <td>85231</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>toyota</td>\n",
       "      <td>auris</td>\n",
       "      <td>RKO</td>\n",
       "      <td>SWI</td>\n",
       "      <td>135000</td>\n",
       "      <td>1598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>clk-klasa</td>\n",
       "      <td>GNI</td>\n",
       "      <td>WIE</td>\n",
       "      <td>255223</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>nissan</td>\n",
       "      <td>x-trail</td>\n",
       "      <td>EHX</td>\n",
       "      <td>WIE</td>\n",
       "      <td>238000</td>\n",
       "      <td>2184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>fiat</td>\n",
       "      <td>bravo</td>\n",
       "      <td>OSW</td>\n",
       "      <td>MAL</td>\n",
       "      <td>251000</td>\n",
       "      <td>1910</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  생산년도  모델출시년도            브랜드      차량모델명 판매도시 판매구역    주행거리  \\\n",
       "0  TRAIN_00000  2018    2014          skoda      fabia  KAT  SLA   85231   \n",
       "1  TRAIN_00001  2010    2006         toyota      auris  RKO  SWI  135000   \n",
       "2  TRAIN_00002  2002    2002  mercedes-benz  clk-klasa  GNI  WIE  255223   \n",
       "3  TRAIN_00003  2006    2001         nissan    x-trail  EHX  WIE  238000   \n",
       "4  TRAIN_00004  2007    2007           fiat      bravo  OSW  MAL  251000   \n",
       "\n",
       "    배기량  압축천연가스(CNG)  경유  가솔린  하이브리드  액화석유가스(LPG)     가격  \n",
       "0   999            0   0    1      0            0  51.74  \n",
       "1  1598            0   0    1      0            0  41.47  \n",
       "2  1796            0   0    1      0            0  17.81  \n",
       "3  2184            0   1    0      0            0  18.20  \n",
       "4  1910            0   1    0      0            0  17.55  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04590f97-2b7a-4039-aa51-7528b7f14a91",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b653065-ce2f-4186-89d0-eb71b4bd0986",
   "metadata": {},
   "source": [
    "## Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30b74aa-75d9-4c9e-a67d-71a97fe529b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.TARGET_TRANSFORMATION:\n",
    "    train_df['가격'] = np.log(train_df['가격'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c323f-9e86-4fe2-9e09-395d4e290050",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0aab2e-3a95-4013-a15e-d141663182ea",
   "metadata": {},
   "source": [
    "## Resetting Columns Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbffe1aa-eef1-4263-933e-492cbbf6cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeResetting:\n",
    "    def __init__(self):\n",
    "        self.cat_features = ['브랜드','차량모델명','판매도시','판매구역','생산년도','모델출시년도']\n",
    "        self.seg_features = []\n",
    "        \n",
    "    def add_categorical_features(self,cat_features):\n",
    "        self.cat_features += cat_features\n",
    "        \n",
    "    def delete_categorical_features(self,cat_features):\n",
    "        self.cat_features = [col for col in self.cat_features if col not in cat_features]\n",
    "        \n",
    "    def add_segment_features(self,segment_features):\n",
    "        self.seg_features = ['segment']\n",
    "        self.cat_features = [col for col in self.cat_features if col not in segment_features]\n",
    "        \n",
    "    def fit(self,data):\n",
    "        if (len(self.seg_features)>0) & ('segment' not in data.columns):\n",
    "            raise ValueError(\"segment column name must be 'segment'\")\n",
    "        self.target_feature = ['가격']\n",
    "        self.unuse_features = ['ID']\n",
    "        self.dummy_features = ['압축천연가스(CNG)','액화석유가스(LPG)','경유','가솔린','하이브리드']\n",
    "        self.num_features   = [col for col in data.columns\n",
    "                               if col not in self.target_feature+self.unuse_features+self.dummy_features+self.cat_features+self.seg_features]\n",
    "        \n",
    "    def transform(self,data):\n",
    "        d = data.copy()\n",
    "        for col in self.dummy_features:\n",
    "            if d[col].dtypes!=int:\n",
    "                d[col] = d[col].astype(int)\n",
    "        for col in self.cat_features:\n",
    "            if d[col].dtypes!=object:\n",
    "                d[col] = d[col].astype(str)\n",
    "        for col in self.num_features:\n",
    "            if d[col].dtypes!=float:\n",
    "                d[col] = d[col].astype(float)\n",
    "        for col in self.seg_features:\n",
    "            if d[col].dtypes!=object:\n",
    "                d[col] = d[col].astype(str)\n",
    "        for col in self.unuse_features:\n",
    "            if col in d.columns:\n",
    "                d.drop(col,axis=1,inplace=True)\n",
    "        return d\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    def get_feature_type(self):\n",
    "        globals()['target_feature'] = self.target_feature\n",
    "        globals()['unuse_features'] = self.unuse_features\n",
    "        globals()['dummy_features'] = self.dummy_features\n",
    "        globals()['cat_features']   = self.cat_features\n",
    "        globals()['num_features']   = self.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5177c8-be0f-4363-8ec8-8849f4531ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_resetor = TypeResetting()\n",
    "type_resetor.fit(train_df)\n",
    "type_resetor.get_feature_type()\n",
    "\n",
    "train_df2 = type_resetor.transform(train_df)\n",
    "test_df2  = type_resetor.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9166d7-d880-4117-a2da-9422f62428ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"always\")\n",
    "\n",
    "def check_only_oneside(train,test,cat_features):\n",
    "    not_test_only_features = []\n",
    "    for iter,col in enumerate(cat_features):\n",
    "        print('[{}/{}] {}'.format(iter+1,len(cat_features),col))\n",
    "        \n",
    "        only_train = list(set(train[col].unique())-set(test[col].unique()))\n",
    "        only_test  = list(set(test[col].unique())-set(train[col].unique()))\n",
    "        print(' - Only Train:',len(only_train))\n",
    "        print(' - Only Test :',len(only_test))\n",
    "        if len(only_test)>0:\n",
    "            print('******Warning******')\n",
    "        else:\n",
    "            not_test_only_features.append(col)\n",
    "        print('')\n",
    "    return not_test_only_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8c40f7-1201-4598-9558-d086e9ab1575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/11] 브랜드\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[2/11] 차량모델명\n",
      " - Only Train: 2\n",
      " - Only Test : 0\n",
      "\n",
      "[3/11] 판매도시\n",
      " - Only Train: 1750\n",
      " - Only Test : 300\n",
      "******Warning******\n",
      "\n",
      "[4/11] 판매구역\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[5/11] 생산년도\n",
      " - Only Train: 3\n",
      " - Only Test : 1\n",
      "******Warning******\n",
      "\n",
      "[6/11] 모델출시년도\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[7/11] 압축천연가스(CNG)\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[8/11] 액화석유가스(LPG)\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[9/11] 경유\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[10/11] 가솔린\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[11/11] 하이브리드\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 브랜드, 차량모델명, 판매구역, 모델출시년도\n",
    "not_test_only_features = check_only_oneside(train_df2,test_df2,cat_features+dummy_features)\n",
    "not_test_only_features = list(set(not_test_only_features)-set(dummy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba4fb877-5302-4a4d-8b79-7f5de66c6b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['모델출시년도', '브랜드', '판매구역', '차량모델명']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_test_only_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204816d7-af14-427d-bc50-32b876febd64",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5254fac-62ad-4ca8-98d9-0cc687d11af2",
   "metadata": {},
   "source": [
    "# New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae5c16b-cf03-4b32-894f-10ef35d8c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series([str(round(int(year)/100,1)) for year in train_df6['생산년도']]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1faf8654-f04e-43ed-be0a-965a18e71664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>생산년도</th>\n",
       "      <th>모델출시년도</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>차량모델명</th>\n",
       "      <th>판매도시</th>\n",
       "      <th>판매구역</th>\n",
       "      <th>주행거리</th>\n",
       "      <th>배기량</th>\n",
       "      <th>압축천연가스(CNG)</th>\n",
       "      <th>경유</th>\n",
       "      <th>가솔린</th>\n",
       "      <th>하이브리드</th>\n",
       "      <th>액화석유가스(LPG)</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2014</td>\n",
       "      <td>skoda</td>\n",
       "      <td>fabia</td>\n",
       "      <td>KAT</td>\n",
       "      <td>SLA</td>\n",
       "      <td>85231.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.946231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>toyota</td>\n",
       "      <td>auris</td>\n",
       "      <td>RKO</td>\n",
       "      <td>SWI</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.724970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>clk-klasa</td>\n",
       "      <td>GNI</td>\n",
       "      <td>WIE</td>\n",
       "      <td>255223.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.879760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>nissan</td>\n",
       "      <td>x-trail</td>\n",
       "      <td>EHX</td>\n",
       "      <td>WIE</td>\n",
       "      <td>238000.0</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.901422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>fiat</td>\n",
       "      <td>bravo</td>\n",
       "      <td>OSW</td>\n",
       "      <td>MAL</td>\n",
       "      <td>251000.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.865054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   생산년도 모델출시년도            브랜드      차량모델명 판매도시 판매구역      주행거리     배기량  \\\n",
       "0  2018   2014          skoda      fabia  KAT  SLA   85231.0   999.0   \n",
       "1  2010   2006         toyota      auris  RKO  SWI  135000.0  1598.0   \n",
       "2  2002   2002  mercedes-benz  clk-klasa  GNI  WIE  255223.0  1796.0   \n",
       "3  2006   2001         nissan    x-trail  EHX  WIE  238000.0  2184.0   \n",
       "4  2007   2007           fiat      bravo  OSW  MAL  251000.0  1910.0   \n",
       "\n",
       "   압축천연가스(CNG)  경유  가솔린  하이브리드  액화석유가스(LPG)        가격  \n",
       "0            0   0    1      0            0  3.946231  \n",
       "1            0   0    1      0            0  3.724970  \n",
       "2            0   0    1      0            0  2.879760  \n",
       "3            0   1    0      0            0  2.901422  \n",
       "4            0   1    0      0            0  2.865054  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6541725-7cf0-4e7d-960b-cb96da805e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import chain, combinations\n",
    "def all_subsets(ss):\n",
    "    return list(chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1))))\n",
    "\n",
    "class FeatureEngineering:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _get_quantile(self,x,col):\n",
    "        x = np.array(x).flatten()\n",
    "        x = x[pd.notnull(x)]\n",
    "\n",
    "        agg_df = pd.DataFrame(index=[0])\n",
    "        for q in [0,25,50,75,100]:\n",
    "            agg_df[f'{col}_Q{q}'] = np.quantile(x,q/100)\n",
    "\n",
    "        return agg_df\n",
    "    \n",
    "    def _derived_features(self,data):\n",
    "        d = data.copy()\n",
    "\n",
    "        # (1) 모델출시년도에 생산된 차량인지\n",
    "        d['출시년도생산여부'] = np.where(d['생산년도'].astype(int)==d['모델출시년도'].astype(int),1,0)\n",
    "\n",
    "        # (2) 모델출시 이후에 몇년 지나서 생산됬는지\n",
    "        d['출시이후생산년수'] = d['생산년도'].astype(int)-d['모델출시년도'].astype(int)\n",
    "\n",
    "        # (3) 출시 이전에 생산되었는지\n",
    "        d['출시이전생산여부'] = np.where(d['출시이후생산년수']<0,1,0)\n",
    "\n",
    "        # (4) 브랜드의 국적 (구글링)\n",
    "        d['브랜드국적'] = ['체코' if brand=='skoda' else\n",
    "                        '일본' if brand in ['toyota','nissan','mazda','honda','mitsubishi'] else\n",
    "                        '독일' if brand in ['mercedes-benz','audi','volkswagen','bmw','opel'] else\n",
    "                        '이탈리아' if brand=='fiat' else\n",
    "                        '프랑스' if brand in ['renault','citroen','peugeot'] else\n",
    "                        '미국' if brand=='ford' else\n",
    "                        '한국' if brand in ['kia','hyundai'] else\n",
    "                        '스페인' if brand=='seat' else\n",
    "                        '스웨덴' if brand=='volvo' else\n",
    "                        np.nan for brand in d['브랜드']]\n",
    "\n",
    "        # (5) 브랜드 국적의 대륙명\n",
    "        d['브랜드대륙명'] = ['유럽' if country in ['체코','독일','이탈리아','프랑스','스페인','스웨덴'] else\n",
    "                          '아시아' if country in ['일본','한국'] else\n",
    "                          '아메리카' if country in ['미국'] else\n",
    "                          np.nan for country in d['브랜드국적']]\n",
    "        \n",
    "        # (6) 판매도시,판매구역 동일여부\n",
    "        d['판매도시구역동일여부'] = np.where(d['판매도시']==d['판매구역'],1,0)\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    def fit(self,data,cat_features,subset_depth=1):\n",
    "        assert '가격' in data.columns, \\\n",
    "            'Input data must be training dataset'\n",
    "        assert len(cat_features)>=subset_depth, \\\n",
    "            'len(cat_features) >= subset_depth'\n",
    "        \n",
    "        self.cat_features = cat_features\n",
    "        self.new_cat_features = ['출시년도생산여부','출시이후생산년수','출시이전생산여부','브랜드국적','브랜드대륙명','판매도시구역동일여부']\n",
    "        \n",
    "        # (6) 카테고리 변수에 따른 가격의 Quantile값\n",
    "        all_subset_list = all_subsets(cat_features)\n",
    "        all_subset_list = [subset for subset in all_subset_list if (len(subset)<=subset_depth) & (len(subset)>=1)]\n",
    "        \n",
    "        self.agg_dict = {}\n",
    "        for subset in tqdm(all_subset_list,desc=f'Get quantiles of target by categorical features (depth={subset_depth})'):\n",
    "            subset = list(subset)\n",
    "            subset_name = '_'.join(subset)\n",
    "            agg_fn = data.groupby(subset)['가격'].apply(lambda x: self._get_quantile(x,subset_name)).reset_index()\n",
    "            drop_cols = [col for col in agg_fn if col.find('level_')>=0]\n",
    "            agg_fn.drop(columns=drop_cols,inplace=True)\n",
    "            self.agg_dict[subset_name] = agg_fn\n",
    "            \n",
    "    def transform(self,data):\n",
    "        data = self._derived_features(data)\n",
    "        for key,agg_fn in self.agg_dict.items():\n",
    "            data = pd.merge(data,agg_fn,how='left',on=key.split('_'))\n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self,data,cat_features,subset_depth=1):\n",
    "        self.fit(data,cat_features,subset_depth)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a085347-abaa-4e5f-9f9b-f71f226bf84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get quantiles of target by categorical features (depth=1): 100%|██████████| 4/4 [00:00<00:00, 12.45it/s]\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineering()\n",
    "fe.fit(\n",
    "    data=train_df2,\n",
    "    cat_features=not_test_only_features, \n",
    "    subset_depth=CFG.SUBSET_DEPTH,\n",
    ")\n",
    "train_df3 = fe.transform(train_df2)\n",
    "test_df3  = fe.transform(test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a29021d0-ce57-42c8-8a78-0f9cc4209d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['출시년도생산여부', '출시이후생산년수', '출시이전생산여부', '브랜드국적', '브랜드대륙명', '판매도시구역동일여부']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.new_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa09b13-62ca-425d-bab5-299828454fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_resetor = TypeResetting()\n",
    "type_resetor.add_categorical_features(fe.new_cat_features)\n",
    "type_resetor.fit(train_df3)\n",
    "type_resetor.get_feature_type()\n",
    "\n",
    "train_df3 = type_resetor.transform(train_df3)\n",
    "test_df3  = type_resetor.transform(test_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af8e5c65-95f9-4a32-b63d-c074537853de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57920, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>생산년도</th>\n",
       "      <th>모델출시년도</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>차량모델명</th>\n",
       "      <th>판매도시</th>\n",
       "      <th>판매구역</th>\n",
       "      <th>주행거리</th>\n",
       "      <th>배기량</th>\n",
       "      <th>압축천연가스(CNG)</th>\n",
       "      <th>경유</th>\n",
       "      <th>가솔린</th>\n",
       "      <th>하이브리드</th>\n",
       "      <th>액화석유가스(LPG)</th>\n",
       "      <th>가격</th>\n",
       "      <th>출시년도생산여부</th>\n",
       "      <th>출시이후생산년수</th>\n",
       "      <th>출시이전생산여부</th>\n",
       "      <th>브랜드국적</th>\n",
       "      <th>브랜드대륙명</th>\n",
       "      <th>판매도시구역동일여부</th>\n",
       "      <th>모델출시년도_Q0</th>\n",
       "      <th>모델출시년도_Q25</th>\n",
       "      <th>모델출시년도_Q50</th>\n",
       "      <th>모델출시년도_Q75</th>\n",
       "      <th>모델출시년도_Q100</th>\n",
       "      <th>브랜드_Q0</th>\n",
       "      <th>브랜드_Q25</th>\n",
       "      <th>브랜드_Q50</th>\n",
       "      <th>브랜드_Q75</th>\n",
       "      <th>브랜드_Q100</th>\n",
       "      <th>판매구역_Q0</th>\n",
       "      <th>판매구역_Q25</th>\n",
       "      <th>판매구역_Q50</th>\n",
       "      <th>판매구역_Q75</th>\n",
       "      <th>판매구역_Q100</th>\n",
       "      <th>차량모델명_Q0</th>\n",
       "      <th>차량모델명_Q25</th>\n",
       "      <th>차량모델명_Q50</th>\n",
       "      <th>차량모델명_Q75</th>\n",
       "      <th>차량모델명_Q100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2014</td>\n",
       "      <td>skoda</td>\n",
       "      <td>fabia</td>\n",
       "      <td>KAT</td>\n",
       "      <td>SLA</td>\n",
       "      <td>85231.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.946231</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>체코</td>\n",
       "      <td>유럽</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>4.019486</td>\n",
       "      <td>4.355041</td>\n",
       "      <td>4.643140</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.727549</td>\n",
       "      <td>3.393501</td>\n",
       "      <td>4.057853</td>\n",
       "      <td>4.509072</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.262364</td>\n",
       "      <td>3.206803</td>\n",
       "      <td>3.773910</td>\n",
       "      <td>4.355041</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.792993</td>\n",
       "      <td>2.933059</td>\n",
       "      <td>3.712352</td>\n",
       "      <td>4.065687</td>\n",
       "      <td>4.830312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>toyota</td>\n",
       "      <td>auris</td>\n",
       "      <td>RKO</td>\n",
       "      <td>SWI</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.724970</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>일본</td>\n",
       "      <td>아시아</td>\n",
       "      <td>0</td>\n",
       "      <td>1.358409</td>\n",
       "      <td>3.089678</td>\n",
       "      <td>3.348851</td>\n",
       "      <td>3.785779</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>3.353407</td>\n",
       "      <td>4.000034</td>\n",
       "      <td>4.435212</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>1.095273</td>\n",
       "      <td>3.113071</td>\n",
       "      <td>3.520461</td>\n",
       "      <td>4.066802</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.687167</td>\n",
       "      <td>3.594569</td>\n",
       "      <td>4.112512</td>\n",
       "      <td>4.387075</td>\n",
       "      <td>4.761062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>clk-klasa</td>\n",
       "      <td>GNI</td>\n",
       "      <td>WIE</td>\n",
       "      <td>255223.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.879760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>독일</td>\n",
       "      <td>유럽</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>2.453588</td>\n",
       "      <td>2.826722</td>\n",
       "      <td>3.353407</td>\n",
       "      <td>5.049022</td>\n",
       "      <td>1.095273</td>\n",
       "      <td>3.152736</td>\n",
       "      <td>3.785779</td>\n",
       "      <td>4.354655</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.482426</td>\n",
       "      <td>3.089678</td>\n",
       "      <td>3.707577</td>\n",
       "      <td>4.296605</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.250239</td>\n",
       "      <td>3.147165</td>\n",
       "      <td>3.440418</td>\n",
       "      <td>3.627069</td>\n",
       "      <td>4.866534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>nissan</td>\n",
       "      <td>x-trail</td>\n",
       "      <td>EHX</td>\n",
       "      <td>WIE</td>\n",
       "      <td>238000.0</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.901422</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>일본</td>\n",
       "      <td>아시아</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>2.341806</td>\n",
       "      <td>2.738903</td>\n",
       "      <td>3.095125</td>\n",
       "      <td>4.886356</td>\n",
       "      <td>1.050822</td>\n",
       "      <td>3.558201</td>\n",
       "      <td>3.923359</td>\n",
       "      <td>4.405499</td>\n",
       "      <td>5.049022</td>\n",
       "      <td>0.482426</td>\n",
       "      <td>3.089678</td>\n",
       "      <td>3.707577</td>\n",
       "      <td>4.296605</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.164472</td>\n",
       "      <td>4.368303</td>\n",
       "      <td>4.575844</td>\n",
       "      <td>4.761062</td>\n",
       "      <td>5.049022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>fiat</td>\n",
       "      <td>bravo</td>\n",
       "      <td>OSW</td>\n",
       "      <td>MAL</td>\n",
       "      <td>251000.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.865054</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>이탈리아</td>\n",
       "      <td>유럽</td>\n",
       "      <td>0</td>\n",
       "      <td>1.697449</td>\n",
       "      <td>3.249210</td>\n",
       "      <td>3.626206</td>\n",
       "      <td>3.948741</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>1.111858</td>\n",
       "      <td>2.865054</td>\n",
       "      <td>3.529985</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>4.969049</td>\n",
       "      <td>0.732368</td>\n",
       "      <td>3.201526</td>\n",
       "      <td>3.755837</td>\n",
       "      <td>4.305416</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.134166</td>\n",
       "      <td>2.894253</td>\n",
       "      <td>3.065725</td>\n",
       "      <td>3.210720</td>\n",
       "      <td>3.660223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   생산년도 모델출시년도            브랜드      차량모델명 판매도시 판매구역      주행거리     배기량  \\\n",
       "0  2018   2014          skoda      fabia  KAT  SLA   85231.0   999.0   \n",
       "1  2010   2006         toyota      auris  RKO  SWI  135000.0  1598.0   \n",
       "2  2002   2002  mercedes-benz  clk-klasa  GNI  WIE  255223.0  1796.0   \n",
       "3  2006   2001         nissan    x-trail  EHX  WIE  238000.0  2184.0   \n",
       "4  2007   2007           fiat      bravo  OSW  MAL  251000.0  1910.0   \n",
       "\n",
       "   압축천연가스(CNG)  경유  가솔린  하이브리드  액화석유가스(LPG)        가격 출시년도생산여부 출시이후생산년수  \\\n",
       "0            0   0    1      0            0  3.946231        0        4   \n",
       "1            0   0    1      0            0  3.724970        0        4   \n",
       "2            0   0    1      0            0  2.879760        1        0   \n",
       "3            0   1    0      0            0  2.901422        0        5   \n",
       "4            0   1    0      0            0  2.865054        1        0   \n",
       "\n",
       "  출시이전생산여부 브랜드국적 브랜드대륙명 판매도시구역동일여부  모델출시년도_Q0  모델출시년도_Q25  모델출시년도_Q50  \\\n",
       "0        0    체코     유럽          0   0.157004    4.019486    4.355041   \n",
       "1        0    일본    아시아          0   1.358409    3.089678    3.348851   \n",
       "2        0    독일     유럽          0   0.955511    2.453588    2.826722   \n",
       "3        0    일본    아시아          0   0.955511    2.341806    2.738903   \n",
       "4        0  이탈리아     유럽          0   1.697449    3.249210    3.626206   \n",
       "\n",
       "   모델출시년도_Q75  모델출시년도_Q100    브랜드_Q0   브랜드_Q25   브랜드_Q50   브랜드_Q75  브랜드_Q100  \\\n",
       "0    4.643140     5.049856  0.727549  3.393501  4.057853  4.509072  5.049856   \n",
       "1    3.785779     5.049856  0.157004  3.353407  4.000034  4.435212  5.049856   \n",
       "2    3.353407     5.049022  1.095273  3.152736  3.785779  4.354655  5.049856   \n",
       "3    3.095125     4.886356  1.050822  3.558201  3.923359  4.405499  5.049022   \n",
       "4    3.948741     5.049856  1.111858  2.865054  3.529985  4.174387  4.969049   \n",
       "\n",
       "    판매구역_Q0  판매구역_Q25  판매구역_Q50  판매구역_Q75  판매구역_Q100  차량모델명_Q0  차량모델명_Q25  \\\n",
       "0  0.262364  3.206803  3.773910  4.355041   5.049856  0.792993   2.933059   \n",
       "1  1.095273  3.113071  3.520461  4.066802   5.049856  2.687167   3.594569   \n",
       "2  0.482426  3.089678  3.707577  4.296605   5.049856  2.250239   3.147165   \n",
       "3  0.482426  3.089678  3.707577  4.296605   5.049856  2.164472   4.368303   \n",
       "4  0.732368  3.201526  3.755837  4.305416   5.049856  2.134166   2.894253   \n",
       "\n",
       "   차량모델명_Q50  차량모델명_Q75  차량모델명_Q100  \n",
       "0   3.712352   4.065687    4.830312  \n",
       "1   4.112512   4.387075    4.761062  \n",
       "2   3.440418   3.627069    4.866534  \n",
       "3   4.575844   4.761062    5.049022  \n",
       "4   3.065725   3.210720    3.660223  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df3.shape)\n",
    "train_df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65939305-7703-474a-912d-3841f3eed25d",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f1466-3f68-43ec-a104-181930321dce",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d1e3686-4ea5-4147-a968-4dc93785c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_num_features = [col for col in num_features if col.find('_Q')<0]\n",
    "\n",
    "# i=0\n",
    "# for col in check_num_features:\n",
    "#     i+=1\n",
    "#     print('\\n({}/{}) {}'.format(i,len(check_num_features),col))\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.scatterplot(x=train_df3['가격'],y=train_df3[col])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920fd41-52ab-4de1-82a4-d9a5b28a4346",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6171ab-e115-43a0-906e-ea644ee74b86",
   "metadata": {},
   "source": [
    "# Add the Interaction Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c35453f-0aae-4d1c-b034-f47a24ec1798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import trange\n",
    "\n",
    "def get_abs_corr(x,y):\n",
    "    return np.abs(np.corrcoef(x,y))[0,1]\n",
    "\n",
    "class InteractionTerm:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,num_features,corr_cutoff=0.7):\n",
    "        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "        \n",
    "        d = data.copy()\n",
    "        self.interaction_list = []\n",
    "        for i in range(len(num_features)):\n",
    "            for j in range(len(num_features)):\n",
    "                if i>j:\n",
    "                    col_i = num_features[i]\n",
    "                    col_j = num_features[j]\n",
    "                    \n",
    "                    # 상관계수가 cutoff보다 큰 경우에는 interaction을 생성하지 않음\n",
    "                    if (get_abs_corr(d[col_i]*d[col_j],d[col_i])>=corr_cutoff) | (get_abs_corr(d[col_i]*d[col_j],d[col_j])>=corr_cutoff):\n",
    "                        pass\n",
    "                    else:\n",
    "                        self.interaction_list.append(f'{col_i}*{col_j}')\n",
    "    \n",
    "    def transform(self,data):\n",
    "        d = data.copy()\n",
    "        for interaction in self.interaction_list:\n",
    "            col_i,col_j = interaction.split('*')\n",
    "            d[interaction] = d[col_i]*d[col_j]\n",
    "        return d\n",
    "    \n",
    "    def fit_transform(self,data,num_features,corr_cutoff=0.7):\n",
    "        self.fit(data,num_features,corr_cutoff)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e973e0f2-e229-493c-9ad0-a42c086a35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4 = train_df3.copy()\n",
    "test_df4  = test_df3.copy()\n",
    "\n",
    "if CFG.INTERACTION:\n",
    "    interaction_maker = InteractionTerm()\n",
    "    interaction_maker.fit(\n",
    "        data=train_df3,\n",
    "        num_features=num_features,\n",
    "        corr_cutoff=0.9,\n",
    "    )\n",
    "    train_df4 = interaction_maker.transform(train_df4)\n",
    "    test_df4  = interaction_maker.transform(test_df4)\n",
    "\n",
    "    type_resetor = TypeResetting()\n",
    "    type_resetor.add_categorical_features(fe.new_cat_features)\n",
    "    type_resetor.fit(train_df4)\n",
    "    type_resetor.get_feature_type()\n",
    "\n",
    "    train_df4 = type_resetor.transform(train_df4)\n",
    "    test_df4  = type_resetor.transform(test_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd2f299d-97bc-4968-8415-7ef80b21221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF: 5.263\n"
     ]
    }
   ],
   "source": [
    "print('VIF: {:.3f}'.format(1/(1-0.9**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad8c2866-1fcf-4f62-8313-4f4b16d58c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57920, 40), (57920, 78))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df3.shape, train_df4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3732aa9-e9d7-41d5-8e8c-667699fe5a30",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec950f8-0d43-4b9a-97ed-6feac553dba3",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "880a07b7-5116-410a-a6d0-0d2c50b151b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=0\n",
    "# for i in range(len(num_features)):\n",
    "#     for j in range(len(num_features)):\n",
    "#         if i>j:\n",
    "#             col_i = num_features[i]\n",
    "#             col_j = num_features[j]\n",
    "#             corr = np.corrcoef(train_df4[col_i],train_df4[col_j])[0,1]\n",
    "#             if corr>=0.7:\n",
    "#                 k+=1\n",
    "#                 print(k,col_i,col_j,corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a38e1e0d-3c13-4c6e-81a1-9e18d0f05e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_offset(x):\n",
    "    if min(x)>0:\n",
    "        offset = 0\n",
    "    elif min(x)==0:\n",
    "        offset = 1e-3\n",
    "    else:\n",
    "        offset = min(x)+1e-3\n",
    "        print('minimum = {:.3f}'.format(min(x)))\n",
    "    return np.log(x+offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40318716-a92d-459a-9ff7-9c1d262a107d",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8304c3-426d-4a24-89cc-d3c76a5ea249",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6e1cc67-3282-47c3-ada7-8c7776443b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81d460ab-4868-423a-8f9c-08e0b456ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "check_cat_features = [col for col in cat_features if train_df4[col].nunique()<=100]\n",
    "\n",
    "# (1) ANOVA를 해서 p-value가 0.05보다 높은 것들 확인\n",
    "pvalue_list = []\n",
    "for col in tqdm(check_cat_features):\n",
    "    d = train_df4[[col,'가격']].rename(columns={col:'feature'})\n",
    "    \n",
    "    model = ols(f'가격 ~ C(feature)',data=d).fit()\n",
    "    pvalue = anova_lm(model).values[0][-1]\n",
    "    pvalue_list.append([col,pvalue])\n",
    "    \n",
    "pvalue_df = pd.DataFrame(pvalue_list,columns=['feature','pvalue'])\\\n",
    "    .sort_values('pvalue',ascending=False)\n",
    "# pvalue_df[pvalue_df.pvalue>=alpha].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90277925-192b-4514-beb0-675a1dddd086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# (2) (1)에서 유의하지않은 feature들은 log적용 후에도 유의하지 않으면 제외\n",
    "pvalue_list2 = []\n",
    "unsignificant_features = pvalue_df[pvalue_df.pvalue>CFG.FS_ALPHA].feature.tolist()\n",
    "for col in tqdm(unsignificant_features):\n",
    "    d = train_df4[[col,'target']].rename(columns={col:'feature'})\n",
    "    d['feature'] = log_offset(d['feature'])\n",
    "    \n",
    "    model = ols(f'feature ~ C(target)',data=d).fit()\n",
    "    pvalue = anova_lm(model).values[0][-1]\n",
    "    pvalue_list2.append([col,pvalue])\n",
    "    \n",
    "pvalue_df2 = pd.DataFrame(pvalue_list2,columns=['feature','pvalue'])\\\n",
    "    .sort_values('pvalue',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a33f82a-221e-4c73-a7e1-6edb0aec18f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> delete_features\n",
      "  - length : 0\n",
      "  - feature_name : []\n",
      "\n",
      "> log_features\n",
      "  - length : 0\n",
      "  - feature_name : []\n"
     ]
    }
   ],
   "source": [
    "delete_features = pvalue_df2[pvalue_df2.pvalue> CFG.FS_ALPHA].feature.tolist()\n",
    "log_features    = pvalue_df2[pvalue_df2.pvalue<=CFG.FS_ALPHA].feature.tolist()\n",
    "print('> delete_features')\n",
    "print('  - length : {}'.format(len(delete_features)))\n",
    "print('  - feature_name : {}'.format(delete_features))\n",
    "print('')\n",
    "print('> log_features')\n",
    "print('  - length : {}'.format(len(log_features)))\n",
    "print('  - feature_name : {}'.format(log_features))\n",
    "\n",
    "train_df5 = train_df4.copy()\n",
    "train_df5.drop(delete_features,axis=1,inplace=True)\n",
    "for col in log_features:\n",
    "    train_df5[col] = log_offset(train_df5[col])\n",
    "    \n",
    "test_df5 = test_df4.copy()\n",
    "test_df5.drop(delete_features,axis=1,inplace=True)\n",
    "for col in log_features:\n",
    "    test_df5[col] = log_offset(test_df5[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176ea54-23ec-469f-b732-88b6afcac30e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501bbc25-a915-4b50-9fb3-d6689c37a216",
   "metadata": {},
   "source": [
    "## Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbb2b20b-bb8e-4081-bdc8-0c121fadbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c13b45c5-3c59-404e-bb14-b023dad4705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) corr test를 해서 p-value가 0.05보다 높은 것들 확인\n",
    "pvalue_list = []\n",
    "for col in num_features:\n",
    "    corr,pvalue = scipy.stats.pearsonr(train_df5['가격'],train_df5[col])\n",
    "    pvalue_list.append([col,pvalue])\n",
    "pvalue_df = pd.DataFrame(pvalue_list,columns=['feature','pvalue'])\\\n",
    "    .sort_values('pvalue',ascending=False)\n",
    "# pvalue_df.round(4).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d178a263-70c2-4a52-9974-fa45e9dd5f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# (2) (1)에서 유의하지않은 feature들은 log적용 후에도 유의하지 않으면 제외\n",
    "pvalue_list2 = []\n",
    "unsignificant_features = pvalue_df[pvalue_df.pvalue>CFG.FS_ALPHA].feature.tolist()\n",
    "for col in tqdm(unsignificant_features):\n",
    "    corr,pvalue = scipy.stats.pearsonr(train_df5['가격'],log_offset(train_df5[col]))\n",
    "    pvalue_list2.append([col,pvalue])\n",
    "pvalue_df2 = pd.DataFrame(pvalue_list2,columns=['feature','pvalue'])\\\n",
    "    .sort_values('pvalue',ascending=False)\n",
    "# pvalue_df2.round(4).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc6bc35c-24f3-4e04-89ae-2a0c6db4deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> delete_features\n",
      "  - length : 0\n",
      "  - feature_name : []\n",
      "\n",
      "> log_features\n",
      "  - length : 0\n",
      "  - feature_name : []\n"
     ]
    }
   ],
   "source": [
    "delete_features = pvalue_df2[pvalue_df2.pvalue> CFG.FS_ALPHA].feature.tolist()\n",
    "log_features    = pvalue_df2[pvalue_df2.pvalue<=CFG.FS_ALPHA].feature.tolist()\n",
    "print('> delete_features')\n",
    "print('  - length : {}'.format(len(delete_features)))\n",
    "print('  - feature_name : {}'.format(delete_features))\n",
    "print('')\n",
    "print('> log_features')\n",
    "print('  - length : {}'.format(len(log_features)))\n",
    "print('  - feature_name : {}'.format(log_features))\n",
    "\n",
    "train_df6 = train_df5.copy()\n",
    "train_df6.drop(delete_features,axis=1,inplace=True)\n",
    "for col in log_features:\n",
    "    train_df6[col] = log_offset(train_df6[col])\n",
    "    \n",
    "test_df6 = test_df5.copy()\n",
    "test_df6.drop(delete_features,axis=1,inplace=True)\n",
    "for col in log_features:\n",
    "    test_df6[col] = log_offset(test_df6[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79601117-685e-475d-84b6-0706f876e338",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b9354-bcc6-448c-969a-e13259c63768",
   "metadata": {},
   "source": [
    "# Make Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79d59204-cd48-463d-9d66-f6cdeb958d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_segment(data,segment: list):\n",
    "    d = data.copy()\n",
    "    d['segment'] = d[segment].apply(lambda x: '___'.join(x),axis=1)\n",
    "    d.drop(columns=segment,inplace=True)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af98b30f-f615-4098-ad04-dc19a06e19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = ['브랜드']\n",
    "train_df7 = make_segment(train_df6,segment)\n",
    "test_df7  = make_segment(test_df6 ,segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5335ebd-d436-4ef0-aa8a-9652f0b42edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_only = list(set(test_df7.segment.unique())-set(train_df7.segment.unique()))\n",
    "assert len(test_only)==0, \\\n",
    "    \"Segment exists only in the test set ({})\".format(len(test_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22f864e5-c30e-41e1-b3bf-45e6a561dcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Train에만 존재하는 Segment 제거\n",
      " - 데이터수 : 57,920 -> 57,920\n",
      " - 세그먼트수 : 20\n"
     ]
    }
   ],
   "source": [
    "train_only = list(set(train_df7['segment'].unique())-set(test_df7['segment'].unique()))\n",
    "\n",
    "n_asis = len(train_df7)\n",
    "n_tobe = len(train_df7[~train_df7.segment.isin(train_only)])\n",
    "train_df7 = train_df7[~train_df7.segment.isin(train_only)]\n",
    "print('> Train에만 존재하는 Segment 제거')\n",
    "print(' - 데이터수 : {:,} -> {:,}'.format(n_asis,n_tobe))\n",
    "print(' - 세그먼트수 : {:,}'.format(train_df7['segment'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4579bed8-088d-46c0-b69a-72cad7028995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment\n",
       "mitsubishi     556\n",
       "peugeot        793\n",
       "citroen       1129\n",
       "fiat          1164\n",
       "volvo         1352\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "segment\n",
       "bmw           5262\n",
       "audi          5597\n",
       "volkswagen    5693\n",
       "ford          5819\n",
       "opel          6651\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vc = train_df7['segment'].value_counts().sort_values()\n",
    "display(vc.head())\n",
    "print('...')\n",
    "display(vc.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "caffe72a-8ac5-4cb9-81c6-8a778faa2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_resetor = TypeResetting()\n",
    "type_resetor.add_categorical_features(fe.new_cat_features)\n",
    "type_resetor.add_segment_features(segment)\n",
    "type_resetor.fit(train_df7)\n",
    "type_resetor.get_feature_type()\n",
    "\n",
    "train_df7 = type_resetor.transform(train_df7)\n",
    "test_df7  = type_resetor.transform(test_df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b6938ef-7438-4e29-9b63-f8b45ae27180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['차량모델명',\n",
       " '판매도시',\n",
       " '판매구역',\n",
       " '생산년도',\n",
       " '모델출시년도',\n",
       " '출시년도생산여부',\n",
       " '출시이후생산년수',\n",
       " '출시이전생산여부',\n",
       " '브랜드국적',\n",
       " '브랜드대륙명',\n",
       " '판매도시구역동일여부']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea57f4f5-bdd5-41f9-a2ea-832514b6bc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57920, 78)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>생산년도</th>\n",
       "      <th>모델출시년도</th>\n",
       "      <th>차량모델명</th>\n",
       "      <th>판매도시</th>\n",
       "      <th>판매구역</th>\n",
       "      <th>주행거리</th>\n",
       "      <th>배기량</th>\n",
       "      <th>압축천연가스(CNG)</th>\n",
       "      <th>경유</th>\n",
       "      <th>가솔린</th>\n",
       "      <th>하이브리드</th>\n",
       "      <th>액화석유가스(LPG)</th>\n",
       "      <th>가격</th>\n",
       "      <th>출시년도생산여부</th>\n",
       "      <th>출시이후생산년수</th>\n",
       "      <th>출시이전생산여부</th>\n",
       "      <th>브랜드국적</th>\n",
       "      <th>브랜드대륙명</th>\n",
       "      <th>판매도시구역동일여부</th>\n",
       "      <th>모델출시년도_Q0</th>\n",
       "      <th>모델출시년도_Q25</th>\n",
       "      <th>모델출시년도_Q50</th>\n",
       "      <th>모델출시년도_Q75</th>\n",
       "      <th>모델출시년도_Q100</th>\n",
       "      <th>브랜드_Q0</th>\n",
       "      <th>브랜드_Q25</th>\n",
       "      <th>브랜드_Q50</th>\n",
       "      <th>브랜드_Q75</th>\n",
       "      <th>브랜드_Q100</th>\n",
       "      <th>판매구역_Q0</th>\n",
       "      <th>판매구역_Q25</th>\n",
       "      <th>판매구역_Q50</th>\n",
       "      <th>판매구역_Q75</th>\n",
       "      <th>판매구역_Q100</th>\n",
       "      <th>차량모델명_Q0</th>\n",
       "      <th>차량모델명_Q25</th>\n",
       "      <th>차량모델명_Q50</th>\n",
       "      <th>차량모델명_Q75</th>\n",
       "      <th>차량모델명_Q100</th>\n",
       "      <th>배기량*주행거리</th>\n",
       "      <th>모델출시년도_Q0*주행거리</th>\n",
       "      <th>모델출시년도_Q0*배기량</th>\n",
       "      <th>모델출시년도_Q25*배기량</th>\n",
       "      <th>모델출시년도_Q50*배기량</th>\n",
       "      <th>모델출시년도_Q75*배기량</th>\n",
       "      <th>브랜드_Q0*주행거리</th>\n",
       "      <th>브랜드_Q0*배기량</th>\n",
       "      <th>브랜드_Q0*모델출시년도_Q0</th>\n",
       "      <th>브랜드_Q75*모델출시년도_Q100</th>\n",
       "      <th>판매구역_Q0*주행거리</th>\n",
       "      <th>판매구역_Q0*배기량</th>\n",
       "      <th>판매구역_Q0*모델출시년도_Q0</th>\n",
       "      <th>판매구역_Q0*모델출시년도_Q25</th>\n",
       "      <th>판매구역_Q0*브랜드_Q0</th>\n",
       "      <th>판매구역_Q25*모델출시년도_Q100</th>\n",
       "      <th>판매구역_Q25*브랜드_Q50</th>\n",
       "      <th>판매구역_Q25*브랜드_Q75</th>\n",
       "      <th>판매구역_Q50*모델출시년도_Q100</th>\n",
       "      <th>판매구역_Q50*브랜드_Q50</th>\n",
       "      <th>판매구역_Q50*브랜드_Q75</th>\n",
       "      <th>판매구역_Q75*모델출시년도_Q100</th>\n",
       "      <th>차량모델명_Q0*주행거리</th>\n",
       "      <th>차량모델명_Q0*배기량</th>\n",
       "      <th>차량모델명_Q0*모델출시년도_Q0</th>\n",
       "      <th>차량모델명_Q0*브랜드_Q0</th>\n",
       "      <th>차량모델명_Q0*판매구역_Q0</th>\n",
       "      <th>차량모델명_Q25*모델출시년도_Q25</th>\n",
       "      <th>차량모델명_Q25*모델출시년도_Q50</th>\n",
       "      <th>차량모델명_Q25*모델출시년도_Q75</th>\n",
       "      <th>차량모델명_Q50*모델출시년도_Q50</th>\n",
       "      <th>차량모델명_Q50*모델출시년도_Q75</th>\n",
       "      <th>차량모델명_Q75*모델출시년도_Q75</th>\n",
       "      <th>차량모델명_Q75*브랜드_Q25</th>\n",
       "      <th>차량모델명_Q100*브랜드_Q25</th>\n",
       "      <th>차량모델명_Q100*브랜드_Q50</th>\n",
       "      <th>차량모델명_Q100*브랜드_Q75</th>\n",
       "      <th>차량모델명_Q100*판매구역_Q25</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2014</td>\n",
       "      <td>fabia</td>\n",
       "      <td>KAT</td>\n",
       "      <td>SLA</td>\n",
       "      <td>85231.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.946231</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>체코</td>\n",
       "      <td>유럽</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>4.019486</td>\n",
       "      <td>4.355041</td>\n",
       "      <td>4.643140</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.727549</td>\n",
       "      <td>3.393501</td>\n",
       "      <td>4.057853</td>\n",
       "      <td>4.509072</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.262364</td>\n",
       "      <td>3.206803</td>\n",
       "      <td>3.773910</td>\n",
       "      <td>4.355041</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.792993</td>\n",
       "      <td>2.933059</td>\n",
       "      <td>3.712352</td>\n",
       "      <td>4.065687</td>\n",
       "      <td>4.830312</td>\n",
       "      <td>85145769.0</td>\n",
       "      <td>13381.586515</td>\n",
       "      <td>156.846745</td>\n",
       "      <td>4015.466312</td>\n",
       "      <td>4350.685729</td>\n",
       "      <td>4638.496977</td>\n",
       "      <td>62009.695347</td>\n",
       "      <td>726.821059</td>\n",
       "      <td>0.114228</td>\n",
       "      <td>22.770164</td>\n",
       "      <td>22361.568625</td>\n",
       "      <td>262.101900</td>\n",
       "      <td>0.041192</td>\n",
       "      <td>1.054569</td>\n",
       "      <td>0.190883</td>\n",
       "      <td>16.193895</td>\n",
       "      <td>13.012738</td>\n",
       "      <td>14.459707</td>\n",
       "      <td>19.057701</td>\n",
       "      <td>15.313973</td>\n",
       "      <td>17.016831</td>\n",
       "      <td>21.992329</td>\n",
       "      <td>67587.545091</td>\n",
       "      <td>792.199523</td>\n",
       "      <td>0.124503</td>\n",
       "      <td>0.576941</td>\n",
       "      <td>0.208053</td>\n",
       "      <td>11.789388</td>\n",
       "      <td>12.773590</td>\n",
       "      <td>13.618602</td>\n",
       "      <td>16.167443</td>\n",
       "      <td>17.236970</td>\n",
       "      <td>18.877555</td>\n",
       "      <td>13.796914</td>\n",
       "      <td>16.391669</td>\n",
       "      <td>19.600697</td>\n",
       "      <td>21.780223</td>\n",
       "      <td>15.489859</td>\n",
       "      <td>skoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>auris</td>\n",
       "      <td>RKO</td>\n",
       "      <td>SWI</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.724970</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>일본</td>\n",
       "      <td>아시아</td>\n",
       "      <td>0</td>\n",
       "      <td>1.358409</td>\n",
       "      <td>3.089678</td>\n",
       "      <td>3.348851</td>\n",
       "      <td>3.785779</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>3.353407</td>\n",
       "      <td>4.000034</td>\n",
       "      <td>4.435212</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>1.095273</td>\n",
       "      <td>3.113071</td>\n",
       "      <td>3.520461</td>\n",
       "      <td>4.066802</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.687167</td>\n",
       "      <td>3.594569</td>\n",
       "      <td>4.112512</td>\n",
       "      <td>4.387075</td>\n",
       "      <td>4.761062</td>\n",
       "      <td>215730000.0</td>\n",
       "      <td>183385.236280</td>\n",
       "      <td>2170.737834</td>\n",
       "      <td>4937.305262</td>\n",
       "      <td>5351.463740</td>\n",
       "      <td>6049.675288</td>\n",
       "      <td>21195.506089</td>\n",
       "      <td>250.891991</td>\n",
       "      <td>0.213275</td>\n",
       "      <td>22.397181</td>\n",
       "      <td>147861.907299</td>\n",
       "      <td>1750.246873</td>\n",
       "      <td>1.487829</td>\n",
       "      <td>3.384042</td>\n",
       "      <td>0.171962</td>\n",
       "      <td>15.720559</td>\n",
       "      <td>12.452389</td>\n",
       "      <td>13.807128</td>\n",
       "      <td>17.777820</td>\n",
       "      <td>14.081962</td>\n",
       "      <td>15.613990</td>\n",
       "      <td>20.536765</td>\n",
       "      <td>362767.543675</td>\n",
       "      <td>4294.092850</td>\n",
       "      <td>3.650272</td>\n",
       "      <td>0.421895</td>\n",
       "      <td>2.943182</td>\n",
       "      <td>11.106060</td>\n",
       "      <td>12.037675</td>\n",
       "      <td>13.608244</td>\n",
       "      <td>13.772189</td>\n",
       "      <td>15.569062</td>\n",
       "      <td>16.608499</td>\n",
       "      <td>14.711648</td>\n",
       "      <td>15.965778</td>\n",
       "      <td>19.044410</td>\n",
       "      <td>21.116320</td>\n",
       "      <td>14.821524</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>clk-klasa</td>\n",
       "      <td>GNI</td>\n",
       "      <td>WIE</td>\n",
       "      <td>255223.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.879760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>독일</td>\n",
       "      <td>유럽</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>2.453588</td>\n",
       "      <td>2.826722</td>\n",
       "      <td>3.353407</td>\n",
       "      <td>5.049022</td>\n",
       "      <td>1.095273</td>\n",
       "      <td>3.152736</td>\n",
       "      <td>3.785779</td>\n",
       "      <td>4.354655</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.482426</td>\n",
       "      <td>3.089678</td>\n",
       "      <td>3.707577</td>\n",
       "      <td>4.296605</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.250239</td>\n",
       "      <td>3.147165</td>\n",
       "      <td>3.440418</td>\n",
       "      <td>3.627069</td>\n",
       "      <td>4.866534</td>\n",
       "      <td>458380508.0</td>\n",
       "      <td>243868.497534</td>\n",
       "      <td>1716.098555</td>\n",
       "      <td>4406.643988</td>\n",
       "      <td>5076.792229</td>\n",
       "      <td>6022.718465</td>\n",
       "      <td>279538.959753</td>\n",
       "      <td>1967.111004</td>\n",
       "      <td>1.046546</td>\n",
       "      <td>21.986752</td>\n",
       "      <td>123126.249089</td>\n",
       "      <td>866.437364</td>\n",
       "      <td>0.460964</td>\n",
       "      <td>1.183675</td>\n",
       "      <td>0.528389</td>\n",
       "      <td>15.599853</td>\n",
       "      <td>11.696839</td>\n",
       "      <td>13.454482</td>\n",
       "      <td>18.719640</td>\n",
       "      <td>14.036069</td>\n",
       "      <td>16.145221</td>\n",
       "      <td>21.693654</td>\n",
       "      <td>574312.649429</td>\n",
       "      <td>4041.428548</td>\n",
       "      <td>2.150129</td>\n",
       "      <td>2.464626</td>\n",
       "      <td>1.085574</td>\n",
       "      <td>7.721846</td>\n",
       "      <td>8.896160</td>\n",
       "      <td>10.553724</td>\n",
       "      <td>9.725105</td>\n",
       "      <td>11.537121</td>\n",
       "      <td>12.163039</td>\n",
       "      <td>11.435192</td>\n",
       "      <td>15.342897</td>\n",
       "      <td>18.423623</td>\n",
       "      <td>21.192078</td>\n",
       "      <td>15.036022</td>\n",
       "      <td>mercedes-benz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>x-trail</td>\n",
       "      <td>EHX</td>\n",
       "      <td>WIE</td>\n",
       "      <td>238000.0</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.901422</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>일본</td>\n",
       "      <td>아시아</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>2.341806</td>\n",
       "      <td>2.738903</td>\n",
       "      <td>3.095125</td>\n",
       "      <td>4.886356</td>\n",
       "      <td>1.050822</td>\n",
       "      <td>3.558201</td>\n",
       "      <td>3.923359</td>\n",
       "      <td>4.405499</td>\n",
       "      <td>5.049022</td>\n",
       "      <td>0.482426</td>\n",
       "      <td>3.089678</td>\n",
       "      <td>3.707577</td>\n",
       "      <td>4.296605</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.164472</td>\n",
       "      <td>4.368303</td>\n",
       "      <td>4.575844</td>\n",
       "      <td>4.761062</td>\n",
       "      <td>5.049022</td>\n",
       "      <td>519792000.0</td>\n",
       "      <td>227411.723917</td>\n",
       "      <td>2086.836996</td>\n",
       "      <td>5114.503881</td>\n",
       "      <td>5981.763419</td>\n",
       "      <td>6759.753038</td>\n",
       "      <td>250095.546710</td>\n",
       "      <td>2294.994429</td>\n",
       "      <td>1.004072</td>\n",
       "      <td>21.526837</td>\n",
       "      <td>114817.423520</td>\n",
       "      <td>1053.618710</td>\n",
       "      <td>0.460964</td>\n",
       "      <td>1.129748</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>15.097267</td>\n",
       "      <td>12.121914</td>\n",
       "      <td>13.611573</td>\n",
       "      <td>18.116543</td>\n",
       "      <td>14.546155</td>\n",
       "      <td>16.333728</td>\n",
       "      <td>20.994742</td>\n",
       "      <td>515144.286226</td>\n",
       "      <td>4727.206391</td>\n",
       "      <td>2.068178</td>\n",
       "      <td>2.274474</td>\n",
       "      <td>1.044198</td>\n",
       "      <td>10.229716</td>\n",
       "      <td>11.964355</td>\n",
       "      <td>13.520442</td>\n",
       "      <td>12.532792</td>\n",
       "      <td>14.162810</td>\n",
       "      <td>14.736083</td>\n",
       "      <td>16.940817</td>\n",
       "      <td>17.965437</td>\n",
       "      <td>19.809125</td>\n",
       "      <td>22.243463</td>\n",
       "      <td>15.599853</td>\n",
       "      <td>nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>bravo</td>\n",
       "      <td>OSW</td>\n",
       "      <td>MAL</td>\n",
       "      <td>251000.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.865054</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>이탈리아</td>\n",
       "      <td>유럽</td>\n",
       "      <td>0</td>\n",
       "      <td>1.697449</td>\n",
       "      <td>3.249210</td>\n",
       "      <td>3.626206</td>\n",
       "      <td>3.948741</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>1.111858</td>\n",
       "      <td>2.865054</td>\n",
       "      <td>3.529985</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>4.969049</td>\n",
       "      <td>0.732368</td>\n",
       "      <td>3.201526</td>\n",
       "      <td>3.755837</td>\n",
       "      <td>4.305416</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>2.134166</td>\n",
       "      <td>2.894253</td>\n",
       "      <td>3.065725</td>\n",
       "      <td>3.210720</td>\n",
       "      <td>3.660223</td>\n",
       "      <td>479410000.0</td>\n",
       "      <td>426059.646229</td>\n",
       "      <td>3242.127188</td>\n",
       "      <td>6205.991763</td>\n",
       "      <td>6926.053192</td>\n",
       "      <td>7542.094524</td>\n",
       "      <td>279076.236370</td>\n",
       "      <td>2123.647854</td>\n",
       "      <td>1.887321</td>\n",
       "      <td>21.080055</td>\n",
       "      <td>183824.341322</td>\n",
       "      <td>1398.822677</td>\n",
       "      <td>1.243157</td>\n",
       "      <td>2.379617</td>\n",
       "      <td>0.814289</td>\n",
       "      <td>16.167246</td>\n",
       "      <td>11.301339</td>\n",
       "      <td>13.364410</td>\n",
       "      <td>18.966436</td>\n",
       "      <td>13.258048</td>\n",
       "      <td>15.678318</td>\n",
       "      <td>21.741728</td>\n",
       "      <td>535675.776784</td>\n",
       "      <td>4076.257903</td>\n",
       "      <td>3.622638</td>\n",
       "      <td>2.372889</td>\n",
       "      <td>1.562995</td>\n",
       "      <td>9.404037</td>\n",
       "      <td>10.495158</td>\n",
       "      <td>11.428655</td>\n",
       "      <td>11.116949</td>\n",
       "      <td>12.105751</td>\n",
       "      <td>12.678299</td>\n",
       "      <td>9.198885</td>\n",
       "      <td>10.486736</td>\n",
       "      <td>12.920531</td>\n",
       "      <td>15.279187</td>\n",
       "      <td>11.718299</td>\n",
       "      <td>fiat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   생산년도 모델출시년도      차량모델명 판매도시 판매구역      주행거리     배기량  압축천연가스(CNG)  경유  가솔린  \\\n",
       "0  2018   2014      fabia  KAT  SLA   85231.0   999.0            0   0    1   \n",
       "1  2010   2006      auris  RKO  SWI  135000.0  1598.0            0   0    1   \n",
       "2  2002   2002  clk-klasa  GNI  WIE  255223.0  1796.0            0   0    1   \n",
       "3  2006   2001    x-trail  EHX  WIE  238000.0  2184.0            0   1    0   \n",
       "4  2007   2007      bravo  OSW  MAL  251000.0  1910.0            0   1    0   \n",
       "\n",
       "   하이브리드  액화석유가스(LPG)        가격 출시년도생산여부 출시이후생산년수 출시이전생산여부 브랜드국적 브랜드대륙명  \\\n",
       "0      0            0  3.946231        0        4        0    체코     유럽   \n",
       "1      0            0  3.724970        0        4        0    일본    아시아   \n",
       "2      0            0  2.879760        1        0        0    독일     유럽   \n",
       "3      0            0  2.901422        0        5        0    일본    아시아   \n",
       "4      0            0  2.865054        1        0        0  이탈리아     유럽   \n",
       "\n",
       "  판매도시구역동일여부  모델출시년도_Q0  모델출시년도_Q25  모델출시년도_Q50  모델출시년도_Q75  모델출시년도_Q100  \\\n",
       "0          0   0.157004    4.019486    4.355041    4.643140     5.049856   \n",
       "1          0   1.358409    3.089678    3.348851    3.785779     5.049856   \n",
       "2          0   0.955511    2.453588    2.826722    3.353407     5.049022   \n",
       "3          0   0.955511    2.341806    2.738903    3.095125     4.886356   \n",
       "4          0   1.697449    3.249210    3.626206    3.948741     5.049856   \n",
       "\n",
       "     브랜드_Q0   브랜드_Q25   브랜드_Q50   브랜드_Q75  브랜드_Q100   판매구역_Q0  판매구역_Q25  \\\n",
       "0  0.727549  3.393501  4.057853  4.509072  5.049856  0.262364  3.206803   \n",
       "1  0.157004  3.353407  4.000034  4.435212  5.049856  1.095273  3.113071   \n",
       "2  1.095273  3.152736  3.785779  4.354655  5.049856  0.482426  3.089678   \n",
       "3  1.050822  3.558201  3.923359  4.405499  5.049022  0.482426  3.089678   \n",
       "4  1.111858  2.865054  3.529985  4.174387  4.969049  0.732368  3.201526   \n",
       "\n",
       "   판매구역_Q50  판매구역_Q75  판매구역_Q100  차량모델명_Q0  차량모델명_Q25  차량모델명_Q50  차량모델명_Q75  \\\n",
       "0  3.773910  4.355041   5.049856  0.792993   2.933059   3.712352   4.065687   \n",
       "1  3.520461  4.066802   5.049856  2.687167   3.594569   4.112512   4.387075   \n",
       "2  3.707577  4.296605   5.049856  2.250239   3.147165   3.440418   3.627069   \n",
       "3  3.707577  4.296605   5.049856  2.164472   4.368303   4.575844   4.761062   \n",
       "4  3.755837  4.305416   5.049856  2.134166   2.894253   3.065725   3.210720   \n",
       "\n",
       "   차량모델명_Q100     배기량*주행거리  모델출시년도_Q0*주행거리  모델출시년도_Q0*배기량  모델출시년도_Q25*배기량  \\\n",
       "0    4.830312   85145769.0    13381.586515     156.846745     4015.466312   \n",
       "1    4.761062  215730000.0   183385.236280    2170.737834     4937.305262   \n",
       "2    4.866534  458380508.0   243868.497534    1716.098555     4406.643988   \n",
       "3    5.049022  519792000.0   227411.723917    2086.836996     5114.503881   \n",
       "4    3.660223  479410000.0   426059.646229    3242.127188     6205.991763   \n",
       "\n",
       "   모델출시년도_Q50*배기량  모델출시년도_Q75*배기량    브랜드_Q0*주행거리   브랜드_Q0*배기량  \\\n",
       "0     4350.685729     4638.496977   62009.695347   726.821059   \n",
       "1     5351.463740     6049.675288   21195.506089   250.891991   \n",
       "2     5076.792229     6022.718465  279538.959753  1967.111004   \n",
       "3     5981.763419     6759.753038  250095.546710  2294.994429   \n",
       "4     6926.053192     7542.094524  279076.236370  2123.647854   \n",
       "\n",
       "   브랜드_Q0*모델출시년도_Q0  브랜드_Q75*모델출시년도_Q100   판매구역_Q0*주행거리  판매구역_Q0*배기량  \\\n",
       "0          0.114228            22.770164   22361.568625   262.101900   \n",
       "1          0.213275            22.397181  147861.907299  1750.246873   \n",
       "2          1.046546            21.986752  123126.249089   866.437364   \n",
       "3          1.004072            21.526837  114817.423520  1053.618710   \n",
       "4          1.887321            21.080055  183824.341322  1398.822677   \n",
       "\n",
       "   판매구역_Q0*모델출시년도_Q0  판매구역_Q0*모델출시년도_Q25  판매구역_Q0*브랜드_Q0  \\\n",
       "0           0.041192            1.054569        0.190883   \n",
       "1           1.487829            3.384042        0.171962   \n",
       "2           0.460964            1.183675        0.528389   \n",
       "3           0.460964            1.129748        0.506944   \n",
       "4           1.243157            2.379617        0.814289   \n",
       "\n",
       "   판매구역_Q25*모델출시년도_Q100  판매구역_Q25*브랜드_Q50  판매구역_Q25*브랜드_Q75  \\\n",
       "0             16.193895         13.012738         14.459707   \n",
       "1             15.720559         12.452389         13.807128   \n",
       "2             15.599853         11.696839         13.454482   \n",
       "3             15.097267         12.121914         13.611573   \n",
       "4             16.167246         11.301339         13.364410   \n",
       "\n",
       "   판매구역_Q50*모델출시년도_Q100  판매구역_Q50*브랜드_Q50  판매구역_Q50*브랜드_Q75  \\\n",
       "0             19.057701         15.313973         17.016831   \n",
       "1             17.777820         14.081962         15.613990   \n",
       "2             18.719640         14.036069         16.145221   \n",
       "3             18.116543         14.546155         16.333728   \n",
       "4             18.966436         13.258048         15.678318   \n",
       "\n",
       "   판매구역_Q75*모델출시년도_Q100  차량모델명_Q0*주행거리  차량모델명_Q0*배기량  차량모델명_Q0*모델출시년도_Q0  \\\n",
       "0             21.992329   67587.545091    792.199523            0.124503   \n",
       "1             20.536765  362767.543675   4294.092850            3.650272   \n",
       "2             21.693654  574312.649429   4041.428548            2.150129   \n",
       "3             20.994742  515144.286226   4727.206391            2.068178   \n",
       "4             21.741728  535675.776784   4076.257903            3.622638   \n",
       "\n",
       "   차량모델명_Q0*브랜드_Q0  차량모델명_Q0*판매구역_Q0  차량모델명_Q25*모델출시년도_Q25  \\\n",
       "0         0.576941          0.208053             11.789388   \n",
       "1         0.421895          2.943182             11.106060   \n",
       "2         2.464626          1.085574              7.721846   \n",
       "3         2.274474          1.044198             10.229716   \n",
       "4         2.372889          1.562995              9.404037   \n",
       "\n",
       "   차량모델명_Q25*모델출시년도_Q50  차량모델명_Q25*모델출시년도_Q75  차량모델명_Q50*모델출시년도_Q50  \\\n",
       "0             12.773590             13.618602             16.167443   \n",
       "1             12.037675             13.608244             13.772189   \n",
       "2              8.896160             10.553724              9.725105   \n",
       "3             11.964355             13.520442             12.532792   \n",
       "4             10.495158             11.428655             11.116949   \n",
       "\n",
       "   차량모델명_Q50*모델출시년도_Q75  차량모델명_Q75*모델출시년도_Q75  차량모델명_Q75*브랜드_Q25  \\\n",
       "0             17.236970             18.877555          13.796914   \n",
       "1             15.569062             16.608499          14.711648   \n",
       "2             11.537121             12.163039          11.435192   \n",
       "3             14.162810             14.736083          16.940817   \n",
       "4             12.105751             12.678299           9.198885   \n",
       "\n",
       "   차량모델명_Q100*브랜드_Q25  차량모델명_Q100*브랜드_Q50  차량모델명_Q100*브랜드_Q75  \\\n",
       "0           16.391669           19.600697           21.780223   \n",
       "1           15.965778           19.044410           21.116320   \n",
       "2           15.342897           18.423623           21.192078   \n",
       "3           17.965437           19.809125           22.243463   \n",
       "4           10.486736           12.920531           15.279187   \n",
       "\n",
       "   차량모델명_Q100*판매구역_Q25        segment  \n",
       "0            15.489859          skoda  \n",
       "1            14.821524         toyota  \n",
       "2            15.036022  mercedes-benz  \n",
       "3            15.599853         nissan  \n",
       "4            11.718299           fiat  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df7.shape)\n",
    "train_df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc32ace-0b1a-4235-b3aa-b834096d6c02",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdebcae-a0db-4e33-8f6a-8d655989d04f",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "330d67f2-4951-4092-aefd-1be42b8577e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def mkdir(paths):\n",
    "    if type(paths)==str:\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            print('> Create Folder: {}'.format(path))\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4abf1609-fe3f-405b-87e6-76c296a00a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## dummy_features는 한가지만 속함\n",
    "# X[dummy_features].apply(lambda x: np.sum(x),axis=1).value_counts()\n",
    "\n",
    "def add_fuel_type(data,dummy_features):\n",
    "    d = data.copy()\n",
    "    d['fuel_type'] = d[dummy_features].apply(\n",
    "        lambda x: dummy_features[np.where(x==1)[0][0]],axis=1)\n",
    "    d.drop(columns=dummy_features,inplace=True)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01609cc3-d341-4d8c-9295-45934f1e4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir('./model_checkpoints')\n",
    "mkdir('./model_checkpoints/segment_catboost')\n",
    "mkdir('./model_checkpoints/segment_weightedensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d430390-c11e-4018-a420-29b1e29850ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_null_cnt(data):\n",
    "    null_cnt = data.isnull().sum()\n",
    "    null_cnt = len(null_cnt[null_cnt!=0])\n",
    "    return null_cnt\n",
    "\n",
    "check_null_cnt(train_df7),check_null_cnt(test_df7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4369ef-ddbf-42f5-8d3b-008573b4b6b9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f1b72-9651-42d2-8410-52fd85595f88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CatBoost\n",
    "- public score : 5.7393705826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da2683aa-dd52-4402-a77b-7560b27b9f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "251d6bfc-9f23-4ad2-bca5-16a3d57c42b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4eceedea-c652-4a96-b165-e222b01b6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = train_df7.copy()\n",
    "test_fn  = test_df7 .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b0364030-ccdf-40df-a8cc-bf6fad1107f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [toyota], Size: [3,259], KFold: [1/5]:   5%|▌         | 1/20 [03:37<1:08:57, 217.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: skoda\n",
      "MAE's for 5-Fold: [[6.5490092  6.32619216 6.07251948 6.4398291  6.5031986 ]]\n",
      "Mean of MAE's for 5-Fold: [6.3781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [mercedes-benz], Size: [2,899], KFold: [1/5]:  10%|█         | 2/20 [07:07<1:03:57, 213.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: toyota\n",
      "MAE's for 5-Fold: [[5.57561943 5.50433417 5.11271022 5.46757983 4.75718478]]\n",
      "Mean of MAE's for 5-Fold: [5.2835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [nissan], Size: [2,129], KFold: [1/5]:  15%|█▌        | 3/20 [10:09<56:20, 198.88s/it]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: mercedes-benz\n",
      "MAE's for 5-Fold: [[7.76573798 8.42286291 8.55411471 8.52200673 8.52255735]]\n",
      "Mean of MAE's for 5-Fold: [8.3575]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [fiat], Size: [1,164], KFold: [1/5]:  20%|██        | 4/20 [12:12<45:00, 168.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: nissan\n",
      "MAE's for 5-Fold: [[5.11968736 5.19265353 5.12311383 4.7429005  5.0842194 ]]\n",
      "Mean of MAE's for 5-Fold: [5.0525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [audi], Size: [5,597], KFold: [1/5]:  25%|██▌       | 5/20 [13:40<34:58, 139.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: fiat\n",
      "MAE's for 5-Fold: [[5.45004198 5.21611996 5.90157623 4.81996641 4.53177913]]\n",
      "Mean of MAE's for 5-Fold: [5.1839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [renault], Size: [3,853], KFold: [1/5]:  30%|███       | 6/20 [17:38<40:22, 173.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: audi\n",
      "MAE's for 5-Fold: [[6.23973919 6.33077072 6.33087495 6.34276612 6.55889916]]\n",
      "Mean of MAE's for 5-Fold: [6.3606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [volkswagen], Size: [5,693], KFold: [1/5]:  35%|███▌      | 7/20 [21:46<42:49, 197.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: renault\n",
      "MAE's for 5-Fold: [[5.00173443 4.92608085 4.58275401 5.09786217 4.8191581 ]]\n",
      "Mean of MAE's for 5-Fold: [4.8855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [citroen], Size: [1,129], KFold: [1/5]:  40%|████      | 8/20 [27:05<47:16, 236.36s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: volkswagen\n",
      "MAE's for 5-Fold: [[6.17706274 6.28164675 5.83489152 6.35479713 6.28106358]]\n",
      "Mean of MAE's for 5-Fold: [6.1859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [bmw], Size: [5,262], KFold: [1/5]:  45%|████▌     | 9/20 [28:28<34:32, 188.40s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: citroen\n",
      "MAE's for 5-Fold: [[3.86604099 4.15480297 4.26777846 3.78236354 3.97996401]]\n",
      "Mean of MAE's for 5-Fold: [4.0102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [opel], Size: [6,651], KFold: [1/5]:  50%|█████     | 10/20 [32:54<35:22, 212.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: bmw\n",
      "MAE's for 5-Fold: [[7.81849255 7.79431741 7.42672622 7.63257741 7.47792326]]\n",
      "Mean of MAE's for 5-Fold: [7.6300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [ford], Size: [5,819], KFold: [1/5]:  55%|█████▌    | 11/20 [42:32<48:37, 324.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: opel\n",
      "MAE's for 5-Fold: [[3.83913273 3.87829278 3.99099523 4.1304431  4.18956905]]\n",
      "Mean of MAE's for 5-Fold: [4.0057]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [mazda], Size: [1,572], KFold: [1/5]:  60%|██████    | 12/20 [46:58<40:52, 306.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: ford\n",
      "MAE's for 5-Fold: [[5.38076771 5.00112535 5.37398635 4.99148789 5.05741477]]\n",
      "Mean of MAE's for 5-Fold: [5.1610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [honda], Size: [1,545], KFold: [1/5]:  65%|██████▌   | 13/20 [48:25<28:00, 240.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: mazda\n",
      "MAE's for 5-Fold: [[6.25417866 5.74157145 6.20268523 5.54321702 5.28722153]]\n",
      "Mean of MAE's for 5-Fold: [5.8058]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [kia], Size: [2,034], KFold: [1/5]:  70%|███████   | 14/20 [50:44<20:55, 209.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: honda\n",
      "MAE's for 5-Fold: [[5.34695607 5.0760443  5.93849489 5.37510092 5.51618834]]\n",
      "Mean of MAE's for 5-Fold: [5.4506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [seat], Size: [1,628], KFold: [1/5]:  75%|███████▌  | 15/20 [53:48<16:49, 201.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: kia\n",
      "MAE's for 5-Fold: [[5.39047566 5.42051852 5.67727304 6.16941647 6.12276775]]\n",
      "Mean of MAE's for 5-Fold: [5.7561]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [volvo], Size: [1,352], KFold: [1/5]:  80%|████████  | 16/20 [59:24<16:08, 242.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: seat\n",
      "MAE's for 5-Fold: [[5.26814765 4.91874333 4.99224606 4.23902738 5.19146089]]\n",
      "Mean of MAE's for 5-Fold: [4.9219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [peugeot], Size: [793], KFold: [1/5]:  85%|████████▌ | 17/20 [1:01:47<10:37, 212.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: volvo\n",
      "MAE's for 5-Fold: [[8.50628795 8.44827453 7.48888613 8.05187314 8.94482676]]\n",
      "Mean of MAE's for 5-Fold: [8.2880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [hyundai], Size: [1,855], KFold: [1/5]:  90%|█████████ | 18/20 [1:03:02<05:42, 171.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: peugeot\n",
      "MAE's for 5-Fold: [[5.47007143 5.37841997 6.51747077 5.44317194 5.46897055]]\n",
      "Mean of MAE's for 5-Fold: [5.6556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [mitsubishi], Size: [556], KFold: [1/5]:  95%|█████████▌| 19/20 [1:05:35<02:45, 165.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: hyundai\n",
      "MAE's for 5-Fold: [[5.50104129 5.38562808 5.60602651 5.96483459 5.88101831]]\n",
      "Mean of MAE's for 5-Fold: [5.6677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [mitsubishi], Size: [556], KFold: [5/5]: 100%|██████████| 20/20 [1:06:45<00:00, 200.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: mitsubishi\n",
      "MAE's for 5-Fold: [[6.23342119 5.83743318 6.25551546 5.09753296 7.70097291]]\n",
      "Mean of MAE's for 5-Fold: [6.2250]\n",
      "CPU times: user 3h 9min 54s, sys: 38min 31s, total: 3h 48min 26s\n",
      "Wall time: 1h 6min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1시간\n",
    "\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X = add_fuel_type(X,dummy_features)\n",
    "new_cat_features = cat_features + ['fuel_type']\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "models = {}\n",
    "feature_info = {}\n",
    "scores = []\n",
    "pbar = tqdm(segment_list)\n",
    "\n",
    "s_i = 0\n",
    "for segment in pbar:\n",
    "    s_i+=1\n",
    "    \n",
    "    # segment에 해당하는 데이터추출\n",
    "    _X = X[X.segment==segment].drop('segment',axis=1)\n",
    "    _y = y[X.segment==segment]\n",
    "    \n",
    "    # kfold\n",
    "    kf = KFold(n_splits=CFG.N_SPLITS,random_state=1000*s_i+CFG.SEED,shuffle=True)\n",
    "    \n",
    "    # unique인 컬럼 제외\n",
    "    unique_info = _X.nunique()\n",
    "    unique_cols = unique_info[unique_info==1].index.tolist()\n",
    "    if len(unique_cols)>0:\n",
    "        _X = _X.drop(unique_cols,axis=1)\n",
    "        \n",
    "    # categorical feature에서 unique인 컬럼을 제외\n",
    "    fixed_cat_features = [col for col in new_cat_features if col in _X.columns]\n",
    "    \n",
    "    _models = []\n",
    "    _scores = []\n",
    "    k=0\n",
    "    for tr_idx,val_idx in kf.split(_X,_y):\n",
    "        k+=1\n",
    "        \n",
    "        # kfold dataset\n",
    "        X_tr, X_va = _X.iloc[tr_idx], _X.iloc[val_idx]\n",
    "        y_tr, y_va = _y.iloc[tr_idx], _y.iloc[val_idx]\n",
    "\n",
    "        # progress\n",
    "        progress = 'Segment: [{}], Size: [{:,}], KFold: [{}/{}]'\\\n",
    "            .format(segment,len(_X),k,CFG.N_SPLITS)\n",
    "        pbar.set_description(progress)\n",
    "\n",
    "        # dataset\n",
    "        train_dataset = Pool(X_tr,y_tr,cat_features=fixed_cat_features)\n",
    "        valid_dataset = Pool(X_va,y_va,cat_features=fixed_cat_features)\n",
    "\n",
    "        # define the model\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function='MAE',\n",
    "            random_state=CFG.SEED,\n",
    "            iterations=CFG.EPOCHS,\n",
    "            learning_rate=CFG.LR,\n",
    "            allow_writing_files=False,\n",
    "        )\n",
    "\n",
    "        # fit the model\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            eval_set=valid_dataset,\n",
    "            early_stopping_rounds=CFG.ES,\n",
    "            verbose=0,\n",
    "            #metric_period=CFG.EPOCHS//5,\n",
    "        )\n",
    "\n",
    "        # save the model\n",
    "        model.save_model(f'./model_checkpoints/segment_catboost/{segment}_k{k}.cbm')\n",
    "\n",
    "        # prediction\n",
    "        y_pred = model.predict(valid_dataset).flatten()\n",
    "        y_true = y_va.values\n",
    "        \n",
    "        # inverse transform\n",
    "        if CFG.TARGET_TRANSFORMATION:\n",
    "            y_pred = np.exp(y_pred)\n",
    "            y_true = np.exp(y_true)\n",
    "            \n",
    "        # calculate score\n",
    "        score = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "        \n",
    "        # append inner loop\n",
    "        _models.append(model)\n",
    "        _scores.append([segment,k,len(X_tr),len(X_va),score])\n",
    "\n",
    "    # append outer loop\n",
    "    models[segment] = _models\n",
    "    scores.append(_scores)\n",
    "    feature_info[segment] = {'cat_features':fixed_cat_features,'features':_X.columns.tolist()}\n",
    "    \n",
    "    # score report\n",
    "    mean_score_report = pd.Series(np.array(_scores)[:,-1]).astype(float).mean()\n",
    "    print('Segment: {}'.format(segment))\n",
    "    print(\"MAE's for {}-Fold: [{}]\".format(CFG.N_SPLITS,np.array(pd.Series(np.array(_scores)[:,-1]).astype(float).values)))\n",
    "    print(\"Mean of MAE's for {}-Fold: [{:.4f}]\".format(CFG.N_SPLITS,mean_score_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d329a-8a2a-4b11-a184-dd86a24de2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model_checkpoints/segment_cat_models_brand_kf.pkl', 'wb') as f:\n",
    "\tpickle.dump(models, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model_checkpoints/segment_cat_feature_info_brand_kf.pkl', 'wb') as f:\n",
    "\tpickle.dump(feature_info, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model_checkpoints/segment_cat_scores_brand_kf.pkl', 'wb') as f:\n",
    "\tpickle.dump(scores, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33753abc-bf26-4ee8-b7a6-847686119b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>k</th>\n",
       "      <th>n_tr</th>\n",
       "      <th>n_val</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>audi</td>\n",
       "      <td>1</td>\n",
       "      <td>4477</td>\n",
       "      <td>1120</td>\n",
       "      <td>6.239739191218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>audi</td>\n",
       "      <td>2</td>\n",
       "      <td>4477</td>\n",
       "      <td>1120</td>\n",
       "      <td>6.330770716549872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>audi</td>\n",
       "      <td>3</td>\n",
       "      <td>4478</td>\n",
       "      <td>1119</td>\n",
       "      <td>6.330874953582962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>audi</td>\n",
       "      <td>4</td>\n",
       "      <td>4478</td>\n",
       "      <td>1119</td>\n",
       "      <td>6.342766121776582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>audi</td>\n",
       "      <td>5</td>\n",
       "      <td>4478</td>\n",
       "      <td>1119</td>\n",
       "      <td>6.558899164553702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1</td>\n",
       "      <td>4209</td>\n",
       "      <td>1053</td>\n",
       "      <td>7.818492548938672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bmw</td>\n",
       "      <td>2</td>\n",
       "      <td>4209</td>\n",
       "      <td>1053</td>\n",
       "      <td>7.794317414444021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bmw</td>\n",
       "      <td>3</td>\n",
       "      <td>4210</td>\n",
       "      <td>1052</td>\n",
       "      <td>7.42672621568825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bmw</td>\n",
       "      <td>4</td>\n",
       "      <td>4210</td>\n",
       "      <td>1052</td>\n",
       "      <td>7.632577414245749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bmw</td>\n",
       "      <td>5</td>\n",
       "      <td>4210</td>\n",
       "      <td>1052</td>\n",
       "      <td>7.477923264383002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   segment  k  n_tr n_val              score\n",
       "25    audi  1  4477  1120  6.239739191218876\n",
       "26    audi  2  4477  1120  6.330770716549872\n",
       "27    audi  3  4478  1119  6.330874953582962\n",
       "28    audi  4  4478  1119  6.342766121776582\n",
       "29    audi  5  4478  1119  6.558899164553702\n",
       "45     bmw  1  4209  1053  7.818492548938672\n",
       "46     bmw  2  4209  1053  7.794317414444021\n",
       "47     bmw  3  4210  1052   7.42672621568825\n",
       "48     bmw  4  4210  1052  7.632577414245749\n",
       "49     bmw  5  4210  1052  7.477923264383002"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(\n",
    "    np.array(scores).reshape(len(scores)*5,5),\n",
    "    columns=['segment','k','n_tr','n_val','score']\n",
    ")\n",
    "\n",
    "score_df.sort_values(['segment','k']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89dbbe-b7cc-4107-b3bc-197c368d49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "X = add_fuel_type(X,dummy_features)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X_test = add_fuel_type(test_fn,dummy_features)\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "tr_pred_list = []\n",
    "te_pred_list = []\n",
    "for segment in tqdm(segment_list):\n",
    "    ## data load\n",
    "    # (1) train\n",
    "    train_data = X[X.segment==segment][feature_info[segment]['features']]\n",
    "    train_dataset = Pool(train_data,cat_features=feature_info[segment]['cat_features'])\n",
    "    # (2) test\n",
    "    test_data = X_test[X_test.segment==segment][feature_info[segment]['features']]\n",
    "    test_dataset = Pool(test_data,cat_features=feature_info[segment]['cat_features'])\n",
    "    \n",
    "    ## model\n",
    "    kfold_models = models[segment]\n",
    "    \n",
    "    ## prediction\n",
    "    # (1) train\n",
    "    tr_pred_df = pd.DataFrame({\n",
    "        'segment':segment,\n",
    "        'true':y[X.segment==segment].values.flatten(),\n",
    "        'pred':np.mean([model.predict(train_dataset) for model in kfold_models],axis=0),\n",
    "        #'pred':np.sum([weight*model.predict(train_dataset) for weight,model in zip(kfold_weights,kfold_models)],axis=0),\n",
    "    })\n",
    "    tr_pred_df.index = train_data.index\n",
    "    # (2) test\n",
    "    te_pred_df = pd.DataFrame({\n",
    "        'segment':segment,\n",
    "        'pred':np.mean([model.predict(test_dataset) for model in kfold_models],axis=0),\n",
    "        #'pred':np.sum([weight*model.predict(test_dataset) for weight,model in zip(kfold_weights,kfold_models)],axis=0),\n",
    "    })\n",
    "    te_pred_df.index = test_data.index\n",
    "    \n",
    "    ## Target Transformation\n",
    "    if CFG.TARGET_TRANSFORMATION:\n",
    "        tr_pred_df['true'] = np.exp(tr_pred_df['true'])\n",
    "        tr_pred_df['pred'] = np.exp(tr_pred_df['pred'])\n",
    "        te_pred_df['pred'] = np.exp(te_pred_df['pred'])\n",
    "    \n",
    "    ## append\n",
    "    tr_pred_list.append(tr_pred_df)\n",
    "    te_pred_list.append(te_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad43d66-1e96-437e-8d88-43c6549e1f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tr_pred_df = pd.concat(tr_pred_list,axis=0).sort_index()\n",
    "mean_absolute_error(y_true=tr_pred_df.true,y_pred=tr_pred_df.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a46da9-6aa5-4fd2-95a2-339aa93a4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred_df = pd.concat(te_pred_list,axis=0).sort_index()\n",
    "te_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d926b-6db7-4b8d-9e16-1ca1c0331872",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['가격'] = te_pred_df.pred.values\n",
    "submit.to_csv('./out/12_catboost_segment_브랜드_kfold_logy_interaction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7a7e9-1c4b-47c3-8959-0412cfc188f6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34001f77-6935-4c16-8d86-2ee1e7ab27ef",
   "metadata": {},
   "source": [
    "## Weighted Ensemble\n",
    "- public score : 5.7381807069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d603f-56f8-4006-a62b-386cc14d51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,columns):\n",
    "        self.transform_list = []\n",
    "        for col in columns:\n",
    "            for i,value in enumerate(sorted(data[col].unique())):\n",
    "                if i>0:\n",
    "                    self.transform_list.append([col,value])\n",
    "        \n",
    "    def transform(self,data):\n",
    "        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "        new_data = data.copy()\n",
    "        for col,value in self.transform_list:\n",
    "            new_data[f'{col}_{value}'] = np.where(new_data[col]==value,1,0)\n",
    "        drop_columns = pd.unique(np.array(self.transform_list)[:,0])\n",
    "        new_data.drop(columns=drop_columns,inplace=True)\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20d5c0-a506-418d-838c-65c44c753dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "class WeightedEnsembleRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,weight=['equal','balanced'],target_transformation=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert weight in ['equal','balanced'], \\\n",
    "            \"weight must be one of ['equal','balanced']\"\n",
    "        assert isinstance(target_transformation,bool), \\\n",
    "            \"target_transformation must be bool type\"\n",
    "        \n",
    "        self.weight = weight\n",
    "        self.target_transformation = target_transformation\n",
    "        self._get_regressors()\n",
    "    \n",
    "    def _get_regressors(self):\n",
    "        max_depth = 10\n",
    "        n_jobs = -1\n",
    "        \n",
    "        params_elasticnet = {\n",
    "            'l1_ratio' : np.arange(0.1, 1, 0.1),\n",
    "            'alphas' : [1e-5, 1e-3, 1e-1, 0.0, 1.0, 10.0, 100.0],\n",
    "            'cv' : RepeatedKFold(n_splits=CFG.N_SPLITS, n_repeats=3, random_state=CFG.SEED),\n",
    "            'n_jobs' : n_jobs,\n",
    "            #'max_iter' : 50000,\n",
    "            'tol' : 0.001,\n",
    "        }\n",
    "        \n",
    "        params_catboost = {\n",
    "            'random_state' : CFG.SEED,\n",
    "            'iterations' : CFG.EPOCHS,\n",
    "            'early_stopping_rounds' : CFG.ES,\n",
    "            'learning_rate' : CFG.LR,\n",
    "            'loss_function' : 'MAE',\n",
    "            'grow_policy' : 'Lossguide', # 'SymmetricTree','Depthwise'\n",
    "            'use_best_model' : True,\n",
    "            'allow_writing_files' : False,\n",
    "            'verbose' : 0,\n",
    "            'max_depth' : max_depth,\n",
    "            #'l2_leaf_reg' : 1,\n",
    "        }\n",
    "    \n",
    "        params_xgboost = {\n",
    "            'random_state' : CFG.SEED,\n",
    "            'n_estimators' : CFG.XGB_EPOCHS,\n",
    "            'early_stopping_rounds' : CFG.XGB_ES,\n",
    "            'learning_rate' : CFG.XGB_LR,\n",
    "            'objective' : 'reg:absoluteerror',\n",
    "            'verbosity' : 0,\n",
    "            'max_depth': max_depth,\n",
    "            'n_jobs' : n_jobs,\n",
    "        }\n",
    "    \n",
    "        params_lightgbm = {\n",
    "            'random_state' : CFG.SEED,\n",
    "            'n_estimators' : CFG.EPOCHS,\n",
    "            'early_stopping_round' : CFG.ES,\n",
    "            'learning_rate' : CFG.LR,\n",
    "            'objective' : 'regression',\n",
    "            'metric' : 'mean_absolute_error',\n",
    "            'verbosity' : -1,\n",
    "            'max_depth': max_depth,\n",
    "            'n_jobs' : n_jobs,\n",
    "        }\n",
    "        \n",
    "        params_extratrees = {\n",
    "            'random_state' : CFG.SEED,\n",
    "            'n_estimators' : CFG.XTRATREES_EPOCHS,\n",
    "            'criterion' : 'absolute_error',\n",
    "            'verbose' : 0,\n",
    "            'max_depth' : max_depth,\n",
    "            'n_jobs' : n_jobs,\n",
    "        }\n",
    "        \n",
    "        self.regressors = [\n",
    "            ElasticNetCV(**params_elasticnet),\n",
    "            CatBoostRegressor(**params_catboost),\n",
    "            XGBRegressor(**params_xgboost),\n",
    "            LGBMRegressor(**params_lightgbm),\n",
    "            ExtraTreesRegressor(**params_extratrees),\n",
    "        ]\n",
    "        self.regressors_name = ['ElasticNet','CatBoost','XGBoost','LightGBM','ExtraTrees']\n",
    "        \n",
    "    def _adjust_prediction(self,pred):\n",
    "        pred = np.array(pred).flatten()\n",
    "        if np.where(pred<0,1,0).sum()>0:\n",
    "            pred = [x if x>0 else self.minimum_value for x in pred]\n",
    "        pred = np.exp(np.array(pred).flatten())\n",
    "        if np.where(pred==np.inf,1,0).sum()>0:\n",
    "            pred = [x if x!=np.inf else self.maximum_value for x in pred]\n",
    "        pred = np.array(pred).flatten()\n",
    "        return pred\n",
    "    \n",
    "    def fit(self,X,y,eval_set,oh_set,cat_features,verbose=1):\n",
    "        assert len(eval_set)==1, \\\n",
    "            \"eval_set length must be 1. len(eval_set)={}\".format(len(eval_set))\n",
    "        assert len(oh_set)==1, \\\n",
    "            \"oh_set length must be 1. len(oh_set)={}\".format(len(oh_set))\n",
    "        X_val, y_val = eval_set[0]\n",
    "        X_oh, X_val_oh = oh_set[0]\n",
    "        \n",
    "        self.cat_features = cat_features\n",
    "        self.weights = []\n",
    "        self.fitting_elapsed = []\n",
    "        if verbose:\n",
    "            pbar = tqdm(zip(self.regressors_name,self.regressors),total=len(self.regressors))\n",
    "        else:\n",
    "            pbar = zip(self.regressors_name,self.regressors)\n",
    "            \n",
    "        fit_iter = 0\n",
    "        for regressor_name,regressor in pbar:\n",
    "            fit_iter+=1\n",
    "            s = time.time()\n",
    "            \n",
    "            if verbose:\n",
    "                pbar.set_description(name)\n",
    "                \n",
    "            if regressor_name=='ElasticNet':\n",
    "                warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                regressor.fit(X_oh,y)\n",
    "                tr_pred = regressor.predict(X_oh)\n",
    "                va_pred = regressor.predict(X_val_oh)\n",
    "            elif regressor_name=='CatBoost':\n",
    "                train_dataset = Pool(X,y,cat_features=cat_features)\n",
    "                val_dataset   = Pool(X_val,y_val,cat_features=cat_features)\n",
    "                regressor.fit(\n",
    "                    train_dataset,\n",
    "                    eval_set=val_dataset,\n",
    "                    #metric_period=CFG.EPOCHS//5,\n",
    "                )\n",
    "                tr_pred = regressor.predict(train_dataset)\n",
    "                va_pred = regressor.predict(val_dataset)\n",
    "            elif regressor_name=='XGBoost':\n",
    "                regressor.fit(\n",
    "                    X_oh,y,\n",
    "                    eval_set=[(X_val_oh,y_val)],\n",
    "                    verbose=0,\n",
    "                )\n",
    "                tr_pred = regressor.predict(X_oh)\n",
    "                va_pred = regressor.predict(X_val_oh)\n",
    "            elif regressor_name=='LightGBM':\n",
    "                warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                X_tmp = X.copy()\n",
    "                X_val_tmp = X_val.copy()\n",
    "                for col in cat_features:\n",
    "                    X_tmp[col]     = X_tmp[col]    .astype('category')\n",
    "                    X_val_tmp[col] = X_val_tmp[col].astype('category')\n",
    "                regressor.fit(\n",
    "                    X_tmp,y,\n",
    "                    eval_set=[(X_val_tmp,y_val)],\n",
    "                    verbose=-1,\n",
    "                )\n",
    "                tr_pred = regressor.predict(X_tmp)\n",
    "                va_pred = regressor.predict(X_val_tmp)\n",
    "            elif regressor_name=='ExtraTrees':\n",
    "                regressor.fit(X_oh,y)\n",
    "                tr_pred = regressor.predict(X_oh)\n",
    "                va_pred = regressor.predict(X_val_oh)\n",
    "            else:\n",
    "                raise ValueError('Unknown Regressor: {}'.format(regressor_name))\n",
    "            \n",
    "            if self.target_transformation:\n",
    "                tr_true = np.exp(np.array(y)    .flatten())\n",
    "                va_true = np.exp(np.array(y_val).flatten())\n",
    "                self.minimum_value = min(np.nanmin(tr_true),np.nanmin(va_true))\n",
    "                self.maximum_value = max(np.nanmax(tr_true),np.nanmax(va_true))\n",
    "                \n",
    "                tr_pred = self._adjust_prediction(tr_pred)\n",
    "                va_pred = self._adjust_prediction(va_pred)\n",
    "            else:\n",
    "                tr_true = np.array(y).flatten()\n",
    "                va_true = np.array(y_val).flatten()\n",
    "                tr_pred = np.array(tr_pred).flatten()\n",
    "                va_pred = np.array(va_pred).flatten()\n",
    "            tr_score = mean_absolute_error(y_pred=tr_pred,y_true=tr_true)\n",
    "            va_score = mean_absolute_error(y_pred=va_pred,y_true=va_true)\n",
    "            e = time.time()\n",
    "            self.weights.append(1/va_score)\n",
    "            self.fitting_elapsed.append(e-s)\n",
    "            \n",
    "            blank = ' '*(11-len(regressor_name))\n",
    "            fit_progress = '  [{}/{}] {}{}: score={:.3f}, val_score={:.3f}, elasped={:.1f}s'\\\n",
    "                .format(fit_iter,len(self.regressors),regressor_name,blank,tr_score,va_score,e-s)\n",
    "            print(fit_progress)\n",
    "        \n",
    "        if self.weight=='equal':\n",
    "            self.weights = np.array([1.0 for _ in self.regressors])\n",
    "        self.weights /= sum(self.weights)\n",
    "        \n",
    "        tr_pred = self.predict(X,X_oh)\n",
    "        va_pred = self.predict(X_val,X_val_oh)\n",
    "        ens_tr_score = mean_absolute_error(y_true=np.exp(np.array(y)    .flatten()),y_pred=tr_pred)\n",
    "        ens_va_score = mean_absolute_error(y_true=np.exp(np.array(y_val).flatten()),y_pred=va_pred)\n",
    "        \n",
    "        total_fit_progress = '  Total({}): score={:.3f}, val_score={:.3f}, elasped={:.1f}s'\\\n",
    "            .format(self.weight,ens_tr_score,ens_va_score,sum(self.fitting_elapsed))\n",
    "        print(total_fit_progress)\n",
    "        \n",
    "    def predict(self,X,X_oh):\n",
    "        assert len(X)==len(X_oh), \\\n",
    "            \"X and X_oh must be same length\"\n",
    "        \n",
    "        pred_list = []\n",
    "        for regressor_name,regressor in zip(self.regressors_name,self.regressors):\n",
    "            if regressor_name in ['ElasticNet','XGBoost','ExtraTrees']:\n",
    "                dataset = X_oh.copy()\n",
    "            elif regressor_name=='CatBoost':\n",
    "                dataset = Pool(X,cat_features=self.cat_features)\n",
    "            elif regressor_name=='LightGBM':\n",
    "                dataset = X.copy()\n",
    "                for col in self.cat_features:\n",
    "                    dataset[col] = dataset[col].astype('category')\n",
    "            else:\n",
    "                raise ValueError('Unknown Regressor: {}'.format(regressor_name))\n",
    "            \n",
    "            y_pred = regressor.predict(dataset)\n",
    "            y_pred = self._adjust_prediction(y_pred)\n",
    "            \n",
    "            pred_list.append(y_pred)\n",
    "            \n",
    "        final_pred = np.zeros(len(X))\n",
    "        for pred,weight in zip(pred_list,self.weights):\n",
    "            final_pred += np.array(pred)*weight\n",
    "            \n",
    "        return final_pred\n",
    "    \n",
    "    def save_model(self,path):\n",
    "        save_dict = {\n",
    "            'cat_features' : self.cat_features,\n",
    "            'weights' : self.weights,\n",
    "            'target_transformation' : self.target_transformation,\n",
    "            'fitting_elapsed' : self.fitting_elapsed,\n",
    "            'regressors' : self.regressors,\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(save_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def load_model(self,path):\n",
    "        with open(path, 'rb') as f:\n",
    "            save_dict = pickle.load(f)\n",
    "            self.cat_features = save_dict['cat_features']\n",
    "            self.weights = save_dict['weights']\n",
    "            self.target_transformation = save_dict['target_transformation'],\n",
    "            self.fitting_elapsed = save_dict['fitting_elapsed']\n",
    "            self.regressors = save_dict['regressors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e22bc-b630-430c-a9f9-6f539e219c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac1666-19fe-4f0c-b651-8d6267292d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003ed17-9aae-4651-9020-35ae377b036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = train_df7.copy()\n",
    "test_fn  = test_df7 .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb213e-a076-45ba-b12d-94449e44d75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 6시간\n",
    "\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "y = train_fn[target_feature]\n",
    "y = pd.Series(y.values.flatten())\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X,cat_features)\n",
    "X_oh = ohe.transform(X)\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "models = {}\n",
    "feature_info = {}\n",
    "scores = []\n",
    "pbar = tqdm(segment_list)\n",
    "\n",
    "s_i = 0\n",
    "for segment in pbar:\n",
    "    s_i+=1\n",
    "    \n",
    "    # segment에 해당하는 데이터추출\n",
    "    _X    = X   [X   .segment==segment].drop('segment',axis=1)\n",
    "    _X_oh = X_oh[X_oh.segment==segment].drop('segment',axis=1)\n",
    "    _y    = y   [X   .segment==segment]\n",
    "    \n",
    "    # kfold\n",
    "    kf = KFold(n_splits=CFG.N_SPLITS,random_state=1000*s_i+CFG.SEED,shuffle=True)\n",
    "    \n",
    "    # unique인 컬럼 제외\n",
    "    # (1) X\n",
    "    unique_info = _X.nunique()\n",
    "    unique_cols = unique_info[unique_info==1].index.tolist()\n",
    "    if len(unique_cols)>0:\n",
    "        _X = _X.drop(unique_cols,axis=1)\n",
    "    # (2) X_oh\n",
    "    unique_info = _X_oh.nunique()\n",
    "    unique_cols = unique_info[unique_info==1].index.tolist()\n",
    "    if len(unique_cols)>0:\n",
    "        _X_oh = _X_oh.drop(unique_cols,axis=1)\n",
    "        \n",
    "    # categorical feature에서 unique인 컬럼을 제외\n",
    "    fixed_cat_features = [col for col in cat_features if col in _X.columns]\n",
    "    \n",
    "    # progress\n",
    "    progress = 'Segment: {}, Length: {}'\\\n",
    "        .format(segment,len(_X))\n",
    "    pbar.set_description(progress)\n",
    "    \n",
    "    _models = []\n",
    "    _scores = []\n",
    "    k=0\n",
    "    for tr_idx,val_idx in kf.split(_X,_y):\n",
    "        k+=1\n",
    "        print('> [K-Fold] {}/{}'.format(k,CFG.N_SPLITS))\n",
    "        \n",
    "        # kfold dataset\n",
    "        X_tr   , X_va    = _X   .iloc[tr_idx], _X   .iloc[val_idx]\n",
    "        X_tr_oh, X_va_oh = _X_oh.iloc[tr_idx], _X_oh.iloc[val_idx]\n",
    "        y_tr   , y_va    = _y   .iloc[tr_idx], _y   .iloc[val_idx]\n",
    "\n",
    "        # define the model\n",
    "        ensemble_model = WeightedEnsembleRegressor(\n",
    "            weight='balanced',\n",
    "            target_transformation=CFG.TARGET_TRANSFORMATION,\n",
    "        )\n",
    "\n",
    "        # fit the model\n",
    "        ensemble_model.fit(\n",
    "            X_tr,y_tr,\n",
    "            eval_set=[(X_va,y_va)],\n",
    "            oh_set=[(X_tr_oh,X_va_oh)],\n",
    "            cat_features=fixed_cat_features,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # save the model\n",
    "        ensemble_model.save_model(f'./model_checkpoints/segment_weightedensemble/{segment}_k{k}.pickle')\n",
    "\n",
    "        # prediction\n",
    "        y_pred = ensemble_model.predict(X_va,X_va_oh).flatten()\n",
    "        y_true = y_va.values\n",
    "        \n",
    "        # caculate score\n",
    "        score = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "        \n",
    "        # append inner loop\n",
    "        _models.append(ensemble_model)\n",
    "        _scores.append([segment,k,len(X_tr),len(X_va),score])\n",
    "\n",
    "    # append outer loop\n",
    "    models[segment] = _models\n",
    "    scores.append(_scores)\n",
    "    feature_info[segment] = {\n",
    "        'cat_features':fixed_cat_features,\n",
    "        'features':_X.columns.tolist(),\n",
    "        'oh_features':_X_oh.columns.tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db8ed9-ced3-432d-aeb2-ba20f3e30150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model_checkpoints/segment_weiens_models_brand.pkl', 'wb') as f:\n",
    "\tpickle.dump(models, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model_checkpoints/segment_weiens_feature_info_brand_kf.pkl', 'wb') as f:\n",
    "\tpickle.dump(feature_info, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model_checkpoints/segment_weiens_scores_brand.pkl', 'wb') as f:\n",
    "\tpickle.dump(scores, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74057406-7c55-4ee1-90e0-bde923905b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('./model_checkpoints/segment_weiens_models_brand.pkl', 'rb') as f:\n",
    "# \tmodels = pickle.load(f)\n",
    "# with open('./model_checkpoints/segment_weiens_feature_info_brand.pkl', 'rb') as f:\n",
    "# \tfeature_info = pickle.load(f)\n",
    "# with open('./model_checkpoints/segment_weiens_scores_brand.pkl', 'rb') as f:\n",
    "# \tscores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754b5f4-1a4e-483a-aa41-019289df14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(\n",
    "#     np.array(scores).reshape(100,5),\n",
    "#     columns=['segment','k','n_tr','n_val','score']\n",
    "# ).sort_values(['segment','k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4feb2f-3fe3-4b15-a2e9-a69e7c283c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X_test = test_fn.copy()\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X,cat_features)\n",
    "X_oh = ohe.transform(X)\n",
    "X_test_oh = ohe.transform(X_test)\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "tr_pred_list = []\n",
    "te_pred_list = []\n",
    "for segment in tqdm(segment_list):\n",
    "    ## data load\n",
    "    # (1) train\n",
    "    train_data    = X   [X   .segment==segment][feature_info[segment]['features']]\n",
    "    train_data_oh = X_oh[X_oh.segment==segment][feature_info[segment]['oh_features']]\n",
    "    # (2) test\n",
    "    test_data     = X_test   [X_test   .segment==segment][feature_info[segment]['features']]\n",
    "    test_data_oh  = X_test_oh[X_test_oh.segment==segment][feature_info[segment]['oh_features']]\n",
    "    \n",
    "    ## model\n",
    "    kfold_models = models[segment]\n",
    "    \n",
    "    ## prediction\n",
    "    # (1) train\n",
    "    tr_pred_df = pd.DataFrame({\n",
    "        'true':y[X.segment==segment].values.flatten(),\n",
    "        'pred':np.mean([model.predict(train_data,train_data_oh) for model in kfold_models],axis=0),\n",
    "    })\n",
    "    tr_pred_df.index = train_data.index\n",
    "    # (2) test\n",
    "    te_pred_df = pd.DataFrame({\n",
    "        'pred':np.mean([model.predict(test_data,test_data_oh) for model in kfold_models],axis=0),\n",
    "    })\n",
    "    te_pred_df.index = test_data.index\n",
    "    if CFG.TARGET_TRANSFORMATION:\n",
    "        tr_pred_df['true'] = np.exp(tr_pred_df['true'])\n",
    "    \n",
    "    ## append\n",
    "    tr_pred_list.append(tr_pred_df)\n",
    "    te_pred_list.append(te_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068d2b4-114a-4556-aebb-49ce81be2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tr_pred_df = pd.concat(tr_pred_list,axis=0).sort_index()\n",
    "mean_absolute_error(y_true=tr_pred_df.true,y_pred=tr_pred_df.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d4242-793f-4c8c-a1da-2f6934a98df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def abline(intercept,slope,**kwargs):\n",
    "#     axes = plt.gca()\n",
    "#     x_vals = np.array(axes.get_xlim())\n",
    "#     y_vals = intercept + slope * x_vals\n",
    "#     plt.plot(x_vals, y_vals, '--',**kwargs)\n",
    "\n",
    "# offset = 0.05\n",
    "# min_value = min(tr_pred_df.true.min(),tr_pred_df.pred.min())*(1-offset)\n",
    "# max_value = min(tr_pred_df.true.max(),tr_pred_df.pred.max())*(1+offset)\n",
    "\n",
    "# plt.figure(figsize=(15,7))\n",
    "# sns.scatterplot(x=tr_pred_df.true,y=tr_pred_df.pred)\n",
    "# plt.xlim(min_value,max_value)\n",
    "# plt.ylim(min_value,max_value)\n",
    "# abline(0,1,color='red',linestyle='--')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b9ad6-0c4f-4593-94e3-70d810909cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred_df = pd.concat(te_pred_list,axis=0).sort_index()\n",
    "te_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e76369-d936-4816-aed7-c7dcdb3bdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['가격'] = te_pred_df.pred.values\n",
    "submit.to_csv('./out/13_ensemble_segment_브랜드_kfold_logy_interaction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92abc4-eb0a-4d71-861f-200a40356c20",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6f0e6-6fa4-458d-838e-32a5db3df13d",
   "metadata": {},
   "source": [
    "## 참조 pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e7ce5-6c68-4d17-b54b-c33c821ced59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da0375-b3dc-45d9-af61-33e733136308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# data = train_fn[train_fn.segment==segment_list[0]]\n",
    "# # data['가격'] = np.exp(data['가격'])\n",
    "# print(len(data))\n",
    "\n",
    "# regression.setup(data=data,target='가격',remove_outliers=True,verbose=True)\n",
    "# best = regression.compare_models(n_select=5,fold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a5297-58ba-49ff-aa43-d0ed18679b74",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19226891-228a-4bd7-98e1-e995869d65d4",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ab80f-7e1e-4392-b1d5-833db926d305",
   "metadata": {},
   "source": [
    "(1) catboost regressor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22ab6e11-22d8-4749-9dee-b0026892b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model_checkpoints/segment_cat_models_brand_kf.pkl', 'rb') as f:\n",
    "\tmodels = pickle.load(f)\n",
    "with open('./model_checkpoints/segment_weiens_feature_info_brand.pkl', 'rb') as f:\n",
    "\tfeature_info = pickle.load(f)\n",
    "with open('./model_checkpoints/segment_cat_scores_brand_kf.pkl', 'rb') as f:\n",
    "\tscores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6552cc1e-9e6f-4f17-b5d7-bc4a4b16b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "X = add_fuel_type(X,dummy_features)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X_test = add_fuel_type(test_fn,dummy_features)\n",
    "\n",
    "segment_list = X['segment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b106f4d9-60c6-4b50-9aef-56244d38dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "tr_pred_list = []\n",
    "te_pred_list = []\n",
    "for segment in tqdm(segment_list):\n",
    "    ## data load\n",
    "    # (1) train\n",
    "    train_data = X[X.segment==segment][feature_info[segment]['features']]\n",
    "    train_dataset = Pool(train_data,cat_features=feature_info[segment]['cat_features'])\n",
    "    # (2) test\n",
    "    test_data = X_test[X_test.segment==segment][feature_info[segment]['features']]\n",
    "    test_dataset = Pool(test_data,cat_features=feature_info[segment]['cat_features'])\n",
    "    \n",
    "    ## model\n",
    "    kfold_models = models[segment]\n",
    "    \n",
    "    ## prediction\n",
    "    # (1) train\n",
    "    tr_pred_df = pd.DataFrame({\n",
    "        'true':y[X.segment==segment].values.flatten(),\n",
    "    })\n",
    "    if CFG.TARGET_TRANSFORMATION:\n",
    "        tr_pred_df['true'] = np.exp(tr_pred_df['true'])\n",
    "    for i in range(len(kfold_models)):\n",
    "        tr_pred_df[f'pred_{i+1}'] = kfold_models[i].predict(train_dataset)\n",
    "        if CFG.TARGET_TRANSFORMATION:\n",
    "            tr_pred_df[f'pred_{i+1}'] = np.exp(tr_pred_df[f'pred_{i+1}'])\n",
    "    tr_pred_df.index = train_data.index\n",
    "    # (2) test\n",
    "    te_pred_df = pd.DataFrame()\n",
    "    for i in range(len(kfold_models)):\n",
    "        te_pred_df[f'pred_{i+1}'] = kfold_models[i].predict(test_dataset)\n",
    "        if CFG.TARGET_TRANSFORMATION:\n",
    "            te_pred_df[f'pred_{i+1}'] = np.exp(te_pred_df[f'pred_{i+1}'])\n",
    "    te_pred_df.index = test_data.index\n",
    "    \n",
    "    ## append\n",
    "    tr_pred_list.append(tr_pred_df)\n",
    "    te_pred_list.append(te_pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c509be6-eb68-4c18-94c6-1b1b30528801",
   "metadata": {},
   "source": [
    "<br>\n",
    "fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7efec0c8-23ea-4d9e-b83e-01988acf47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_fn.drop(target_feature,axis=1)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X = add_fuel_type(X,dummy_features)\n",
    "new_cat_features = cat_features + ['fuel_type']\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "# add predictions\n",
    "X      = pd.concat([X     ,tr_pred_df.drop('true',axis=1)],axis=1)\n",
    "X_test = pd.concat([X_test,te_pred_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17c9e7f5-c1c7-4dbf-9de7-229ce4512e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [toyota], Size: [3,259], KFold: [1/5]:   5%|▌         | 1/20 [04:44<1:29:59, 284.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment: skoda\n",
      "MAE's for 5-Fold: [[6.53776477 6.29479335 6.09450366 6.42935063 6.48182736]]\n",
      "Mean of MAE's for 5-Fold: [6.3676]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segment: [toyota], Size: [3,259], KFold: [3/5]:   5%|▌         | 1/20 [06:40<2:06:48, 400.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1b6590c7f81a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         model.fit(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5732\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5734\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5735\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5736\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m             \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2357\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   2358\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacking_models = {}\n",
    "stacking_feature_info = {}\n",
    "stacking_scores = []\n",
    "pbar = tqdm(segment_list)\n",
    "\n",
    "s_i = 0\n",
    "for segment in pbar:\n",
    "    s_i+=1\n",
    "    \n",
    "    # segment에 해당하는 데이터추출\n",
    "    _X = X[X.segment==segment].drop('segment',axis=1)\n",
    "    _y = y[X.segment==segment]\n",
    "    \n",
    "    # kfold\n",
    "    kf = KFold(n_splits=CFG.N_SPLITS,random_state=1000*s_i+CFG.SEED,shuffle=True)\n",
    "    \n",
    "    # unique인 컬럼 제외\n",
    "    unique_info = _X.nunique()\n",
    "    unique_cols = unique_info[unique_info==1].index.tolist()\n",
    "    if len(unique_cols)>0:\n",
    "        _X = _X.drop(unique_cols,axis=1)\n",
    "        \n",
    "    # categorical feature에서 unique인 컬럼을 제외\n",
    "    fixed_cat_features = [col for col in new_cat_features if col in _X.columns]\n",
    "    \n",
    "    _models = []\n",
    "    _scores = []\n",
    "    k=0\n",
    "    for tr_idx,val_idx in kf.split(_X,_y):\n",
    "        k+=1\n",
    "        \n",
    "        # kfold dataset\n",
    "        X_tr, X_va = _X.iloc[tr_idx], _X.iloc[val_idx]\n",
    "        y_tr, y_va = _y.iloc[tr_idx], _y.iloc[val_idx]\n",
    "\n",
    "        # progress\n",
    "        progress = 'Segment: [{}], Size: [{:,}], KFold: [{}/{}]'\\\n",
    "            .format(segment,len(_X),k,CFG.N_SPLITS)\n",
    "        pbar.set_description(progress)\n",
    "\n",
    "        # dataset\n",
    "        train_dataset = Pool(X_tr,y_tr,cat_features=fixed_cat_features)\n",
    "        valid_dataset = Pool(X_va,y_va,cat_features=fixed_cat_features)\n",
    "\n",
    "        # define the model\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function='MAE',\n",
    "            random_state=CFG.SEED,\n",
    "            iterations=CFG.EPOCHS,\n",
    "            learning_rate=CFG.LR,\n",
    "            allow_writing_files=False,\n",
    "        )\n",
    "\n",
    "        # fit the model\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            eval_set=valid_dataset,\n",
    "            early_stopping_rounds=CFG.ES,\n",
    "            verbose=0,\n",
    "            #metric_period=CFG.EPOCHS//5,\n",
    "        )\n",
    "\n",
    "        # save the model\n",
    "        model.save_model(f'./model_checkpoints/segment_catboost/{segment}_k{k}.cbm')\n",
    "\n",
    "        # prediction\n",
    "        y_pred = model.predict(valid_dataset).flatten()\n",
    "        y_true = y_va.values\n",
    "        \n",
    "        # inverse transform\n",
    "        if CFG.TARGET_TRANSFORMATION:\n",
    "            y_pred = np.exp(y_pred)\n",
    "            y_true = np.exp(y_true)\n",
    "            \n",
    "        # calculate score\n",
    "        score = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "        \n",
    "        # append inner loop\n",
    "        _models.append(model)\n",
    "        _scores.append([segment,k,len(X_tr),len(X_va),score])\n",
    "\n",
    "    # append outer loop\n",
    "    stacking_models[segment] = _models\n",
    "    stacking_scores.append(_scores)\n",
    "    stacking_feature_info[segment] = {'cat_features':fixed_cat_features,'features':_X.columns.tolist()}\n",
    "    \n",
    "    # score report\n",
    "    mean_score_report = pd.Series(np.array(_scores)[:,-1]).astype(float).mean()\n",
    "    print('Segment: {}'.format(segment))\n",
    "    print(\"MAE's for {}-Fold: [{}]\".format(CFG.N_SPLITS,np.array(pd.Series(np.array(_scores)[:,-1]).astype(float).values)))\n",
    "    print(\"Mean of MAE's for {}-Fold: [{:.4f}]\".format(CFG.N_SPLITS,mean_score_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512aecff-b50f-4ad8-8cbb-dd4d60ab6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(\n",
    "    np.array(stacking_scores).reshape(len(stacking_scores)*5,5),\n",
    "    columns=['segment','k','n_tr','n_val','score']\n",
    ")\n",
    "\n",
    "score_df.sort_values(['segment','k']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29985d8-a61f-42f5-bca9-29317ef9bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "X = add_fuel_type(X,dummy_features)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X_test = add_fuel_type(test_fn,dummy_features)\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "# add predictions\n",
    "X      = pd.concat([X     ,tr_pred_df.drop('true',axis=1)],axis=1)\n",
    "X_test = pd.concat([X_test,te_pred_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1de139-77ce-4346-9efd-a608e6327906",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pred_list = []\n",
    "te_pred_list = []\n",
    "for segment in tqdm(segment_list):\n",
    "    ## data load\n",
    "    # (1) train\n",
    "    train_data = X[X.segment==segment][stacking_feature_info[segment]['features']]\n",
    "    train_dataset = Pool(train_data,cat_features=stacking_feature_info[segment]['cat_features'])\n",
    "    # (2) test\n",
    "    test_data = X_test[X_test.segment==segment][stacking_feature_info[segment]['features']]\n",
    "    test_dataset = Pool(test_data,cat_features=stacking_feature_info[segment]['cat_features'])\n",
    "    \n",
    "    ## model\n",
    "    kfold_models = stacking_models[segment]\n",
    "    \n",
    "    ## prediction\n",
    "    # (1) train\n",
    "    tr_pred_df = pd.DataFrame({\n",
    "        'segment':segment,\n",
    "        'true':y[X.segment==segment].values.flatten(),\n",
    "        'pred':np.mean([model.predict(train_dataset) for model in kfold_models],axis=0),\n",
    "        #'pred':np.sum([weight*model.predict(train_dataset) for weight,model in zip(kfold_weights,kfold_models)],axis=0),\n",
    "    })\n",
    "    tr_pred_df.index = train_data.index\n",
    "    # (2) test\n",
    "    te_pred_df = pd.DataFrame({\n",
    "        'segment':segment,\n",
    "        'pred':np.mean([model.predict(test_dataset) for model in kfold_models],axis=0),\n",
    "        #'pred':np.sum([weight*model.predict(test_dataset) for weight,model in zip(kfold_weights,kfold_models)],axis=0),\n",
    "    })\n",
    "    te_pred_df.index = test_data.index\n",
    "    \n",
    "    ## Target Transformation\n",
    "    if CFG.TARGET_TRANSFORMATION:\n",
    "        tr_pred_df['true'] = np.exp(tr_pred_df['true'])\n",
    "        tr_pred_df['pred'] = np.exp(tr_pred_df['pred'])\n",
    "        te_pred_df['pred'] = np.exp(te_pred_df['pred'])\n",
    "    \n",
    "    ## append\n",
    "    tr_pred_list.append(tr_pred_df)\n",
    "    te_pred_list.append(te_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6804a7e-c52a-4bc1-950b-3b45a1505848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tr_pred_df = pd.concat(tr_pred_list,axis=0).sort_index()\n",
    "mean_absolute_error(y_true=tr_pred_df.true,y_pred=tr_pred_df.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834c15c-2ad2-49bd-9bd2-e06f7396a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred_df = pd.concat(te_pred_list,axis=0).sort_index()\n",
    "te_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d20c1-95ae-42bd-a0be-2933dca876b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['가격'] = te_pred_df.pred.values\n",
    "submit.to_csv('./out/14_cat_stacking_segment_브랜드_kfold_logy_interaction.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332771e9-7835-48bb-8325-e7258fddf664",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "(2) ensemble regressor : 5.6656766125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60abb74-4091-4dae-b324-68cebe32242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X_test = test_fn.copy()\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X,cat_features)\n",
    "X_oh = ohe.transform(X)\n",
    "X_test_oh = ohe.transform(X_test)\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "tr_pred_list = []\n",
    "te_pred_list = []\n",
    "for segment in tqdm(segment_list):\n",
    "    ## data load\n",
    "    # (1) train\n",
    "    train_data    = X   [X   .segment==segment][feature_info[segment]['features']]\n",
    "    train_data_oh = X_oh[X_oh.segment==segment][feature_info[segment]['oh_features']]\n",
    "    # (2) test\n",
    "    test_data     = X_test   [X_test   .segment==segment][feature_info[segment]['features']]\n",
    "    test_data_oh  = X_test_oh[X_test_oh.segment==segment][feature_info[segment]['oh_features']]\n",
    "    \n",
    "    ## model\n",
    "    kfold_models = models[segment]\n",
    "    \n",
    "    ## prediction\n",
    "    # (1) train\n",
    "    tr_pred_df = pd.DataFrame({\n",
    "        'true':y[X.segment==segment].values.flatten(),\n",
    "    })\n",
    "    for i in range(len(kfold_models)):\n",
    "        tr_pred_df[f'pred_{i+1}'] = kfold_models[i].predict(train_data,train_data_oh)\n",
    "    tr_pred_df.index = train_data.index\n",
    "    # (2) test\n",
    "    te_pred_df = pd.DataFrame()\n",
    "    for i in range(len(kfold_models)):\n",
    "        te_pred_df[f'pred_{i+1}'] = kfold_models[i].predict(test_data,test_data_oh)\n",
    "    te_pred_df.index = test_data.index\n",
    "        \n",
    "    ## target transformation\n",
    "    if CFG.TARGET_TRANSFORMATION:\n",
    "        tr_pred_df['true'] = np.exp(tr_pred_df['true'])\n",
    "    \n",
    "    ## append\n",
    "    tr_pred_list.append(tr_pred_df)\n",
    "    te_pred_list.append(te_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7113a0-4948-4d7a-bf7c-11da02d21ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tr_pred_df = pd.concat(tr_pred_list,axis=0).sort_index()\n",
    "te_pred_df = pd.concat(te_pred_list,axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88129d5f-d271-4719-8e3f-4bbfcdb9f29a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355f85c-0329-4d2b-a9dc-c693992be144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "X = add_fuel_type(X,dummy_features)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X_test = add_fuel_type(test_fn,dummy_features)\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "# add predictions\n",
    "X      = pd.concat([X     ,tr_pred_df.drop('true',axis=1)],axis=1)\n",
    "X_test = pd.concat([X_test,te_pred_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170aafb-28d2-40d4-9173-69e993c2404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_models = {}\n",
    "stacking_feature_info = {}\n",
    "stacking_scores = []\n",
    "pbar = tqdm(segment_list)\n",
    "\n",
    "s_i = 0\n",
    "for segment in pbar:\n",
    "    s_i+=1\n",
    "    \n",
    "    # segment에 해당하는 데이터추출\n",
    "    _X = X[X.segment==segment].drop('segment',axis=1)\n",
    "    _y = y[X.segment==segment]\n",
    "    \n",
    "    # kfold\n",
    "    kf = KFold(n_splits=CFG.N_SPLITS,random_state=1000*s_i+CFG.SEED,shuffle=True)\n",
    "    \n",
    "    # unique인 컬럼 제외\n",
    "    unique_info = _X.nunique()\n",
    "    unique_cols = unique_info[unique_info==1].index.tolist()\n",
    "    if len(unique_cols)>0:\n",
    "        _X = _X.drop(unique_cols,axis=1)\n",
    "        \n",
    "    # categorical feature에서 unique인 컬럼을 제외\n",
    "    fixed_cat_features = [col for col in new_cat_features if col in _X.columns]\n",
    "    \n",
    "    _models = []\n",
    "    _scores = []\n",
    "    k=0\n",
    "    for tr_idx,val_idx in kf.split(_X,_y):\n",
    "        k+=1\n",
    "        \n",
    "        # kfold dataset\n",
    "        X_tr, X_va = _X.iloc[tr_idx], _X.iloc[val_idx]\n",
    "        y_tr, y_va = _y.iloc[tr_idx], _y.iloc[val_idx]\n",
    "\n",
    "        # progress\n",
    "        progress = 'Segment: [{}], Size: [{:,}], KFold: [{}/{}]'\\\n",
    "            .format(segment,len(_X),k,CFG.N_SPLITS)\n",
    "        pbar.set_description(progress)\n",
    "\n",
    "        # dataset\n",
    "        train_dataset = Pool(X_tr,y_tr,cat_features=fixed_cat_features)\n",
    "        valid_dataset = Pool(X_va,y_va,cat_features=fixed_cat_features)\n",
    "\n",
    "        # define the model\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function='MAE',\n",
    "            random_state=CFG.SEED,\n",
    "            iterations=CFG.EPOCHS,\n",
    "            learning_rate=CFG.LR,\n",
    "            allow_writing_files=False,\n",
    "        )\n",
    "\n",
    "        # fit the model\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            eval_set=valid_dataset,\n",
    "            early_stopping_rounds=CFG.ES,\n",
    "            verbose=0,\n",
    "            #metric_period=CFG.EPOCHS//5,\n",
    "        )\n",
    "\n",
    "        # save the model\n",
    "        model.save_model(f'./model_checkpoints/segment_catboost/{segment}_k{k}.cbm')\n",
    "\n",
    "        # prediction\n",
    "        y_pred = model.predict(valid_dataset).flatten()\n",
    "        y_true = y_va.values\n",
    "        \n",
    "        # inverse transform\n",
    "        if CFG.TARGET_TRANSFORMATION:\n",
    "            y_pred = np.exp(y_pred)\n",
    "            y_true = np.exp(y_true)\n",
    "            \n",
    "        # calculate score\n",
    "        score = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "        \n",
    "        # append inner loop\n",
    "        _models.append(model)\n",
    "        _scores.append([segment,k,len(X_tr),len(X_va),score])\n",
    "\n",
    "    # append outer loop\n",
    "    stacking_models[segment] = _models\n",
    "    stacking_scores.append(_scores)\n",
    "    stacking_feature_info[segment] = {'cat_features':fixed_cat_features,'features':_X.columns.tolist()}\n",
    "    \n",
    "    # score report\n",
    "    mean_score_report = pd.Series(np.array(_scores)[:,-1]).astype(float).mean()\n",
    "    print('Segment: {}'.format(segment))\n",
    "    print(\"MAE's for {}-Fold: [{}]\".format(CFG.N_SPLITS,np.array(pd.Series(np.array(_scores)[:,-1]).astype(float).values)))\n",
    "    print(\"Mean of MAE's for {}-Fold: [{:.4f}]\".format(CFG.N_SPLITS,mean_score_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd68ad-d754-4ad4-a5a1-10c4683b7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model_checkpoints/segment_stacking_models_brand_kf.pkl', 'wb') as f:\n",
    "\tpickle.dump(stacking_models, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model_checkpoints/segment_stacking_feature_info_brand_kf.pkl', 'wb') as f:\n",
    "\tpickle.dump(stacking_feature_info, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model_checkpoints/segment_stacking_scores_brand_kf.pkl', 'wb') as f:\n",
    "\tpickle.dump(stacking_scores, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437fe9a-9d8e-4d74-bed8-4256401a3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(\n",
    "    np.array(stacking_scores).reshape(len(stacking_scores)*5,5),\n",
    "    columns=['segment','k','n_tr','n_val','score']\n",
    ")\n",
    "\n",
    "score_df.sort_values(['segment','k']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d620d4-45d8-4af5-97c9-f0ee66cdc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = train_fn.drop(target_feature,axis=1)\n",
    "X = add_fuel_type(X,dummy_features)\n",
    "y = train_fn[target_feature]\n",
    "\n",
    "X_test = add_fuel_type(test_fn,dummy_features)\n",
    "\n",
    "segment_list = X['segment'].unique()\n",
    "\n",
    "# add predictions\n",
    "X      = pd.concat([X     ,tr_pred_df.drop('true',axis=1)],axis=1)\n",
    "X_test = pd.concat([X_test,te_pred_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9ad98-aa92-41de-8d44-0e1e8d0297fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pred_list = []\n",
    "te_pred_list = []\n",
    "for segment in tqdm(segment_list):\n",
    "    ## data load\n",
    "    # (1) train\n",
    "    train_data = X[X.segment==segment][stacking_feature_info[segment]['features']]\n",
    "    train_dataset = Pool(train_data,cat_features=stacking_feature_info[segment]['cat_features'])\n",
    "    # (2) test\n",
    "    test_data = X_test[X_test.segment==segment][stacking_feature_info[segment]['features']]\n",
    "    test_dataset = Pool(test_data,cat_features=stacking_feature_info[segment]['cat_features'])\n",
    "    \n",
    "    ## model\n",
    "    kfold_models = stacking_models[segment]\n",
    "    \n",
    "    ## prediction\n",
    "    # (1) train\n",
    "    tr_pred_df = pd.DataFrame({\n",
    "        'segment':segment,\n",
    "        'true':y[X.segment==segment].values.flatten(),\n",
    "        'pred':np.mean([model.predict(train_dataset) for model in kfold_models],axis=0),\n",
    "        #'pred':np.sum([weight*model.predict(train_dataset) for weight,model in zip(kfold_weights,kfold_models)],axis=0),\n",
    "    })\n",
    "    tr_pred_df.index = train_data.index\n",
    "    # (2) test\n",
    "    te_pred_df = pd.DataFrame({\n",
    "        'segment':segment,\n",
    "        'pred':np.mean([model.predict(test_dataset) for model in kfold_models],axis=0),\n",
    "        #'pred':np.sum([weight*model.predict(test_dataset) for weight,model in zip(kfold_weights,kfold_models)],axis=0),\n",
    "    })\n",
    "    te_pred_df.index = test_data.index\n",
    "    \n",
    "    ## Target Transformation\n",
    "    if CFG.TARGET_TRANSFORMATION:\n",
    "        tr_pred_df['true'] = np.exp(tr_pred_df['true'])\n",
    "        tr_pred_df['pred'] = np.exp(tr_pred_df['pred'])\n",
    "        te_pred_df['pred'] = np.exp(te_pred_df['pred'])\n",
    "    \n",
    "    ## append\n",
    "    tr_pred_list.append(tr_pred_df)\n",
    "    te_pred_list.append(te_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39693550-8c3d-4ec1-b764-9d4e78494de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "tr_pred_df = pd.concat(tr_pred_list,axis=0).sort_index()\n",
    "mean_absolute_error(y_true=tr_pred_df.true,y_pred=tr_pred_df.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47710c5-ed65-4828-8267-9b2f9638e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred_df = pd.concat(te_pred_list,axis=0).sort_index()\n",
    "te_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6199fcc-6bc6-4689-a27d-36a1f9ad871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['가격'] = te_pred_df.pred.values\n",
    "submit.to_csv('./out/15_ensemble_stacking_segment_브랜드_kfold_logy_interaction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe5896-725e-4cf5-b9cf-07d3d7cc61eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
