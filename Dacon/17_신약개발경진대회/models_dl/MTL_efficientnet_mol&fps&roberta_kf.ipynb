{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4017e1",
   "metadata": {
    "id": "pYzhJrEibIlq"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4ebe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q rdkit\n",
    "# !pip install -q albumentations\n",
    "# !pip install accelerate -U\n",
    "# !pip install -q tokenizer\n",
    "# !pip install -q transformer\n",
    "\n",
    "# import accelerate\n",
    "# accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef87ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f74415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd734955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 0\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 512\n",
    "    LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd08720",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca811623",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ffd49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df  = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8492afa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             SMILES     MLM  \\\n",
       "0  TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n",
       "1  TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n",
       "2  TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n",
       "3  TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   \n",
       "4  TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n",
       "\n",
       "      HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
       "0  50.680  3.259           400.495                5             2   \n",
       "1  50.590  2.169           301.407                2             1   \n",
       "2  80.892  1.593           297.358                5             0   \n",
       "3   2.000  4.771           494.652                6             0   \n",
       "4  99.990  2.335           268.310                3             0   \n",
       "\n",
       "   Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  \n",
       "0                   8  3.259                      117.37  \n",
       "1                   2  2.172                       73.47  \n",
       "2                   3  1.585                       62.45  \n",
       "3                   5  3.475                       92.60  \n",
       "4                   1  2.337                       42.43  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3257508",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fe798",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6096d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ffeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = train_df.columns[train_df.dtypes!='object'].tolist()\n",
    "# for i,col in enumerate(num_features):\n",
    "\n",
    "#     fig = plt.figure(figsize=(15,7))\n",
    "#     fig.add_subplot(121)\n",
    "#     sns.histplot(train_df[col],bins=20)\n",
    "#     plt.grid()\n",
    "\n",
    "#     fig.add_subplot(122)\n",
    "#     sns.histplot(np.log(train_df[col]+1e-3),bins=20)\n",
    "#     plt.grid()\n",
    "\n",
    "#     plt.suptitle('[{}/{}] {}'.format(i+1,len(num_features),col))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # -> ['Molecular_Weight','Molecular_PolarSurfaceArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd746be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "# for col in cols:\n",
    "#     print(col)\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.scatterplot(x=train_df[col],y=train_df['HLM'])\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa30e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds']\n",
    "# for col in cols:\n",
    "#     print(col)\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.boxplot(x=train_df[col],y=train_df.MLM)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18aebe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4d54127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists = sorted(train_df['Num_H_Acceptors'].unique())\n",
    "# for v in lists:\n",
    "#     print('########',v)\n",
    "#     d = train_df[train_df['Num_H_Acceptors']==v]\n",
    "    \n",
    "#     cols = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "#     for col in cols:\n",
    "#         print(col)\n",
    "#         plt.figure(figsize=(15,7))\n",
    "#         sns.scatterplot(x=d[col],y=d['HLM'])\n",
    "#         plt.grid()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc8b34",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d3d67",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f856d5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e64c9",
   "metadata": {},
   "source": [
    "## Set target range to [0,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69478b",
   "metadata": {},
   "source": [
    "- [Dacon](https://dacon.io/competitions/official/236127/talkboard/409051?page=1&dtype=recent)에 따르면 100이 넘는 값도 나올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10e21ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = ['MLM','HLM']\n",
    "# for t in targets:\n",
    "#     train_df[t] = [0 if x<0 else\n",
    "#                    100 if x>100 else\n",
    "#                    x for x in train_df[t]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5eba9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7e47a",
   "metadata": {},
   "source": [
    "## Make molecule features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "282d8f27",
   "metadata": {
    "id": "oXOFfJVW22DL"
   },
   "outputs": [],
   "source": [
    "# Molecule to MorganFingerprint\n",
    "def mol2fp(mol):\n",
    "    #radius, nBits = 6, 4096\n",
    "    radius, nBits = 12, (2**10)*3\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, radius=radius, nBits=nBits)\n",
    "    ar = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b784479f",
   "metadata": {
    "id": "7KbqRv6I19Rg"
   },
   "outputs": [],
   "source": [
    "# (1) SMILES를 통해 Molecule(분자구조) 생성\n",
    "PandasTools.AddMoleculeColumnToFrame(train_df,'SMILES','Molecule')\n",
    "PandasTools.AddMoleculeColumnToFrame(test_df ,'SMILES','Molecule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df099df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff135d15",
   "metadata": {
    "id": "1MTlg0wx22DM"
   },
   "outputs": [],
   "source": [
    "# (2) Morgan Fingerprint column 추가\n",
    "train_df[\"FPs\"] = train_df.Molecule.apply(mol2fp)\n",
    "test_df [\"FPs\"] = test_df .Molecule.apply(mol2fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25994d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n"
     ]
    }
   ],
   "source": [
    "# (3) Morgan Fingerprint 중, variance가 0.05보다 작은 컬럼들을 지우기\n",
    "feature_select = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "# 일부사용\n",
    "tr_fps_selected = feature_select.fit_transform(np.stack(train_df['FPs']))\n",
    "te_fps_selected = feature_select.transform(np.stack(test_df['FPs']))\n",
    "print(tr_fps_selected.shape[1])\n",
    "\n",
    "# # 전체사용\n",
    "# tr_fps_selected = np.stack(train_df['FPs'])\n",
    "# te_fps_selected = np.stack(test_df ['FPs'])\n",
    "\n",
    "fps_names = ['fps'+str(i+1) for i in range(tr_fps_selected.shape[1])]\n",
    "\n",
    "train_df = pd.concat([train_df,pd.DataFrame(tr_fps_selected,columns=fps_names)],axis=1)\n",
    "test_df  = pd.concat([test_df ,pd.DataFrame(te_fps_selected,columns=fps_names)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "251af740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 column만 추출\n",
    "features = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors',\n",
    "            'Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "fps_feature = 'FPs'\n",
    "smiles_feature = 'SMILES'\n",
    "targets  = ['MLM','HLM']\n",
    "\n",
    "train_df = train_df[features+[fps_feature,smiles_feature]+targets] #fps_names\n",
    "test_df  = test_df[features+[fps_feature,smiles_feature]]          #fps_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50dd4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3498, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2a593dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "      <th>FPs</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  Num_RotatableBonds  \\\n",
       "0  3.259           400.495                5             2                   8   \n",
       "1  2.169           301.407                2             1                   2   \n",
       "2  1.593           297.358                5             0                   3   \n",
       "3  4.771           494.652                6             0                   5   \n",
       "4  2.335           268.310                3             0                   1   \n",
       "\n",
       "    LogD  Molecular_PolarSurfaceArea  \\\n",
       "0  3.259                      117.37   \n",
       "1  2.172                       73.47   \n",
       "2  1.585                       62.45   \n",
       "3  3.475                       92.60   \n",
       "4  2.337                       42.43   \n",
       "\n",
       "                                                 FPs  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              SMILES     MLM     HLM  \n",
       "0    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010  50.680  \n",
       "1               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270  50.590  \n",
       "2                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586  80.892  \n",
       "3  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   2.000  \n",
       "4                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270  99.990  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b4942",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a7b47",
   "metadata": {},
   "source": [
    "## Imputaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7976ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd8b8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_check(data):\n",
    "    d = data.copy()\n",
    "    null_info = d.isnull().sum()\n",
    "    null_info = null_info[null_info!=0]\n",
    "    display(null_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b362ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlogP    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlogP    1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('> train')\n",
    "null_check(train_df)\n",
    "\n",
    "print('> test')\n",
    "null_check(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4bbe616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_features = ['AlogP']\n",
    "\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# train_df[null_features] = imputer.fit_transform(train_df[null_features])\n",
    "# test_df [null_features] = imputer.transform(test_df[null_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad4a4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(features)-set(['AlogP']))\n",
    "train_df.drop('AlogP',axis=1,inplace=True)\n",
    "test_df .drop('AlogP',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e563ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('> train')\n",
    "null_check(train_df)\n",
    "\n",
    "print('> test')\n",
    "null_check(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3bb4f",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6264c",
   "metadata": {},
   "source": [
    "# Interaction Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f72cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction_maker = InteractionTerm()\n",
    "# interaction_maker.fit(\n",
    "#     data=train_df,\n",
    "#     num_features=features,\n",
    "#     corr_cutoff=0.8,\n",
    "# )\n",
    "# train_df = interaction_maker.transform(train_df)\n",
    "# test_df  = interaction_maker.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45133082",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd706f1b",
   "metadata": {},
   "source": [
    "# Tokenizer Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27d10228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d48177",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SMILES'].to_csv('./out/smiles.txt',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7223818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseTokenizer.save of Tokenizer(vocabulary_size=259, model=ByteLevelBPE, add_prefix_space=False, lowercase=False, dropout=None, unicode_normalizer=None, continuing_subword_prefix=None, end_of_word_suffix=None, trim_offsets=False)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 200\n",
    "special_tokens = [\"<s>\",\"<PAD>\",\"<MASK>\"]\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train('./out/smiles.txt', vocab_size=vocab_size, min_frequency=1, special_tokens=special_tokens)\n",
    "tokenizer.save_model('./mc/ByteLevelBPETokenizer')\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./mc/ByteLevelBPETokenizer/vocab.json\",\n",
    "    \"./mc/ByteLevelBPETokenizer/merges.txt\",\n",
    ")\n",
    "\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"<PAD>\" , tokenizer.token_to_id(\"<PAD>\")),\n",
    "    (\"<MASK>\", tokenizer.token_to_id(\"<MASK>\")),\n",
    ")\n",
    "\n",
    "tokenizer.enable_padding(length=600)\n",
    "tokenizer.save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10345dd3",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59738c3f",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf2caea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets, smiles, fps, fps_maximum, tokenizer, transforms=[None,None], is_test=False):\n",
    "        self.data = data.copy()\n",
    "        self.targets = targets\n",
    "        self.smiles = smiles\n",
    "        self.fps = fps\n",
    "        self.tokenizer = tokenizer\n",
    "        self.smiles_transforms, self.fps_transforms = transforms\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # self.smiles_features = []\n",
    "        # for s in tqdm(data[smiles].values,desc='Setup SMILES... '):\n",
    "        #     m = Chem.MolFromSmiles(s)\n",
    "        #     img = Draw.MolToImage(m)#, size=(224,224))\n",
    "        #     img = np.array(img)\n",
    "        #     if self.smiles_transforms is not None:\n",
    "        #         img = self.smiles_transforms(image=img)['image']\n",
    "        #     self.smiles_features.append(img)\n",
    "        # self.smiles_features = torch.stack(self.smiles_features)\n",
    "        \n",
    "        # fps_values = (np.stack(data[fps])/fps_maximum)*255 # max -> 255\n",
    "        # self.fps_features = []\n",
    "        # for f in fps_values:\n",
    "        #     img = f.reshape(32,32,3)\n",
    "        #     if self.fps_transforms is not None:\n",
    "        #         img = self.fps_transforms(image=img)['image']\n",
    "        #     self.fps_features.append(img)\n",
    "        \n",
    "        self.embedding = []\n",
    "        for s in data[smiles].values:\n",
    "            encoded = self.tokenizer.encode(s)\n",
    "            self.embedding.append(encoded.ids)\n",
    "            \n",
    "        if not self.is_test:\n",
    "            self.target_features = self.data[self.targets].values\n",
    "            self.num_features = self.data.drop(columns=targets+[fps,smiles],axis=1).values\n",
    "        else:\n",
    "            self.num_features = self.data.drop(columns=[fps,smiles],axis=1).values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            return (\n",
    "                torch.Tensor(self.num_features[index]),\n",
    "                #torch.Tensor(self.smiles_features[index]),\n",
    "                #torch.Tensor(self.fps_features[index]),\n",
    "                torch.tensor(self.embedding[index]),\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                torch.Tensor(self.num_features[index]),\n",
    "                #torch.Tensor(self.smiles_features[index]),\n",
    "                #torch.Tensor(self.fps_features[index]),\n",
    "                torch.tensor(self.embedding[index]),\n",
    "                torch.Tensor(self.target_features[index]),\n",
    "            )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bdea8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fb90de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # (1) smiles\n",
    "# s = tr_df['SMILES'].values[0]\n",
    "# m = Chem.MolFromSmiles(s)\n",
    "# img = Draw.MolToImage(m)#, size=(224,224))\n",
    "# img = np.array(img)\n",
    "# img = smiles_transform(image=img)['image']\n",
    "# img.shape\n",
    "# plt.imshow(img.T)\n",
    "\n",
    "# # (2) fps\n",
    "# fps_maximum = max(np.stack(tr_df.FPs).max(),np.stack(te_df.FPs).max())\n",
    "# fps_value = (np.stack(tr_df['FPs'])/fps_maximum)*255 # max -> 255\n",
    "\n",
    "# f = fps_value[0]\n",
    "# img = f.reshape(32,32,3)\n",
    "# img = img.astype(np.float32)\n",
    "# img = fps_transform(image=img)['image']\n",
    "# plt.imshow(img.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fef0b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  이미지 변환\n",
    "smiles_transform = A.Compose([\n",
    "    A.Resize(CFG.IMG_SIZE,CFG.IMG_SIZE),\n",
    "    A.ToGray(p=1),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "fps_transform = A.Compose([\n",
    "    A.Resize(CFG.IMG_SIZE,CFG.IMG_SIZE),\n",
    "    #A.ToGray(p=1),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9819896",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a12e41",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02859648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3a97c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiTaskModel(nn.Module):\n",
    "#     def __init__(self, feature_input_size, output_size, hidden_size, dropout_rate):\n",
    "#         super(MultiTaskModel, self).__init__()\n",
    "#         self.feature_output_size = 500\n",
    "#         self.dropout_rate = dropout_rate\n",
    "        \n",
    "#         # BatchNorm1d\n",
    "#         self.feature_layer = nn.Sequential(\n",
    "#             nn.Linear(feature_input_size,hidden_size),\n",
    "#             #nn.BatchNorm1d(hidden_size),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             #nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(hidden_size,hidden_size),\n",
    "#             #nn.BatchNorm1d(hidden_size),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             #nn.Dropout(self.dropout_rate),\n",
    "#             # nn.Linear(hidden_size,hidden_size),\n",
    "#             # nn.BatchNorm1d(hidden_size),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#             # nn.Dropout(self.dropout_rate),\n",
    "#             # nn.Linear(hidden_size,hidden_size),\n",
    "#             # nn.BatchNorm1d(hidden_size),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#             # nn.Dropout(self.dropout_rate),\n",
    "#             # nn.Linear(hidden_size,hidden_size),\n",
    "#         )\n",
    "#         self.mlm_layer = deepcopy(self.feature_layer)\n",
    "#         self.hlm_layer = deepcopy(self.feature_layer)\n",
    "        \n",
    "#         fc_input_size = 2*hidden_size\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(fc_input_size,fc_input_size//2),\n",
    "#             #nn.BatchNorm1d(fc_input_size//2),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             #nn.Dropout(self.dropout_rate),\n",
    "#             # nn.Linear(fc_input_size//2,fc_input_size//4),\n",
    "#             # nn.BatchNorm1d(fc_input_size//4),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#             # nn.Dropout(self.dropout_rate),\n",
    "#             # nn.Linear(fc_input_size//4,fc_input_size//8),\n",
    "#             # nn.BatchNorm1d(fc_input_size//8),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#             # nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(fc_input_size//2,output_size),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, feat, mol, fps):\n",
    "        \n",
    "#         mlm = self.mlm_layer(feat)\n",
    "#         hlm = self.hlm_layer(feat)\n",
    "        \n",
    "#         combined = torch.cat((mlm,hlm),dim=1)\n",
    "#         combined = self.fc(combined)\n",
    "        \n",
    "#         output = combined\n",
    "        \n",
    "#         # output = self.tanh(output)\n",
    "#         # output = (output+1)/2\n",
    "        \n",
    "#         #output = self.sigmoid(output)\n",
    "        \n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0d02a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiTaskModel(nn.Module):\n",
    "#     def __init__(self, feature_input_size, output_size, hidden_size, dropout_rate):\n",
    "#         super(MultiTaskModel, self).__init__()\n",
    "#         self.feature_output_size = 1000\n",
    "#         self.dropout_rate = dropout_rate\n",
    "        \n",
    "#         # BatchNorm1d\n",
    "#         self.feature_layer = nn.Sequential(\n",
    "#             nn.Linear(feature_input_size,hidden_size),\n",
    "#             nn.BatchNorm1d(hidden_size),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(hidden_size,hidden_size),\n",
    "#             nn.BatchNorm1d(hidden_size),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(hidden_size,hidden_size),\n",
    "#             nn.BatchNorm1d(hidden_size),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(hidden_size,hidden_size),\n",
    "#             nn.BatchNorm1d(hidden_size),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(hidden_size,self.feature_output_size),\n",
    "#         )\n",
    "        \n",
    "#         fc_input_size = self.feature_output_size\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(fc_input_size,fc_input_size//2),\n",
    "#             nn.BatchNorm1d(fc_input_size//2),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(fc_input_size//2,fc_input_size//4),\n",
    "#             nn.BatchNorm1d(fc_input_size//4),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(fc_input_size//4,fc_input_size//8),\n",
    "#             nn.BatchNorm1d(fc_input_size//8),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(fc_input_size//8,output_size),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, feat, mol, fps):\n",
    "#         feat = self.feature_layer(feat)\n",
    "#         #mol = self.mol_layer(mol)\n",
    "#         #fps = self.fps_layer(fps)\n",
    "#         feat = self.fc(feat)\n",
    "        \n",
    "#         output = feat\n",
    "        \n",
    "#         # output = self.tanh(output)\n",
    "#         # output = (output+1)/2\n",
    "        \n",
    "#         #output = self.sigmoid(output)\n",
    "        \n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e8583f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiTaskModel(nn.Module):\n",
    "#     def __init__(self, feature_input_size, output_size, hidden_size, dropout_rate):\n",
    "#         super(MultiTaskModel, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.dropout_rate = dropout_rate\n",
    "#         self.image_output_size = 50\n",
    "#         self.feature_output_size = 100\n",
    "        \n",
    "#         self.lstm1 = nn.LSTM(feature_input_size,hidden_size,num_layers=1,batch_first=True)\n",
    "#         self.lstm2 = nn.LSTM(hidden_size,hidden_size,num_layers=1,batch_first=True)\n",
    "#         self.lstm3 = nn.LSTM(hidden_size,hidden_size,num_layers=1,batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_size,output_size)\n",
    "#         self.bn = nn.BatchNorm1d(hidden_size)\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "#         self.activation = nn.LeakyReLU(0.01)\n",
    "\n",
    "#     def forward(self, feat, mol, fps):\n",
    "#         x = feat\n",
    "#         h0 = torch.zeros(1, self.hidden_size).to(x.device) \n",
    "#         c0 = torch.zeros(1, self.hidden_size).to(x.device)\n",
    "        \n",
    "#         x, (hn,cn) = self.lstm1(x,(h0,c0))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "#         x, (hn,cn) = self.lstm2(x,(hn,cn))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "#         x, (hn,cn) = self.lstm3(x,(hn,cn))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.activation(x)\n",
    "        \n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b7542fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiTaskModel(nn.Module):\n",
    "#     def __init__(self, feature_input_size, output_size, hidden_size, dropout_rate):\n",
    "#         super(MultiTaskModel, self).__init__()\n",
    "#         self.image_output_size = 50\n",
    "#         self.feature_output_size = 100\n",
    "#         self.dropout_rate = dropout_rate\n",
    "        \n",
    "#         self.activation = nn.Tanh()\n",
    "        \n",
    "#         # efficientnet\n",
    "#         self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "#         self.backbone.classifier = nn.Sequential(\n",
    "#             nn.Dropout(p=0.2,inplace=True),\n",
    "#             nn.Linear(self.backbone.classifier[-1].in_features,self.image_output_size),\n",
    "#         )\n",
    "#         self.mol_backbone = deepcopy(self.backbone)\n",
    "#         self.fps_backbone = deepcopy(self.backbone)\n",
    "        \n",
    "#         # # resnet\n",
    "#         # self.backbone = models.resnet18(pretrained=True)\n",
    "#         # self.backbone.fc = nn.Linear(self.backbone.fc.in_features,self.image_output_size)\n",
    "        \n",
    "#         self.mol_layer = nn.Sequential(\n",
    "#             self.mol_backbone,\n",
    "#             #nn.BatchNorm1d(self.image_output_size),\n",
    "#             #self.activation,\n",
    "#             #nn.Dropout(self.dropout_rate),\n",
    "#         )\n",
    "#         self.fps_layer = nn.Sequential(\n",
    "#             self.fps_backbone,\n",
    "#             #nn.BatchNorm1d(self.image_output_size),\n",
    "#             #self.activation,\n",
    "#             #nn.Dropout(self.dropout_rate),\n",
    "#         )\n",
    "        \n",
    "#         self.feature_layer = nn.Sequential(\n",
    "#             nn.Linear(feature_input_size,hidden_size),\n",
    "#             #nn.BatchNorm1d(hidden_size),\n",
    "#             self.activation,\n",
    "#             #nn.Dropout(self.dropout_rate),\n",
    "#             nn.Linear(hidden_size,self.feature_output_size),\n",
    "#         )\n",
    "        \n",
    "#         combined_input_size = self.feature_output_size # 2*self.image_output_size+\n",
    "#         self.lstm = nn.LSTM(combined_input_size, combined_input_size//4, num_layers=2, batch_first=True)\n",
    "#         self.fc = nn.Linear(combined_input_size//4,output_size)\n",
    "        \n",
    "#     def forward(self, feat, mol, fps):\n",
    "#         feat = self.feature_layer(feat)\n",
    "#         mol = self.mol_layer(mol)\n",
    "#         fps = self.fps_layer(fps)\n",
    "#         combined = torch.cat((feat,mol,fps),dim=1)\n",
    "#         combined, _ = self.lstm(combined)\n",
    "#         combined = self.activation(combined)\n",
    "#         combined = self.fc(combined)\n",
    "#         return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5406f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, feature_input_size, vocab_size, output_size, hidden_size, dropout_rate):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.image_output_size = 16\n",
    "        self.feature_output_size = 32\n",
    "        self.embedding_output_size = 32\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # efficientnet\n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2,inplace=True),\n",
    "            nn.Linear(self.backbone.classifier[-1].in_features,self.image_output_size),\n",
    "        )\n",
    "        \n",
    "        # # resnet\n",
    "        # self.backbone = models.resnet18(pretrained=True)\n",
    "        # self.backbone.fc = nn.Linear(self.backbone.fc.in_features,self.image_output_size)\n",
    "        \n",
    "        self.mol_layer = nn.Sequential(\n",
    "            deepcopy(self.backbone),\n",
    "            #nn.BatchNorm1d(self.image_output_size),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(self.dropout_rate),\n",
    "        )\n",
    "        self.fps_layer = nn.Sequential(\n",
    "            deepcopy(self.backbone),\n",
    "            #nn.BatchNorm1d(self.image_output_size),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(self.dropout_rate),\n",
    "        )\n",
    "        \n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(feature_input_size,hidden_size),\n",
    "            #nn.BatchNorm1d(hidden_size),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            #nn.BatchNorm1d(hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size, self.embedding_output_size),\n",
    "        )\n",
    "        \n",
    "        self.emb_layer = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.emb_sequence = nn.Sequential(\n",
    "            #nn.BatchNorm1d(hidden_size),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            #nn.BatchNorm1d(hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size, self.embedding_output_size),\n",
    "        )\n",
    "        \n",
    "        fc_input_size = self.feature_output_size+self.embedding_output_size #2*self.image_output_size\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_input_size,2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, feat, emb):\n",
    "        feat = self.feature_layer(feat)\n",
    "        #mol = self.mol_layer(mol)\n",
    "        #fps = self.fps_layer(fps)\n",
    "        emb = self.emb_layer(emb).mean(dim=1)\n",
    "        emb = self.emb_sequence(emb)\n",
    "        \n",
    "        combined = torch.cat((feat,emb),dim=1)\n",
    "        output = self.fc(combined)\n",
    "        \n",
    "        # output = self.tanh(output)\n",
    "        # output = (output+1.0)/2.0\n",
    "        # output = output*100.0\n",
    "        \n",
    "        # output = self.sigmoid(output)\n",
    "        # output = output*100\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113a7d6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379adc4",
   "metadata": {},
   "source": [
    "# Train & Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "daa00385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiRMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        loss1 = torch.sqrt(torch.mean((output[:,0]-target[:,0])**2))\n",
    "        loss2 = torch.sqrt(torch.mean((output[:,1]-target[:,1])**2))\n",
    "        loss = 0.5*loss1+0.5*loss2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a663723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        if self.path!='':\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "        \n",
    "def train(\n",
    "    model, criterion, optimizer, train_loader, valid_loader, epochs,\n",
    "    early_stopping, device='cpu', scheduler=None, metric_period=1, verbose=True, \n",
    "    save_model_path = './mc/best_model.pt', final_model_path = './mc/final_model.pt',\n",
    "    use_best_model=True,\n",
    "    inverse_transform=None,\n",
    "):  \n",
    "    seed_everything(CFG.SEED)\n",
    "    model.to(device)\n",
    "\n",
    "    best_loss  = 999999999\n",
    "    best_epoch = 1\n",
    "    best_model = None\n",
    "    is_best    = np.nan\n",
    "    \n",
    "    start_time = time.time()\n",
    "    epoch_s = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        gc.collect()\n",
    "        \n",
    "        #model.train()\n",
    "        train_loss = []\n",
    "        for feat,emb,target in train_loader:\n",
    "            feat = feat.to(device)\n",
    "            #mol = mol.to(device)\n",
    "            #fps = fps.to(device)\n",
    "            emb = emb.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(feat,emb).float()\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()  # Getting gradients\n",
    "            optimizer.step() # Updating parameters\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            valid_loss = validation(model, valid_loader, criterion, device, inverse_transform)\n",
    "        else:\n",
    "            valid_loss = loss\n",
    "            \n",
    "        epoch_e = time.time()\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        # update the best epoch & best loss\n",
    "        if (best_loss > valid_loss) | (epoch==1):\n",
    "            best_epoch = epoch\n",
    "            best_loss = valid_loss\n",
    "            best_model = model\n",
    "            is_best = 1\n",
    "            torch.save(best_model.state_dict(), save_model_path)\n",
    "        else:\n",
    "            is_best = 0\n",
    "            if not use_best_model:\n",
    "                torch.save(best_model.state_dict(), save_model_path)\n",
    "            \n",
    "        # 결과물 printing\n",
    "        if (verbose) & (epoch % metric_period == 0):\n",
    "            mark = '*' if is_best else ' '\n",
    "            epoch_str = str(epoch).zfill(len(str(epochs)))\n",
    "            if valid_loader is not None:\n",
    "                progress = '{}[{}/{}] loss: {:.5f}, val_loss: {:.5f}, best_epoch: {}, elapsed: {:.2f}s, total: {:.2f}s, remaining: {:.2f}s'\\\n",
    "                    .format(\n",
    "                        mark,\n",
    "                        epoch_str,\n",
    "                        epochs,\n",
    "                        np.mean(train_loss),\n",
    "                        valid_loss,\n",
    "                        best_epoch,\n",
    "                        epoch_e-epoch_s,\n",
    "                        epoch_e-start_time,\n",
    "                        (epoch_e-epoch_s)*(epochs-epoch)/metric_period,\n",
    "                    )\n",
    "            else:\n",
    "                progress = '{}[{}/{}] loss: {:.5f}, best_epoch: {}, elapsed: {:.2f}s, total: {:.2f}s, remaining: {:.2f}s'\\\n",
    "                    .format(\n",
    "                        mark,\n",
    "                        epoch_str,\n",
    "                        epochs,\n",
    "                        np.mean(train_loss),\n",
    "                        best_epoch,\n",
    "                        epoch_e-epoch_s,\n",
    "                        epoch_e-start_time,\n",
    "                        (epoch_e-epoch_s)*(epochs-epoch)/metric_period,\n",
    "                    )\n",
    "            epoch_s = time.time()\n",
    "            print(progress)\n",
    "\n",
    "        # early stopping 여부를 체크. 현재 과적합 상황 추적\n",
    "        if early_stopping is not None:\n",
    "            early_stopping(valid_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "                \n",
    "        torch.save(best_model.state_dict(), final_model_path)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def validation(model, valid_loader, criterion, device, inverse_transform):\n",
    "    valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for feat,emb,target in valid_loader:\n",
    "            feat = feat.to(device)\n",
    "            #mol = mol.to(device)\n",
    "            #fps = fps.to(device)\n",
    "            emb = emb.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(feat,emb).float()\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242653b1",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b067a",
   "metadata": {},
   "source": [
    "# K-Fold Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eda36c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import trange\n",
    "\n",
    "def get_abs_corr(x,y):\n",
    "    return np.abs(np.corrcoef(x,y))[0,1]\n",
    "\n",
    "class InteractionTerm:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,num_features,corr_cutoff=0.7):\n",
    "        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        \n",
    "        d = data.copy()\n",
    "        self.interaction_list = []\n",
    "        for i in trange(len(num_features),desc='fitting...'):\n",
    "            for j in range(len(num_features)):\n",
    "                if i>j:\n",
    "                    col_i = num_features[i]\n",
    "                    col_j = num_features[j]\n",
    "                    \n",
    "                    # 상관계수가 cutoff보다 큰 경우에는 interaction을 생성하지 않음\n",
    "                    if (get_abs_corr(d[col_i]*d[col_j],d[col_i])>=corr_cutoff) | (get_abs_corr(d[col_i]*d[col_j],d[col_j])>=corr_cutoff):\n",
    "                        pass\n",
    "                    else:\n",
    "                        self.interaction_list.append(f'{col_i}*{col_j}')\n",
    "    \n",
    "    def transform(self,data):\n",
    "        d = data.copy()\n",
    "        print('> the number of interaction term:',len(self.interaction_list))\n",
    "        for interaction in self.interaction_list:\n",
    "            col_i,col_j = interaction.split('*')\n",
    "            d[interaction] = d[col_i]*d[col_j]\n",
    "        return d\n",
    "    \n",
    "    def fit_transform(self,data,num_features,corr_cutoff=0.7):\n",
    "        self.fit(data,num_features,corr_cutoff)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80cab755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f11de47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_features = [col for col in train_df.columns if col.find('*')>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf6d307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_maximum = max(np.stack(train_df.FPs).max(),np.stack(test_df.FPs).max())\n",
    "\n",
    "feature_input_size = len(features) + len(interaction_features)\n",
    "output_size = 2\n",
    "hidden_size = 32\n",
    "dropout_rate = 0.00\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daca5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "> K-Fold: 1\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[001/512] loss: 37.77555, val_loss: 33.85527, best_epoch: 1, elapsed: 0.83s, total: 0.83s, remaining: 426.67s\n",
      " [002/512] loss: 32.58034, val_loss: 34.02709, best_epoch: 1, elapsed: 1.02s, total: 2.05s, remaining: 519.40s\n",
      " [003/512] loss: 32.44486, val_loss: 33.87916, best_epoch: 1, elapsed: 1.02s, total: 3.07s, remaining: 521.42s\n",
      "*[004/512] loss: 32.35245, val_loss: 33.75582, best_epoch: 4, elapsed: 1.02s, total: 4.10s, remaining: 519.63s\n",
      "*[005/512] loss: 32.27905, val_loss: 33.64662, best_epoch: 5, elapsed: 1.01s, total: 5.30s, remaining: 514.14s\n",
      "*[006/512] loss: 32.21673, val_loss: 33.53580, best_epoch: 6, elapsed: 1.02s, total: 6.50s, remaining: 515.74s\n",
      "*[007/512] loss: 32.15913, val_loss: 33.43187, best_epoch: 7, elapsed: 1.01s, total: 7.71s, remaining: 512.38s\n",
      "*[008/512] loss: 32.10520, val_loss: 33.34493, best_epoch: 8, elapsed: 1.02s, total: 8.91s, remaining: 512.11s\n",
      "*[009/512] loss: 32.05656, val_loss: 33.26248, best_epoch: 9, elapsed: 1.02s, total: 10.12s, remaining: 512.69s\n",
      "*[010/512] loss: 32.01302, val_loss: 33.17427, best_epoch: 10, elapsed: 1.01s, total: 11.32s, remaining: 509.43s\n",
      "*[011/512] loss: 31.97157, val_loss: 33.08946, best_epoch: 11, elapsed: 1.03s, total: 12.54s, remaining: 515.09s\n",
      "*[012/512] loss: 31.93203, val_loss: 33.01179, best_epoch: 12, elapsed: 1.02s, total: 13.75s, remaining: 510.06s\n",
      "*[013/512] loss: 31.89456, val_loss: 32.94106, best_epoch: 13, elapsed: 1.03s, total: 14.98s, remaining: 515.63s\n",
      "*[014/512] loss: 31.85924, val_loss: 32.87777, best_epoch: 14, elapsed: 1.03s, total: 16.22s, remaining: 512.98s\n",
      "*[015/512] loss: 31.82614, val_loss: 32.82331, best_epoch: 15, elapsed: 1.03s, total: 17.45s, remaining: 511.58s\n",
      "*[016/512] loss: 31.79607, val_loss: 32.78126, best_epoch: 16, elapsed: 1.03s, total: 18.68s, remaining: 511.73s\n",
      "*[017/512] loss: 31.76485, val_loss: 32.75213, best_epoch: 17, elapsed: 1.02s, total: 19.90s, remaining: 506.65s\n",
      "*[018/512] loss: 31.74425, val_loss: 32.72226, best_epoch: 18, elapsed: 1.02s, total: 21.12s, remaining: 506.07s\n",
      "*[019/512] loss: 31.71740, val_loss: 32.69322, best_epoch: 19, elapsed: 1.04s, total: 22.35s, remaining: 511.00s\n",
      "*[020/512] loss: 31.69562, val_loss: 32.68362, best_epoch: 20, elapsed: 1.03s, total: 23.58s, remaining: 507.25s\n",
      "*[021/512] loss: 31.67216, val_loss: 32.67010, best_epoch: 21, elapsed: 1.03s, total: 24.81s, remaining: 505.31s\n",
      "*[022/512] loss: 31.64925, val_loss: 32.66648, best_epoch: 22, elapsed: 1.03s, total: 26.04s, remaining: 505.56s\n",
      "*[023/512] loss: 31.63138, val_loss: 32.64596, best_epoch: 23, elapsed: 1.03s, total: 27.26s, remaining: 501.31s\n",
      "*[024/512] loss: 31.61289, val_loss: 32.64151, best_epoch: 24, elapsed: 1.03s, total: 28.48s, remaining: 500.50s\n",
      "*[025/512] loss: 31.59529, val_loss: 32.62029, best_epoch: 25, elapsed: 1.02s, total: 29.69s, remaining: 497.64s\n",
      "*[026/512] loss: 31.57777, val_loss: 32.60752, best_epoch: 26, elapsed: 1.02s, total: 30.89s, remaining: 493.82s\n",
      "*[027/512] loss: 31.56317, val_loss: 32.59749, best_epoch: 27, elapsed: 1.02s, total: 32.10s, remaining: 492.34s\n",
      "*[028/512] loss: 31.54801, val_loss: 32.58934, best_epoch: 28, elapsed: 1.02s, total: 33.31s, remaining: 495.58s\n",
      "*[029/512] loss: 31.53377, val_loss: 32.57348, best_epoch: 29, elapsed: 1.02s, total: 34.52s, remaining: 493.38s\n",
      "*[030/512] loss: 31.52004, val_loss: 32.56380, best_epoch: 30, elapsed: 1.02s, total: 35.73s, remaining: 491.06s\n",
      "*[031/512] loss: 31.50381, val_loss: 32.55497, best_epoch: 31, elapsed: 1.02s, total: 36.94s, remaining: 491.07s\n",
      "*[032/512] loss: 31.49529, val_loss: 32.52126, best_epoch: 32, elapsed: 1.03s, total: 38.15s, remaining: 492.65s\n",
      "*[033/512] loss: 31.48125, val_loss: 32.51372, best_epoch: 33, elapsed: 1.02s, total: 39.36s, remaining: 488.51s\n",
      "*[034/512] loss: 31.46927, val_loss: 32.50095, best_epoch: 34, elapsed: 1.02s, total: 40.57s, remaining: 486.76s\n",
      "*[035/512] loss: 31.45847, val_loss: 32.48325, best_epoch: 35, elapsed: 1.02s, total: 41.78s, remaining: 488.14s\n",
      "*[036/512] loss: 31.44948, val_loss: 32.46333, best_epoch: 36, elapsed: 1.02s, total: 43.00s, remaining: 486.85s\n",
      "*[037/512] loss: 31.43613, val_loss: 32.43290, best_epoch: 37, elapsed: 1.03s, total: 44.22s, remaining: 487.79s\n",
      "*[038/512] loss: 31.42643, val_loss: 32.42581, best_epoch: 38, elapsed: 1.03s, total: 45.44s, remaining: 486.36s\n",
      "*[039/512] loss: 31.41452, val_loss: 32.40339, best_epoch: 39, elapsed: 1.03s, total: 46.67s, remaining: 485.57s\n",
      " [040/512] loss: 31.40453, val_loss: 32.40647, best_epoch: 39, elapsed: 1.02s, total: 47.89s, remaining: 482.80s\n",
      "*[041/512] loss: 31.39511, val_loss: 32.37438, best_epoch: 41, elapsed: 1.03s, total: 48.92s, remaining: 484.17s\n",
      "*[042/512] loss: 31.38524, val_loss: 32.35859, best_epoch: 42, elapsed: 1.02s, total: 50.14s, remaining: 481.26s\n",
      "*[043/512] loss: 31.37503, val_loss: 32.34314, best_epoch: 43, elapsed: 1.02s, total: 51.36s, remaining: 479.00s\n",
      "*[044/512] loss: 31.36545, val_loss: 32.33466, best_epoch: 44, elapsed: 1.04s, total: 52.59s, remaining: 485.08s\n",
      "*[045/512] loss: 31.35798, val_loss: 32.31661, best_epoch: 45, elapsed: 1.03s, total: 53.81s, remaining: 480.82s\n",
      "*[046/512] loss: 31.35062, val_loss: 32.31167, best_epoch: 46, elapsed: 1.03s, total: 55.03s, remaining: 480.19s\n",
      "*[047/512] loss: 31.34131, val_loss: 32.30283, best_epoch: 47, elapsed: 1.02s, total: 56.25s, remaining: 476.09s\n",
      "*[048/512] loss: 31.33390, val_loss: 32.28727, best_epoch: 48, elapsed: 1.02s, total: 57.47s, remaining: 474.10s\n",
      "*[049/512] loss: 31.32671, val_loss: 32.28336, best_epoch: 49, elapsed: 1.02s, total: 58.68s, remaining: 472.71s\n",
      "*[050/512] loss: 31.31776, val_loss: 32.27095, best_epoch: 50, elapsed: 1.02s, total: 59.88s, remaining: 469.61s\n",
      "*[051/512] loss: 31.30833, val_loss: 32.26541, best_epoch: 51, elapsed: 1.02s, total: 61.09s, remaining: 468.39s\n",
      "*[052/512] loss: 31.30183, val_loss: 32.25607, best_epoch: 52, elapsed: 1.02s, total: 62.29s, remaining: 468.59s\n",
      "*[053/512] loss: 31.29501, val_loss: 32.25348, best_epoch: 53, elapsed: 1.02s, total: 63.46s, remaining: 467.46s\n",
      "*[054/512] loss: 31.28858, val_loss: 32.24056, best_epoch: 54, elapsed: 1.01s, total: 64.65s, remaining: 464.41s\n",
      "*[055/512] loss: 31.28125, val_loss: 32.23399, best_epoch: 55, elapsed: 1.02s, total: 65.86s, remaining: 465.19s\n",
      "*[056/512] loss: 31.27384, val_loss: 32.22474, best_epoch: 56, elapsed: 1.02s, total: 67.07s, remaining: 463.78s\n",
      "*[057/512] loss: 31.26753, val_loss: 32.22464, best_epoch: 57, elapsed: 1.03s, total: 68.28s, remaining: 468.13s\n",
      "*[058/512] loss: 31.26150, val_loss: 32.21973, best_epoch: 58, elapsed: 1.02s, total: 69.49s, remaining: 461.94s\n",
      "*[059/512] loss: 31.25524, val_loss: 32.21275, best_epoch: 59, elapsed: 1.02s, total: 70.70s, remaining: 463.85s\n",
      "*[060/512] loss: 31.25039, val_loss: 32.20965, best_epoch: 60, elapsed: 1.02s, total: 71.91s, remaining: 460.60s\n",
      "*[061/512] loss: 31.24377, val_loss: 32.20499, best_epoch: 61, elapsed: 1.02s, total: 73.12s, remaining: 459.81s\n",
      "*[062/512] loss: 31.23618, val_loss: 32.19764, best_epoch: 62, elapsed: 1.02s, total: 74.33s, remaining: 457.71s\n",
      "*[063/512] loss: 31.22870, val_loss: 32.19370, best_epoch: 63, elapsed: 1.03s, total: 75.56s, remaining: 460.81s\n",
      "*[064/512] loss: 31.22257, val_loss: 32.18708, best_epoch: 64, elapsed: 1.03s, total: 76.78s, remaining: 460.99s\n",
      " [065/512] loss: 31.21902, val_loss: 32.19059, best_epoch: 64, elapsed: 1.03s, total: 78.00s, remaining: 460.48s\n",
      " [066/512] loss: 31.21092, val_loss: 32.18741, best_epoch: 64, elapsed: 1.04s, total: 79.04s, remaining: 462.14s\n",
      "*[067/512] loss: 31.20438, val_loss: 32.18486, best_epoch: 67, elapsed: 1.03s, total: 80.07s, remaining: 459.63s\n",
      "*[068/512] loss: 31.19974, val_loss: 32.16003, best_epoch: 68, elapsed: 1.03s, total: 81.30s, remaining: 457.45s\n",
      "*[069/512] loss: 31.20264, val_loss: 32.15803, best_epoch: 69, elapsed: 1.03s, total: 82.52s, remaining: 455.81s\n",
      " [070/512] loss: 31.21133, val_loss: 32.17884, best_epoch: 69, elapsed: 1.03s, total: 83.76s, remaining: 456.52s\n",
      "*[071/512] loss: 31.18915, val_loss: 32.15739, best_epoch: 71, elapsed: 1.03s, total: 84.79s, remaining: 454.77s\n",
      " [072/512] loss: 31.17730, val_loss: 32.16095, best_epoch: 71, elapsed: 1.04s, total: 86.02s, remaining: 457.20s\n",
      " [073/512] loss: 31.17471, val_loss: 32.16315, best_epoch: 71, elapsed: 1.03s, total: 87.05s, remaining: 453.71s\n",
      " [074/512] loss: 31.16389, val_loss: 32.18371, best_epoch: 71, elapsed: 1.03s, total: 88.08s, remaining: 449.33s\n",
      "*[075/512] loss: 31.15706, val_loss: 32.13665, best_epoch: 75, elapsed: 1.04s, total: 89.12s, remaining: 452.92s\n",
      "*[076/512] loss: 31.16347, val_loss: 32.13141, best_epoch: 76, elapsed: 1.03s, total: 90.33s, remaining: 450.11s\n",
      "*[077/512] loss: 31.17815, val_loss: 32.12408, best_epoch: 77, elapsed: 1.03s, total: 91.55s, remaining: 448.95s\n",
      "*[078/512] loss: 31.16865, val_loss: 32.12377, best_epoch: 78, elapsed: 1.10s, total: 92.85s, remaining: 479.07s\n",
      " [079/512] loss: 31.16484, val_loss: 32.13404, best_epoch: 78, elapsed: 0.99s, total: 94.03s, remaining: 430.53s\n",
      "*[080/512] loss: 31.14342, val_loss: 32.11588, best_epoch: 80, elapsed: 1.02s, total: 95.05s, remaining: 442.67s\n",
      " [081/512] loss: 31.13839, val_loss: 32.12367, best_epoch: 80, elapsed: 1.03s, total: 96.27s, remaining: 444.39s\n",
      "*[082/512] loss: 31.13194, val_loss: 32.11345, best_epoch: 82, elapsed: 1.02s, total: 97.30s, remaining: 439.88s\n",
      " [083/512] loss: 31.12235, val_loss: 32.12026, best_epoch: 82, elapsed: 1.02s, total: 98.50s, remaining: 435.48s\n",
      " [084/512] loss: 31.11806, val_loss: 32.12161, best_epoch: 82, elapsed: 1.02s, total: 99.53s, remaining: 438.21s\n",
      " [085/512] loss: 31.11429, val_loss: 32.11699, best_epoch: 82, elapsed: 1.03s, total: 100.55s, remaining: 437.83s\n",
      " [086/512] loss: 31.11304, val_loss: 32.11835, best_epoch: 82, elapsed: 1.03s, total: 101.58s, remaining: 439.30s\n",
      " [087/512] loss: 31.11628, val_loss: 32.11610, best_epoch: 82, elapsed: 1.03s, total: 102.62s, remaining: 438.87s\n",
      "*[088/512] loss: 31.11513, val_loss: 32.11001, best_epoch: 88, elapsed: 1.03s, total: 103.65s, remaining: 436.75s\n",
      "*[089/512] loss: 31.11308, val_loss: 32.08515, best_epoch: 89, elapsed: 1.04s, total: 104.88s, remaining: 437.89s\n",
      " [090/512] loss: 31.11715, val_loss: 32.10007, best_epoch: 89, elapsed: 1.04s, total: 106.11s, remaining: 438.34s\n",
      " [091/512] loss: 31.08977, val_loss: 32.09572, best_epoch: 89, elapsed: 1.04s, total: 107.16s, remaining: 438.63s\n",
      " [092/512] loss: 31.08090, val_loss: 32.10271, best_epoch: 89, elapsed: 1.05s, total: 108.20s, remaining: 440.16s\n",
      " [093/512] loss: 31.08017, val_loss: 32.09359, best_epoch: 89, elapsed: 1.06s, total: 109.27s, remaining: 444.53s\n",
      " [094/512] loss: 31.08394, val_loss: 32.10323, best_epoch: 89, elapsed: 1.05s, total: 110.32s, remaining: 440.50s\n",
      " [095/512] loss: 31.07936, val_loss: 32.10254, best_epoch: 89, elapsed: 1.04s, total: 111.36s, remaining: 432.28s\n",
      " [096/512] loss: 30.85365, val_loss: 32.26982, best_epoch: 89, elapsed: 1.05s, total: 112.41s, remaining: 437.62s\n",
      " [097/512] loss: 30.86044, val_loss: 32.27911, best_epoch: 89, elapsed: 1.05s, total: 113.46s, remaining: 436.35s\n",
      " [098/512] loss: 30.85550, val_loss: 32.27878, best_epoch: 89, elapsed: 1.05s, total: 114.50s, remaining: 432.74s\n",
      " [099/512] loss: 30.85086, val_loss: 32.27598, best_epoch: 89, elapsed: 1.04s, total: 115.55s, remaining: 431.11s\n",
      " [100/512] loss: 30.84701, val_loss: 32.27309, best_epoch: 89, elapsed: 1.04s, total: 116.59s, remaining: 429.82s\n",
      " [101/512] loss: 30.84328, val_loss: 32.26959, best_epoch: 89, elapsed: 1.04s, total: 117.63s, remaining: 428.54s\n",
      "*[102/512] loss: 30.77580, val_loss: 31.98048, best_epoch: 102, elapsed: 1.04s, total: 118.68s, remaining: 428.34s\n",
      " [103/512] loss: 30.75463, val_loss: 31.98233, best_epoch: 102, elapsed: 1.03s, total: 119.91s, remaining: 421.05s\n",
      " [104/512] loss: 30.74887, val_loss: 31.98144, best_epoch: 102, elapsed: 1.05s, total: 120.96s, remaining: 427.83s\n",
      " [105/512] loss: 30.74439, val_loss: 31.98057, best_epoch: 102, elapsed: 1.04s, total: 122.00s, remaining: 422.89s\n",
      "*[106/512] loss: 30.74037, val_loss: 31.97953, best_epoch: 106, elapsed: 1.04s, total: 123.03s, remaining: 421.20s\n",
      "*[107/512] loss: 30.73650, val_loss: 31.97828, best_epoch: 107, elapsed: 1.04s, total: 124.29s, remaining: 422.35s\n",
      "*[108/512] loss: 30.73272, val_loss: 31.97682, best_epoch: 108, elapsed: 1.03s, total: 125.53s, remaining: 416.50s\n",
      "*[109/512] loss: 30.72898, val_loss: 31.97519, best_epoch: 109, elapsed: 1.03s, total: 126.77s, remaining: 416.67s\n",
      "*[110/512] loss: 30.72526, val_loss: 31.97341, best_epoch: 110, elapsed: 1.04s, total: 128.00s, remaining: 416.79s\n",
      "*[111/512] loss: 30.72156, val_loss: 31.97151, best_epoch: 111, elapsed: 1.03s, total: 129.23s, remaining: 413.11s\n",
      "*[112/512] loss: 30.71785, val_loss: 31.96951, best_epoch: 112, elapsed: 1.03s, total: 130.45s, remaining: 410.70s\n",
      "*[113/512] loss: 30.71414, val_loss: 31.96744, best_epoch: 113, elapsed: 1.02s, total: 131.65s, remaining: 405.25s\n",
      "*[114/512] loss: 30.71042, val_loss: 31.96530, best_epoch: 114, elapsed: 1.02s, total: 132.86s, remaining: 405.37s\n",
      "*[115/512] loss: 30.70669, val_loss: 31.96311, best_epoch: 115, elapsed: 1.02s, total: 134.06s, remaining: 404.05s\n",
      "*[116/512] loss: 30.70294, val_loss: 31.96088, best_epoch: 116, elapsed: 1.02s, total: 135.26s, remaining: 403.51s\n",
      "*[117/512] loss: 30.69919, val_loss: 31.95862, best_epoch: 117, elapsed: 1.03s, total: 136.50s, remaining: 405.54s\n",
      "*[118/512] loss: 30.69542, val_loss: 31.95635, best_epoch: 118, elapsed: 1.02s, total: 137.71s, remaining: 402.04s\n",
      "*[119/512] loss: 30.69163, val_loss: 31.95406, best_epoch: 119, elapsed: 1.02s, total: 138.92s, remaining: 401.24s\n",
      "*[120/512] loss: 30.68784, val_loss: 31.95178, best_epoch: 120, elapsed: 1.04s, total: 140.14s, remaining: 406.74s\n",
      "*[121/512] loss: 30.68403, val_loss: 31.94947, best_epoch: 121, elapsed: 1.02s, total: 141.35s, remaining: 399.09s\n",
      "*[122/512] loss: 30.68020, val_loss: 31.94718, best_epoch: 122, elapsed: 1.02s, total: 142.57s, remaining: 398.36s\n",
      "*[123/512] loss: 30.67637, val_loss: 31.94490, best_epoch: 123, elapsed: 1.02s, total: 143.78s, remaining: 397.19s\n",
      "*[124/512] loss: 30.67253, val_loss: 31.94265, best_epoch: 124, elapsed: 1.02s, total: 144.99s, remaining: 394.60s\n",
      "*[125/512] loss: 30.66867, val_loss: 31.94042, best_epoch: 125, elapsed: 1.02s, total: 146.20s, remaining: 396.50s\n",
      "*[126/512] loss: 30.66481, val_loss: 31.93820, best_epoch: 126, elapsed: 1.03s, total: 147.42s, remaining: 397.38s\n",
      "*[127/512] loss: 30.66094, val_loss: 31.93600, best_epoch: 127, elapsed: 1.02s, total: 148.63s, remaining: 392.52s\n",
      "*[128/512] loss: 30.65706, val_loss: 31.93383, best_epoch: 128, elapsed: 1.02s, total: 149.84s, remaining: 391.67s\n",
      "*[129/512] loss: 30.65317, val_loss: 31.93170, best_epoch: 129, elapsed: 1.01s, total: 151.04s, remaining: 388.69s\n",
      "*[130/512] loss: 30.64928, val_loss: 31.92959, best_epoch: 130, elapsed: 1.02s, total: 152.24s, remaining: 388.86s\n",
      "*[131/512] loss: 30.64539, val_loss: 31.92749, best_epoch: 131, elapsed: 1.02s, total: 153.45s, remaining: 389.36s\n",
      "*[132/512] loss: 30.64149, val_loss: 31.92545, best_epoch: 132, elapsed: 1.02s, total: 154.66s, remaining: 388.28s\n",
      "*[133/512] loss: 30.63759, val_loss: 31.92344, best_epoch: 133, elapsed: 1.02s, total: 155.88s, remaining: 387.78s\n",
      "*[134/512] loss: 30.63368, val_loss: 31.92144, best_epoch: 134, elapsed: 1.03s, total: 157.09s, remaining: 388.69s\n",
      "*[135/512] loss: 30.62977, val_loss: 31.91946, best_epoch: 135, elapsed: 1.03s, total: 158.30s, remaining: 387.69s\n",
      "*[136/512] loss: 30.62585, val_loss: 31.91752, best_epoch: 136, elapsed: 1.02s, total: 159.51s, remaining: 385.38s\n",
      "*[137/512] loss: 30.62194, val_loss: 31.91563, best_epoch: 137, elapsed: 1.02s, total: 160.72s, remaining: 382.36s\n",
      "*[138/512] loss: 30.61804, val_loss: 31.91381, best_epoch: 138, elapsed: 1.02s, total: 161.93s, remaining: 381.87s\n",
      "*[139/512] loss: 30.61410, val_loss: 31.91204, best_epoch: 139, elapsed: 1.03s, total: 163.15s, remaining: 384.42s\n",
      "*[140/512] loss: 30.61018, val_loss: 31.91021, best_epoch: 140, elapsed: 1.02s, total: 164.36s, remaining: 377.91s\n",
      "*[141/512] loss: 30.60625, val_loss: 31.90829, best_epoch: 141, elapsed: 1.02s, total: 165.57s, remaining: 379.82s\n",
      "*[142/512] loss: 30.60228, val_loss: 31.90661, best_epoch: 142, elapsed: 1.03s, total: 166.79s, remaining: 382.05s\n",
      "*[143/512] loss: 30.59835, val_loss: 31.90483, best_epoch: 143, elapsed: 1.03s, total: 168.02s, remaining: 381.82s\n",
      "*[144/512] loss: 30.59440, val_loss: 31.90297, best_epoch: 144, elapsed: 1.02s, total: 169.23s, remaining: 375.37s\n",
      "*[145/512] loss: 30.59046, val_loss: 31.90111, best_epoch: 145, elapsed: 1.02s, total: 170.45s, remaining: 375.38s\n",
      "*[146/512] loss: 30.58646, val_loss: 31.90012, best_epoch: 146, elapsed: 1.01s, total: 171.65s, remaining: 370.14s\n",
      "*[147/512] loss: 30.58241, val_loss: 31.89825, best_epoch: 147, elapsed: 1.02s, total: 172.86s, remaining: 371.31s\n",
      "*[148/512] loss: 30.57857, val_loss: 31.89605, best_epoch: 148, elapsed: 1.02s, total: 174.05s, remaining: 369.51s\n",
      "*[149/512] loss: 30.57461, val_loss: 31.89334, best_epoch: 149, elapsed: 1.02s, total: 175.26s, remaining: 368.85s\n",
      "*[150/512] loss: 30.57045, val_loss: 31.89193, best_epoch: 150, elapsed: 1.01s, total: 176.46s, remaining: 366.89s\n",
      " [151/512] loss: 30.56655, val_loss: 31.89472, best_epoch: 150, elapsed: 1.02s, total: 177.66s, remaining: 367.66s\n",
      " [152/512] loss: 30.56261, val_loss: 31.89417, best_epoch: 150, elapsed: 1.02s, total: 178.68s, remaining: 366.76s\n",
      "*[153/512] loss: 30.56063, val_loss: 31.88779, best_epoch: 153, elapsed: 1.02s, total: 179.70s, remaining: 364.48s\n",
      "*[154/512] loss: 30.55423, val_loss: 31.88404, best_epoch: 154, elapsed: 1.02s, total: 180.90s, remaining: 364.33s\n",
      " [155/512] loss: 30.55104, val_loss: 31.89156, best_epoch: 154, elapsed: 1.02s, total: 182.11s, remaining: 363.24s\n",
      " [156/512] loss: 30.54740, val_loss: 31.89276, best_epoch: 154, elapsed: 1.03s, total: 183.13s, remaining: 365.64s\n",
      " [157/512] loss: 30.54634, val_loss: 31.88519, best_epoch: 154, elapsed: 1.03s, total: 184.16s, remaining: 365.04s\n",
      "*[158/512] loss: 30.53747, val_loss: 31.88241, best_epoch: 158, elapsed: 1.01s, total: 185.17s, remaining: 358.74s\n",
      "*[159/512] loss: 30.53356, val_loss: 31.87941, best_epoch: 159, elapsed: 1.02s, total: 186.38s, remaining: 358.74s\n",
      "*[160/512] loss: 30.52911, val_loss: 31.87718, best_epoch: 160, elapsed: 1.02s, total: 187.59s, remaining: 360.17s\n",
      " [161/512] loss: 30.52472, val_loss: 31.87763, best_epoch: 160, elapsed: 1.02s, total: 188.80s, remaining: 358.94s\n",
      " [162/512] loss: 30.52051, val_loss: 31.87753, best_epoch: 160, elapsed: 1.03s, total: 189.83s, remaining: 361.13s\n",
      "*[163/512] loss: 30.51662, val_loss: 31.87435, best_epoch: 163, elapsed: 1.02s, total: 190.86s, remaining: 357.29s\n",
      "*[164/512] loss: 30.51191, val_loss: 31.87265, best_epoch: 164, elapsed: 1.02s, total: 192.06s, remaining: 354.40s\n",
      " [165/512] loss: 30.50748, val_loss: 31.87524, best_epoch: 164, elapsed: 1.03s, total: 193.28s, remaining: 356.96s\n",
      " [166/512] loss: 30.50313, val_loss: 31.87502, best_epoch: 164, elapsed: 1.03s, total: 194.30s, remaining: 355.40s\n",
      "*[167/512] loss: 30.49996, val_loss: 31.87042, best_epoch: 167, elapsed: 1.03s, total: 195.33s, remaining: 354.37s\n",
      " [168/512] loss: 30.49412, val_loss: 31.87164, best_epoch: 167, elapsed: 1.02s, total: 196.54s, remaining: 350.71s\n",
      " [169/512] loss: 30.48996, val_loss: 31.87691, best_epoch: 167, elapsed: 1.03s, total: 197.58s, remaining: 354.97s\n",
      " [170/512] loss: 30.48613, val_loss: 31.87311, best_epoch: 167, elapsed: 1.03s, total: 198.61s, remaining: 353.62s\n",
      "*[171/512] loss: 30.48210, val_loss: 31.86844, best_epoch: 171, elapsed: 1.03s, total: 199.65s, remaining: 352.65s\n",
      " [172/512] loss: 30.47687, val_loss: 31.87681, best_epoch: 171, elapsed: 1.01s, total: 200.85s, remaining: 344.96s\n",
      " [173/512] loss: 30.47196, val_loss: 31.87891, best_epoch: 171, elapsed: 1.02s, total: 201.87s, remaining: 346.88s\n",
      " [174/512] loss: 30.47088, val_loss: 31.87167, best_epoch: 171, elapsed: 1.03s, total: 202.91s, remaining: 349.54s\n",
      " [175/512] loss: 30.46280, val_loss: 31.87850, best_epoch: 171, elapsed: 1.03s, total: 203.94s, remaining: 347.46s\n",
      " [176/512] loss: 30.45812, val_loss: 31.87898, best_epoch: 171, elapsed: 1.03s, total: 204.97s, remaining: 347.21s\n",
      " [177/512] loss: 30.45466, val_loss: 31.87554, best_epoch: 171, elapsed: 1.03s, total: 206.00s, remaining: 345.29s\n",
      "*[178/512] loss: 30.39872, val_loss: 31.79120, best_epoch: 178, elapsed: 1.02s, total: 207.02s, remaining: 341.22s\n",
      "*[179/512] loss: 30.38737, val_loss: 31.79023, best_epoch: 179, elapsed: 1.03s, total: 208.25s, remaining: 342.83s\n",
      "*[180/512] loss: 30.38330, val_loss: 31.78947, best_epoch: 180, elapsed: 1.02s, total: 209.47s, remaining: 340.00s\n",
      "*[181/512] loss: 30.37962, val_loss: 31.78927, best_epoch: 181, elapsed: 1.03s, total: 210.68s, remaining: 339.37s\n",
      " [182/512] loss: 30.37609, val_loss: 31.78938, best_epoch: 181, elapsed: 1.02s, total: 211.89s, remaining: 337.81s\n",
      " [183/512] loss: 30.37267, val_loss: 31.78967, best_epoch: 181, elapsed: 1.04s, total: 212.93s, remaining: 341.90s\n",
      " [184/512] loss: 30.36932, val_loss: 31.79011, best_epoch: 181, elapsed: 1.04s, total: 213.97s, remaining: 339.98s\n",
      " [185/512] loss: 30.36604, val_loss: 31.79066, best_epoch: 181, elapsed: 1.03s, total: 215.01s, remaining: 338.37s\n",
      " [186/512] loss: 30.36281, val_loss: 31.79130, best_epoch: 181, elapsed: 1.03s, total: 216.04s, remaining: 336.40s\n",
      " [187/512] loss: 30.35963, val_loss: 31.79202, best_epoch: 181, elapsed: 1.03s, total: 217.07s, remaining: 334.28s\n",
      " [188/512] loss: 30.31243, val_loss: 31.79331, best_epoch: 181, elapsed: 1.03s, total: 218.10s, remaining: 334.11s\n",
      " [189/512] loss: 30.30718, val_loss: 31.79369, best_epoch: 181, elapsed: 1.04s, total: 219.13s, remaining: 334.76s\n",
      " [190/512] loss: 30.30464, val_loss: 31.79403, best_epoch: 181, elapsed: 1.05s, total: 220.18s, remaining: 337.60s\n",
      " [191/512] loss: 30.30248, val_loss: 31.79437, best_epoch: 181, elapsed: 1.04s, total: 221.22s, remaining: 334.15s\n",
      " [192/512] loss: 30.30044, val_loss: 31.79480, best_epoch: 181, elapsed: 1.04s, total: 222.26s, remaining: 331.92s\n",
      " [193/512] loss: 30.29846, val_loss: 31.79530, best_epoch: 181, elapsed: 1.06s, total: 223.32s, remaining: 336.82s\n",
      " [194/512] loss: 30.27240, val_loss: 31.79959, best_epoch: 181, elapsed: 1.03s, total: 224.35s, remaining: 328.76s\n",
      " [195/512] loss: 30.27051, val_loss: 31.79941, best_epoch: 181, elapsed: 1.05s, total: 225.40s, remaining: 332.95s\n",
      " [196/512] loss: 30.26899, val_loss: 31.79966, best_epoch: 181, elapsed: 1.05s, total: 226.45s, remaining: 331.25s\n",
      " [197/512] loss: 30.26777, val_loss: 31.80005, best_epoch: 181, elapsed: 1.05s, total: 227.49s, remaining: 329.19s\n",
      " [198/512] loss: 30.26663, val_loss: 31.80050, best_epoch: 181, elapsed: 1.05s, total: 228.55s, remaining: 331.20s\n",
      " [199/512] loss: 30.26552, val_loss: 31.80096, best_epoch: 181, elapsed: 1.05s, total: 229.60s, remaining: 328.04s\n",
      " [200/512] loss: 30.24803, val_loss: 31.79470, best_epoch: 181, elapsed: 1.04s, total: 230.64s, remaining: 324.27s\n",
      " [201/512] loss: 30.24578, val_loss: 31.79459, best_epoch: 181, elapsed: 1.05s, total: 231.68s, remaining: 325.71s\n",
      " [202/512] loss: 30.24505, val_loss: 31.79471, best_epoch: 181, elapsed: 1.03s, total: 232.72s, remaining: 319.65s\n",
      " [203/512] loss: 30.24444, val_loss: 31.79487, best_epoch: 181, elapsed: 1.03s, total: 233.74s, remaining: 317.98s\n",
      " [204/512] loss: 30.24386, val_loss: 31.79507, best_epoch: 181, elapsed: 1.03s, total: 234.77s, remaining: 317.08s\n",
      " [205/512] loss: 30.24329, val_loss: 31.79529, best_epoch: 181, elapsed: 1.03s, total: 235.81s, remaining: 316.60s\n",
      " [206/512] loss: 30.23354, val_loss: 31.79308, best_epoch: 181, elapsed: 1.04s, total: 236.84s, remaining: 316.88s\n",
      " [207/512] loss: 30.23255, val_loss: 31.79264, best_epoch: 181, elapsed: 1.03s, total: 237.87s, remaining: 314.98s\n",
      " [208/512] loss: 30.23211, val_loss: 31.79259, best_epoch: 181, elapsed: 1.03s, total: 238.90s, remaining: 312.36s\n",
      " [209/512] loss: 30.23178, val_loss: 31.79264, best_epoch: 181, elapsed: 1.03s, total: 239.93s, remaining: 313.03s\n",
      " [210/512] loss: 30.23149, val_loss: 31.79273, best_epoch: 181, elapsed: 1.03s, total: 240.97s, remaining: 311.79s\n",
      " [211/512] loss: 30.23121, val_loss: 31.79282, best_epoch: 181, elapsed: 1.03s, total: 242.00s, remaining: 311.16s\n",
      " [212/512] loss: 30.22613, val_loss: 31.79242, best_epoch: 181, elapsed: 1.02s, total: 243.02s, remaining: 306.51s\n",
      " [213/512] loss: 30.22583, val_loss: 31.79225, best_epoch: 181, elapsed: 1.02s, total: 244.05s, remaining: 306.31s\n",
      " [214/512] loss: 30.22562, val_loss: 31.79218, best_epoch: 181, elapsed: 1.03s, total: 245.07s, remaining: 305.48s\n",
      " [215/512] loss: 30.22546, val_loss: 31.79216, best_epoch: 181, elapsed: 1.03s, total: 246.10s, remaining: 304.62s\n",
      " [216/512] loss: 30.22531, val_loss: 31.79217, best_epoch: 181, elapsed: 1.02s, total: 247.12s, remaining: 302.46s\n",
      " [217/512] loss: 30.22516, val_loss: 31.79219, best_epoch: 181, elapsed: 1.03s, total: 248.15s, remaining: 305.17s\n",
      " [218/512] loss: 30.22257, val_loss: 31.79214, best_epoch: 181, elapsed: 1.04s, total: 249.20s, remaining: 307.21s\n",
      " [219/512] loss: 30.22247, val_loss: 31.79212, best_epoch: 181, elapsed: 1.05s, total: 250.25s, remaining: 307.35s\n",
      " [220/512] loss: 30.22238, val_loss: 31.79211, best_epoch: 181, elapsed: 1.04s, total: 251.29s, remaining: 304.45s\n",
      " [221/512] loss: 30.22230, val_loss: 31.79211, best_epoch: 181, elapsed: 1.04s, total: 252.33s, remaining: 302.69s\n",
      " [222/512] loss: 30.22222, val_loss: 31.79213, best_epoch: 181, elapsed: 1.05s, total: 253.38s, remaining: 303.42s\n",
      " [223/512] loss: 30.22215, val_loss: 31.79214, best_epoch: 181, elapsed: 1.04s, total: 254.42s, remaining: 301.00s\n",
      " [224/512] loss: 30.22087, val_loss: 31.79213, best_epoch: 181, elapsed: 1.03s, total: 255.45s, remaining: 297.84s\n",
      " [225/512] loss: 30.22083, val_loss: 31.79212, best_epoch: 181, elapsed: 1.05s, total: 256.50s, remaining: 301.37s\n",
      " [226/512] loss: 30.22079, val_loss: 31.79212, best_epoch: 181, elapsed: 1.02s, total: 257.53s, remaining: 292.50s\n",
      " [227/512] loss: 30.22075, val_loss: 31.79212, best_epoch: 181, elapsed: 1.04s, total: 258.56s, remaining: 295.29s\n",
      " [228/512] loss: 30.22072, val_loss: 31.79211, best_epoch: 181, elapsed: 1.04s, total: 259.60s, remaining: 294.35s\n",
      " [229/512] loss: 30.22068, val_loss: 31.79212, best_epoch: 181, elapsed: 1.03s, total: 260.63s, remaining: 291.52s\n",
      " [230/512] loss: 30.22065, val_loss: 31.79212, best_epoch: 181, elapsed: 1.03s, total: 261.66s, remaining: 290.98s\n",
      " [231/512] loss: 30.22061, val_loss: 31.79212, best_epoch: 181, elapsed: 1.03s, total: 262.69s, remaining: 288.15s\n",
      " [232/512] loss: 30.22058, val_loss: 31.79213, best_epoch: 181, elapsed: 1.04s, total: 263.72s, remaining: 290.51s\n",
      " [233/512] loss: 30.22054, val_loss: 31.79213, best_epoch: 181, elapsed: 1.02s, total: 264.75s, remaining: 285.21s\n",
      " [234/512] loss: 30.22051, val_loss: 31.79214, best_epoch: 181, elapsed: 1.02s, total: 265.77s, remaining: 283.83s\n",
      " [235/512] loss: 30.22048, val_loss: 31.79214, best_epoch: 181, elapsed: 1.03s, total: 266.79s, remaining: 284.08s\n",
      " [236/512] loss: 30.22044, val_loss: 31.79215, best_epoch: 181, elapsed: 1.02s, total: 267.82s, remaining: 282.15s\n",
      " [237/512] loss: 30.22041, val_loss: 31.79216, best_epoch: 181, elapsed: 1.03s, total: 268.84s, remaining: 282.17s\n",
      " [238/512] loss: 30.22038, val_loss: 31.79216, best_epoch: 181, elapsed: 1.04s, total: 269.88s, remaining: 283.71s\n",
      " [239/512] loss: 30.22034, val_loss: 31.79217, best_epoch: 181, elapsed: 1.05s, total: 270.92s, remaining: 285.96s\n",
      " [240/512] loss: 30.22031, val_loss: 31.79218, best_epoch: 181, elapsed: 1.05s, total: 271.97s, remaining: 285.29s\n",
      " [241/512] loss: 30.22028, val_loss: 31.79219, best_epoch: 181, elapsed: 1.08s, total: 273.06s, remaining: 293.14s\n",
      " [242/512] loss: 30.22024, val_loss: 31.79220, best_epoch: 181, elapsed: 1.02s, total: 274.08s, remaining: 275.54s\n",
      " [243/512] loss: 30.22021, val_loss: 31.79221, best_epoch: 181, elapsed: 1.02s, total: 275.10s, remaining: 274.35s\n",
      " [244/512] loss: 30.22018, val_loss: 31.79222, best_epoch: 181, elapsed: 1.03s, total: 276.13s, remaining: 277.00s\n",
      " [245/512] loss: 30.22015, val_loss: 31.79223, best_epoch: 181, elapsed: 1.03s, total: 277.16s, remaining: 273.88s\n",
      " [246/512] loss: 30.22011, val_loss: 31.79224, best_epoch: 181, elapsed: 1.02s, total: 278.18s, remaining: 272.03s\n",
      " [247/512] loss: 30.22008, val_loss: 31.79225, best_epoch: 181, elapsed: 1.02s, total: 279.20s, remaining: 270.90s\n",
      " [248/512] loss: 30.22005, val_loss: 31.79225, best_epoch: 181, elapsed: 1.03s, total: 280.23s, remaining: 272.65s\n",
      " [249/512] loss: 30.22002, val_loss: 31.79227, best_epoch: 181, elapsed: 1.03s, total: 281.26s, remaining: 271.17s\n",
      " [250/512] loss: 30.21998, val_loss: 31.79228, best_epoch: 181, elapsed: 1.04s, total: 282.30s, remaining: 271.30s\n",
      " [251/512] loss: 30.21995, val_loss: 31.79229, best_epoch: 181, elapsed: 1.04s, total: 283.34s, remaining: 272.72s\n",
      " [252/512] loss: 30.21992, val_loss: 31.79230, best_epoch: 181, elapsed: 1.03s, total: 284.38s, remaining: 268.65s\n",
      " [253/512] loss: 30.21989, val_loss: 31.79231, best_epoch: 181, elapsed: 1.03s, total: 285.41s, remaining: 266.80s\n",
      " [254/512] loss: 30.21985, val_loss: 31.79232, best_epoch: 181, elapsed: 1.03s, total: 286.44s, remaining: 265.37s\n",
      " [255/512] loss: 30.21982, val_loss: 31.79233, best_epoch: 181, elapsed: 1.04s, total: 287.47s, remaining: 266.20s\n",
      " [256/512] loss: 30.21979, val_loss: 31.79234, best_epoch: 181, elapsed: 1.05s, total: 288.52s, remaining: 268.28s\n",
      " [257/512] loss: 30.21976, val_loss: 31.79235, best_epoch: 181, elapsed: 1.04s, total: 289.57s, remaining: 266.41s\n",
      " [258/512] loss: 30.21973, val_loss: 31.79236, best_epoch: 181, elapsed: 1.03s, total: 290.60s, remaining: 261.81s\n",
      " [259/512] loss: 30.21969, val_loss: 31.79237, best_epoch: 181, elapsed: 1.03s, total: 291.63s, remaining: 260.55s\n",
      " [260/512] loss: 30.21966, val_loss: 31.79238, best_epoch: 181, elapsed: 1.03s, total: 292.66s, remaining: 259.64s\n",
      " [261/512] loss: 30.21963, val_loss: 31.79239, best_epoch: 181, elapsed: 1.02s, total: 293.68s, remaining: 257.13s\n",
      " [262/512] loss: 30.21960, val_loss: 31.79241, best_epoch: 181, elapsed: 1.03s, total: 294.71s, remaining: 256.42s\n",
      " [263/512] loss: 30.21956, val_loss: 31.79242, best_epoch: 181, elapsed: 1.03s, total: 295.74s, remaining: 256.29s\n",
      " [264/512] loss: 30.21953, val_loss: 31.79243, best_epoch: 181, elapsed: 1.03s, total: 296.76s, remaining: 254.39s\n",
      " [265/512] loss: 30.21950, val_loss: 31.79244, best_epoch: 181, elapsed: 1.03s, total: 297.79s, remaining: 253.32s\n",
      " [266/512] loss: 30.21947, val_loss: 31.79245, best_epoch: 181, elapsed: 1.02s, total: 298.81s, remaining: 251.81s\n",
      " [267/512] loss: 30.21944, val_loss: 31.79246, best_epoch: 181, elapsed: 1.03s, total: 299.84s, remaining: 252.44s\n",
      " [268/512] loss: 30.21940, val_loss: 31.79247, best_epoch: 181, elapsed: 1.03s, total: 300.87s, remaining: 250.76s\n",
      " [269/512] loss: 30.21937, val_loss: 31.79249, best_epoch: 181, elapsed: 1.03s, total: 301.90s, remaining: 249.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits,random_state=0,shuffle=True)\n",
    "\n",
    "k=0\n",
    "for tr_idx,va_idx in kf.split(train_df):\n",
    "    k+=1\n",
    "    print('-'*100)\n",
    "    print('> K-Fold: {}'.format(k))\n",
    "    print('-'*100)\n",
    "    \n",
    "    tr_df, va_df = train_df.iloc[tr_idx], train_df.iloc[va_idx]\n",
    "    te_df = test_df.copy()\n",
    "    \n",
    "    # (1) scaling\n",
    "    for f in features:\n",
    "        scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "        tr_df[f] = scaler.fit_transform(np.array(tr_df[f]).reshape(-1,1))\n",
    "        va_df[f] = scaler.transform(np.array(va_df[f]).reshape(-1,1))\n",
    "        te_df[f] = scaler.transform(np.array(te_df[f]).reshape(-1,1))\n",
    "    \n",
    "    # (2) target transform\n",
    "    inverse_transform = None\n",
    "    \n",
    "    # (3) custom dataset\n",
    "    transform = [smiles_transform,fps_transform]\n",
    "    train_dataset = CustomDataset(tr_df, ['MLM','HLM'], 'SMILES', 'FPs', fps_maximum, tokenizer, transform, False)\n",
    "    val_dataset   = CustomDataset(va_df, ['MLM','HLM'], 'SMILES', 'FPs', fps_maximum, tokenizer, transform, False)\n",
    "    test_dataset  = CustomDataset(te_df, ['MLM','HLM'], 'SMILES', 'FPs', fps_maximum, tokenizer, transform, True)\n",
    "    \n",
    "    # (4) dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_dataset  , batch_size=CFG.BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=0)\n",
    "    test_loader  = DataLoader(test_dataset , batch_size=CFG.BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=0)\n",
    "    \n",
    "    # (5) model define\n",
    "    model = MultiTaskModel(feature_input_size,vocab_size,output_size,hidden_size,dropout_rate)\n",
    "\n",
    "    criterion = MultiRMSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.LEARNING_RATE)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=CFG.LEARNING_RATE, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, threshold_mode='abs', min_lr=1e-5, verbose=False)\n",
    "    # scheduler = None\n",
    "    # early_stopping = EarlyStopping(patience=10,verbose=False,path='')\n",
    "    early_stopping = None\n",
    "    \n",
    "    # (6) modeling\n",
    "    torch.cuda.empty_cache(), gc.collect(), gc.collect()\n",
    "    \n",
    "    best_model = train(\n",
    "        model, criterion, optimizer, train_loader, val_loader,\n",
    "        CFG.EPOCHS, early_stopping, device, scheduler,\n",
    "        metric_period=1, verbose=True,\n",
    "        save_model_path=f'./mc/best_model_k{k}.pt',\n",
    "        final_model_path=f'./mc/final_model_k{k}.pt',\n",
    "        use_best_model=True,\n",
    "        inverse_transform=inverse_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3213f",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0eef94",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(best_model,loader,device,inverse_transform):\n",
    "    best_model.to(device)\n",
    "\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for feat,mol,fps,emb,target in iter(loader):\n",
    "            feat = feat.to(device)\n",
    "            mol = mol.to(device)\n",
    "            fps = fps.to(device)\n",
    "            emb = emb.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = best_model(feat,mol,fps,emb)\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "\n",
    "            true_list.append(target)\n",
    "            pred_list.append(output)\n",
    "\n",
    "    trues = torch.cat(true_list,dim=0)\n",
    "    preds = torch.cat(pred_list,dim=0)\n",
    "\n",
    "    trues = trues.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    return trues, preds\n",
    "\n",
    "def predict_test(best_model,loader,device,inverse_transform):\n",
    "    best_model.to(device)\n",
    "\n",
    "    #true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for feat,mol,fps,emb in iter(loader):\n",
    "            feat = feat.to(device)\n",
    "            mol = mol.to(device)\n",
    "            fps = fps.to(device)\n",
    "            emb = emb.to(device)\n",
    "            #target = target.to(device)\n",
    "\n",
    "            output = best_model(feat,mol,fps,emb)\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                #target = inverse_transform(target)\n",
    "\n",
    "            #true_list.append(target)\n",
    "            pred_list.append(output)\n",
    "\n",
    "    #trues = torch.cat(true_list,dim=0)\n",
    "    preds = torch.cat(pred_list,dim=0)\n",
    "\n",
    "    #trues = trues.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411336a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MultiTaskModel(feature_input_size,vocab_size,output_size,hidden_size,dropout_rate)\n",
    "best_model.load_state_dict(torch.load('./mc/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_true, tr_pred = predict(best_model,train_loader,device,inverse_transform)\n",
    "va_true, va_pred = predict(best_model,val_loader,device,inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(MultiRMSELoss()(torch.tensor(tr_true),torch.tensor(tr_pred)),\n",
    " MultiRMSELoss()(torch.tensor(va_true),torch.tensor(va_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ec090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_pred = tr_pred.mean(axis=1).tolist()\n",
    "# tr_pred = np.array([tr_pred,tr_pred]).T\n",
    "\n",
    "# va_pred = va_pred.mean(axis=1).tolist()\n",
    "# va_pred = np.array([va_pred,va_pred]).T\n",
    "\n",
    "# (MultiRMSELoss()(torch.tensor(tr_true),torch.tensor(tr_pred)),\n",
    "#  MultiRMSELoss()(torch.tensor(va_true),torch.tensor(va_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_true[:10].round(1), tr_pred[:10].round(1)\n",
    "# va_true[:10].round(1), va_pred[:10].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(intercept,slope):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, linestyle='--', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "fig.add_subplot(121)\n",
    "sns.scatterplot(x=tr_true[:,0],y=tr_pred[:,0])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "fig.add_subplot(122)\n",
    "sns.scatterplot(x=tr_true[:,1],y=tr_pred[:,1])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.suptitle('train',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "fig.add_subplot(121)\n",
    "sns.scatterplot(x=va_true[:,0],y=va_pred[:,0])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "fig.add_subplot(122)\n",
    "sns.scatterplot(x=va_true[:,1],y=va_pred[:,1])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.suptitle('validation',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8171385",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred = predict_test(best_model,test_loader,device,inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit[targets] = te_pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e787c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./out/mlt_efficientnet_mol&fps.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "88a5da79f9030d36a713e3ceec9ed9a47a216907c035af9944c458137c4e5cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
