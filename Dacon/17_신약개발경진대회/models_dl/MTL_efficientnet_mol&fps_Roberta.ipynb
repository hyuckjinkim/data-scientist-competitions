{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec73c4a",
   "metadata": {},
   "source": [
    "- https://discuss.huggingface.co/t/training-a-regression-model-using-roberta-smiles-to-ccs-cheminformatics/1314"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3679158",
   "metadata": {
    "id": "pYzhJrEibIlq"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff3003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q rdkit\n",
    "# !pip install -q albumentations\n",
    "# !pip install accelerate -U\n",
    "# !pip install -q tokenizer\n",
    "# !pip install -q transformer\n",
    "\n",
    "# import accelerate\n",
    "# accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7ad588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776dc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd00644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 0\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 512\n",
    "    LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56d185",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cb90c",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd34c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df  = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5c3c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             SMILES     MLM  \\\n",
       "0  TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n",
       "1  TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n",
       "2  TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n",
       "3  TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   \n",
       "4  TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n",
       "\n",
       "      HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
       "0  50.680  3.259           400.495                5             2   \n",
       "1  50.590  2.169           301.407                2             1   \n",
       "2  80.892  1.593           297.358                5             0   \n",
       "3   2.000  4.771           494.652                6             0   \n",
       "4  99.990  2.335           268.310                3             0   \n",
       "\n",
       "   Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  \n",
       "0                   8  3.259                      117.37  \n",
       "1                   2  2.172                       73.47  \n",
       "2                   3  1.585                       62.45  \n",
       "3                   5  3.475                       92.60  \n",
       "4                   1  2.337                       42.43  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0392e5d",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303709aa",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08128bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8c6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = train_df.columns[train_df.dtypes!='object'].tolist()\n",
    "# for i,col in enumerate(num_features):\n",
    "\n",
    "#     fig = plt.figure(figsize=(15,7))\n",
    "#     fig.add_subplot(121)\n",
    "#     sns.histplot(train_df[col],bins=20)\n",
    "#     plt.grid()\n",
    "\n",
    "#     fig.add_subplot(122)\n",
    "#     sns.histplot(np.log(train_df[col]+1e-3),bins=20)\n",
    "#     plt.grid()\n",
    "\n",
    "#     plt.suptitle('[{}/{}] {}'.format(i+1,len(num_features),col))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # -> ['Molecular_Weight','Molecular_PolarSurfaceArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03943e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "# for col in cols:\n",
    "#     print(col)\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.scatterplot(x=train_df[col],y=train_df['HLM'])\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3816f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds']\n",
    "# for col in cols:\n",
    "#     print(col)\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.boxplot(x=train_df[col],y=train_df.MLM)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca43fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bfd8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists = sorted(train_df['Num_H_Acceptors'].unique())\n",
    "# for v in lists:\n",
    "#     print('########',v)\n",
    "#     d = train_df[train_df['Num_H_Acceptors']==v]\n",
    "    \n",
    "#     cols = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "#     for col in cols:\n",
    "#         print(col)\n",
    "#         plt.figure(figsize=(15,7))\n",
    "#         sns.scatterplot(x=d[col],y=d['HLM'])\n",
    "#         plt.grid()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274469da",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c310d6",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3b63c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a29030",
   "metadata": {},
   "source": [
    "## Set target range to [0,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b49c7f",
   "metadata": {},
   "source": [
    "- [Dacon](https://dacon.io/competitions/official/236127/talkboard/409051?page=1&dtype=recent)에 따르면 100이 넘는 값도 나올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d90379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = ['MLM','HLM']\n",
    "# for t in targets:\n",
    "#     train_df[t] = [0 if x<0 else\n",
    "#                    100 if x>100 else\n",
    "#                    x for x in train_df[t]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed1b3f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87ccc0",
   "metadata": {},
   "source": [
    "## Make molecule features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf8cfe39",
   "metadata": {
    "id": "oXOFfJVW22DL"
   },
   "outputs": [],
   "source": [
    "# Molecule to MorganFingerprint\n",
    "def mol2fp(mol):\n",
    "    #radius, nBits = 6, 4096\n",
    "    radius, nBits = 12, (2**10)*3\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, radius=radius, nBits=nBits)\n",
    "    ar = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf7b2a45",
   "metadata": {
    "id": "7KbqRv6I19Rg"
   },
   "outputs": [],
   "source": [
    "# (1) SMILES를 통해 Molecule(분자구조) 생성\n",
    "PandasTools.AddMoleculeColumnToFrame(train_df,'SMILES','Molecule')\n",
    "PandasTools.AddMoleculeColumnToFrame(test_df ,'SMILES','Molecule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e666c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d19941",
   "metadata": {
    "id": "1MTlg0wx22DM"
   },
   "outputs": [],
   "source": [
    "# (2) Morgan Fingerprint column 추가\n",
    "train_df[\"FPs\"] = train_df.Molecule.apply(mol2fp)\n",
    "test_df [\"FPs\"] = test_df .Molecule.apply(mol2fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17054fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n"
     ]
    }
   ],
   "source": [
    "# (3) Morgan Fingerprint 중, variance가 0.05보다 작은 컬럼들을 지우기\n",
    "feature_select = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "# 일부사용\n",
    "tr_fps_selected = feature_select.fit_transform(np.stack(train_df['FPs']))\n",
    "te_fps_selected = feature_select.transform(np.stack(test_df['FPs']))\n",
    "print(tr_fps_selected.shape[1])\n",
    "\n",
    "# # 전체사용\n",
    "# tr_fps_selected = np.stack(train_df['FPs'])\n",
    "# te_fps_selected = np.stack(test_df ['FPs'])\n",
    "\n",
    "fps_names = ['fps'+str(i+1) for i in range(tr_fps_selected.shape[1])]\n",
    "\n",
    "train_df = pd.concat([train_df,pd.DataFrame(tr_fps_selected,columns=fps_names)],axis=1)\n",
    "test_df  = pd.concat([test_df ,pd.DataFrame(te_fps_selected,columns=fps_names)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "979f5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 column만 추출\n",
    "features = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors',\n",
    "            'Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "fps_feature = 'FPs'\n",
    "smiles_feature = 'SMILES'\n",
    "targets  = ['MLM','HLM']\n",
    "\n",
    "train_df = train_df[features+fps_names+[fps_feature,smiles_feature]+targets]\n",
    "test_df  = test_df[features+fps_names+[fps_feature,smiles_feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9580679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3498, 304)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ca3e3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "      <th>fps1</th>\n",
       "      <th>fps2</th>\n",
       "      <th>fps3</th>\n",
       "      <th>...</th>\n",
       "      <th>fps288</th>\n",
       "      <th>fps289</th>\n",
       "      <th>fps290</th>\n",
       "      <th>fps291</th>\n",
       "      <th>fps292</th>\n",
       "      <th>fps293</th>\n",
       "      <th>FPs</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  Num_RotatableBonds  \\\n",
       "0  3.259           400.495                5             2                   8   \n",
       "1  2.169           301.407                2             1                   2   \n",
       "2  1.593           297.358                5             0                   3   \n",
       "3  4.771           494.652                6             0                   5   \n",
       "4  2.335           268.310                3             0                   1   \n",
       "\n",
       "    LogD  Molecular_PolarSurfaceArea  fps1  fps2  fps3  ...  fps288  fps289  \\\n",
       "0  3.259                      117.37     0     0     4  ...       0       0   \n",
       "1  2.172                       73.47     0     0     3  ...       0       0   \n",
       "2  1.585                       62.45     0     0     1  ...       0       0   \n",
       "3  3.475                       92.60     0     0     3  ...       2       0   \n",
       "4  2.337                       42.43     0     0     2  ...       0       0   \n",
       "\n",
       "   fps290  fps291  fps292  fps293  \\\n",
       "0       2       0       0       0   \n",
       "1       0       0       0       1   \n",
       "2       0       2       0       0   \n",
       "3       0       0       0       1   \n",
       "4       0       0       0       1   \n",
       "\n",
       "                                                 FPs  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              SMILES     MLM     HLM  \n",
       "0    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010  50.680  \n",
       "1               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270  50.590  \n",
       "2                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586  80.892  \n",
       "3  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   2.000  \n",
       "4                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270  99.990  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd6736",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0869d",
   "metadata": {},
   "source": [
    "## Imputaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2605d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0633439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_check(data):\n",
    "    d = data.copy()\n",
    "    null_info = d.isnull().sum()\n",
    "    null_info = null_info[null_info!=0]\n",
    "    display(null_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f75589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlogP    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlogP    1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('> train')\n",
    "null_check(train_df)\n",
    "\n",
    "print('> test')\n",
    "null_check(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5db823eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_features = ['AlogP']\n",
    "\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# train_df[null_features] = imputer.fit_transform(train_df[null_features])\n",
    "# test_df [null_features] = imputer.transform(test_df[null_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ca94077",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(features)-set(['AlogP']))\n",
    "train_df.drop('AlogP',axis=1,inplace=True)\n",
    "test_df .drop('AlogP',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b41c0c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('> train')\n",
    "null_check(train_df)\n",
    "\n",
    "print('> test')\n",
    "null_check(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110a95c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eeaafd",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "552fbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f99148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df, va_df = train_test_split(train_df,test_size=0.2,shuffle=True,random_state=CFG.SEED)\n",
    "te_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86db0c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2798, 700, 483)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_df), len(va_df), len(te_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f2104d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666922e",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14e69bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaling_features = features+fps_names\n",
    "scalers = {}\n",
    "for f in scaling_features:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    tr_df[f] = scaler.fit_transform(np.array(tr_df[f]).reshape(-1,1))\n",
    "    va_df[f] = scaler.transform(np.array(va_df[f]).reshape(-1,1))\n",
    "    te_df[f] = scaler.transform(np.array(te_df[f]).reshape(-1,1))\n",
    "    scalers[f] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8fd593",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b534b53",
   "metadata": {},
   "source": [
    "## Interaction Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b79a7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import trange\n",
    "\n",
    "def get_abs_corr(x,y):\n",
    "    return np.abs(np.corrcoef(x,y))[0,1]\n",
    "\n",
    "class InteractionTerm:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,num_features,corr_cutoff=0.7):\n",
    "        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        \n",
    "        d = data.copy()\n",
    "        self.interaction_list = []\n",
    "        for i in trange(len(num_features),desc='fitting...'):\n",
    "            for j in range(len(num_features)):\n",
    "                if i>j:\n",
    "                    col_i = num_features[i]\n",
    "                    col_j = num_features[j]\n",
    "                    \n",
    "                    # 상관계수가 cutoff보다 큰 경우에는 interaction을 생성하지 않음\n",
    "                    if (get_abs_corr(d[col_i]*d[col_j],d[col_i])>=corr_cutoff) | (get_abs_corr(d[col_i]*d[col_j],d[col_j])>=corr_cutoff):\n",
    "                        pass\n",
    "                    else:\n",
    "                        self.interaction_list.append(f'{col_i}*{col_j}')\n",
    "    \n",
    "    def transform(self,data):\n",
    "        d = data.copy()\n",
    "        print('> the number of interaction term:',len(self.interaction_list))\n",
    "        for interaction in self.interaction_list:\n",
    "            col_i,col_j = interaction.split('*')\n",
    "            d[interaction] = d[col_i]*d[col_j]\n",
    "        return d\n",
    "    \n",
    "    def fit_transform(self,data,num_features,corr_cutoff=0.7):\n",
    "        self.fit(data,num_features,corr_cutoff)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3faeedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = features + fps_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dea889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction_maker = InteractionTerm()\n",
    "# interaction_maker.fit(\n",
    "#     data=tr_df,\n",
    "#     num_features=num_features,\n",
    "#     corr_cutoff=0.15,\n",
    "# )\n",
    "# tr_df = interaction_maker.transform(tr_df)\n",
    "# va_df = interaction_maker.transform(va_df)\n",
    "# te_df = interaction_maker.transform(te_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45b9de71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2798, 303)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef010404",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6e98a",
   "metadata": {},
   "source": [
    "## Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f544d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in targets:\n",
    "#     tr_df[t] = np.log(tr_df[t]+1e-3)\n",
    "#     va_df[t] = np.log(va_df[t]+1e-3)\n",
    "\n",
    "# def inverse_transform(x):\n",
    "#     return torch.exp(x)-1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a3926c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.special import boxcox, inv_boxcox\n",
    "\n",
    "# def boxcox_transform(x):\n",
    "#     _lambda = 0.25\n",
    "#     return boxcox(x,_lambda)\n",
    "\n",
    "# def inverse_boxcox_transform(x):\n",
    "#     _lambda = 0.25\n",
    "#     return inv_boxcox(x,_lambda)\n",
    "\n",
    "# tr_df[targets] = tr_df[targets].apply(boxcox_transform)\n",
    "# va_df[targets] = va_df[targets].apply(boxcox_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19728fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8814bc44",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff84a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiRMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        loss1 = torch.sqrt(torch.mean((output[:,0]-target[:,0])**2))\n",
    "        loss2 = torch.sqrt(torch.mean((output[:,1]-target[:,1])**2))\n",
    "        loss = 0.5*loss1+0.5*loss2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edd88763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        if self.path!='':\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "        \n",
    "def train(\n",
    "    model, criterion, optimizer, train_loader, valid_loader, epochs,\n",
    "    early_stopping, device='cpu', scheduler=None, metric_period=1, verbose=True, \n",
    "    save_model_path = './mc/best_model.pt', final_model_path = './mc/final_model.pt',\n",
    "    use_best_model=True,\n",
    "    inverse_transform=None,\n",
    "):  \n",
    "    seed_everything(CFG.SEED)\n",
    "    model.to(device)\n",
    "\n",
    "    best_loss  = 999999999\n",
    "    best_epoch = 1\n",
    "    best_model = None\n",
    "    is_best    = np.nan\n",
    "    \n",
    "    start_time = time.time()\n",
    "    epoch_s = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        gc.collect()\n",
    "        \n",
    "        #model.train()\n",
    "        train_loss = []\n",
    "        for ids,target in train_loader:\n",
    "            ids = ids.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(ids).float()\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()  # Getting gradients\n",
    "            optimizer.step() # Updating parameters\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            valid_loss = validation(model, valid_loader, criterion, device, inverse_transform)\n",
    "        else:\n",
    "            valid_loss = loss\n",
    "            \n",
    "        epoch_e = time.time()\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        # update the best epoch & best loss\n",
    "        if (best_loss > valid_loss) | (epoch==1):\n",
    "            best_epoch = epoch\n",
    "            best_loss = valid_loss\n",
    "            best_model = model\n",
    "            is_best = 1\n",
    "            torch.save(best_model.state_dict(), save_model_path)\n",
    "        else:\n",
    "            is_best = 0\n",
    "            if not use_best_model:\n",
    "                torch.save(best_model.state_dict(), save_model_path)\n",
    "            \n",
    "        # 결과물 printing\n",
    "        if (verbose) & (epoch % metric_period == 0):\n",
    "            mark = '*' if is_best else ' '\n",
    "            epoch_str = str(epoch).zfill(len(str(epochs)))\n",
    "            if valid_loader is not None:\n",
    "                progress = '{}[{}/{}] loss: {:.5f}, val_loss: {:.5f}, best_epoch: {}, elapsed: {:.2f}s, total: {:.2f}s, remaining: {:.2f}s'\\\n",
    "                    .format(\n",
    "                        mark,\n",
    "                        epoch_str,\n",
    "                        epochs,\n",
    "                        np.mean(train_loss),\n",
    "                        valid_loss,\n",
    "                        best_epoch,\n",
    "                        epoch_e-epoch_s,\n",
    "                        epoch_e-start_time,\n",
    "                        (epoch_e-epoch_s)*(epochs-epoch)/metric_period,\n",
    "                    )\n",
    "            else:\n",
    "                progress = '{}[{}/{}] loss: {:.5f}, best_epoch: {}, elapsed: {:.2f}s, total: {:.2f}s, remaining: {:.2f}s'\\\n",
    "                    .format(\n",
    "                        mark,\n",
    "                        epoch_str,\n",
    "                        epochs,\n",
    "                        np.mean(train_loss),\n",
    "                        best_epoch,\n",
    "                        epoch_e-epoch_s,\n",
    "                        epoch_e-start_time,\n",
    "                        (epoch_e-epoch_s)*(epochs-epoch)/metric_period,\n",
    "                    )\n",
    "            epoch_s = time.time()\n",
    "            print(progress)\n",
    "\n",
    "        # early stopping 여부를 체크. 현재 과적합 상황 추적\n",
    "        if early_stopping is not None:\n",
    "            early_stopping(valid_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "                \n",
    "        torch.save(best_model.state_dict(), final_model_path)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def validation(model, valid_loader, criterion, device, inverse_transform):\n",
    "    valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for ids,target in valid_loader:\n",
    "            ids = ids.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(ids).float()\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "548f66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2d3b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SMILES'].to_csv('./out/smiles.txt',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c118937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseTokenizer.save of Tokenizer(vocabulary_size=564, model=ByteLevelBPE, add_prefix_space=False, lowercase=False, dropout=None, unicode_normalizer=None, continuing_subword_prefix=None, end_of_word_suffix=None, trim_offsets=False)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = [\"<s>\",\"<PAD>\",\"<MASK>\"]\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "tokenizer.train('./out/smiles.txt', vocab_size=800, min_frequency=1, special_tokens=special_tokens)\n",
    "tokenizer.save_model('./mc/ByteLevelBPETokenizer')\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./mc/ByteLevelBPETokenizer/vocab.json\",\n",
    "    \"./mc/ByteLevelBPETokenizer/merges.txt\",\n",
    ")\n",
    "\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"<PAD>\" , tokenizer.token_to_id(\"<PAD>\")),\n",
    "    (\"<MASK>\", tokenizer.token_to_id(\"<MASK>\")),\n",
    ")\n",
    "\n",
    "tokenizer.enable_padding(length=600)\n",
    "tokenizer.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf35bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Dataset 정의\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, data, smiles, targets, tokenizer, is_test):\n",
    "        self.smiles = data[smiles].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        if not self.is_test:\n",
    "            self.targets = data[targets].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        encoded = self.tokenizer.encode(smile)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return (\n",
    "                torch.tensor(encoded.ids),\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                torch.tensor(encoded.ids),\n",
    "                torch.tensor(self.targets[idx]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "485734f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 설정\n",
    "train_dataset = SMILESDataset(tr_df, 'SMILES', ['MLM','HLM'], tokenizer, False)\n",
    "valid_dataset = SMILESDataset(va_df, 'SMILES', ['MLM','HLM'], tokenizer, False)\n",
    "test_dataset  = SMILESDataset(te_df, 'SMILES', ['MLM','HLM'], tokenizer, True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, pin_memory=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, pin_memory=True, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset , batch_size=64, shuffle=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18dfca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ids for ids,target in train_loader][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db2661d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.emb_layer = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.emb_sequence = nn.Sequential(\n",
    "            #nn.BatchNorm1d(hidden_size),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            #nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb_layer(x).mean(dim=1)\n",
    "        x = self.emb_sequence(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bdd742c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = RegressionModel(vocab_size=800, hidden_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "437f6cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37907d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "769c43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MultiRMSELoss()\n",
    "# optimizer= torch.optim.Adam(model.parameters(), lr=CFG.LEARNING_RATE)#, weight_decay=5e-4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.LEARNING_RATE)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=CFG.LEARNING_RATE, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-7, verbose=True)\n",
    "scheduler = None\n",
    "# early_stopping = EarlyStopping(patience=10,verbose=False,path='')\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d05d2ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "165581b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[0001/1024] loss: 40.12185, val_loss: 36.15742, best_epoch: 1, elapsed: 0.99s, total: 0.99s, remaining: 1008.32s\n",
      "*[0002/1024] loss: 35.83322, val_loss: 36.05397, best_epoch: 2, elapsed: 1.01s, total: 2.00s, remaining: 1035.62s\n",
      "*[0003/1024] loss: 35.77955, val_loss: 36.03536, best_epoch: 3, elapsed: 0.98s, total: 2.99s, remaining: 1000.66s\n",
      "*[0004/1024] loss: 35.76068, val_loss: 36.01447, best_epoch: 4, elapsed: 1.00s, total: 3.99s, remaining: 1024.42s\n",
      "*[0005/1024] loss: 35.74170, val_loss: 35.99284, best_epoch: 5, elapsed: 0.99s, total: 4.98s, remaining: 1004.79s\n",
      "*[0006/1024] loss: 35.71864, val_loss: 35.96947, best_epoch: 6, elapsed: 0.98s, total: 5.97s, remaining: 998.20s\n",
      "*[0007/1024] loss: 35.69179, val_loss: 35.94370, best_epoch: 7, elapsed: 0.98s, total: 6.95s, remaining: 1001.15s\n",
      "*[0008/1024] loss: 35.66010, val_loss: 35.91384, best_epoch: 8, elapsed: 0.98s, total: 7.94s, remaining: 995.31s\n",
      "*[0009/1024] loss: 35.62270, val_loss: 35.87650, best_epoch: 9, elapsed: 0.98s, total: 8.92s, remaining: 997.48s\n",
      "*[0010/1024] loss: 35.57757, val_loss: 35.83359, best_epoch: 10, elapsed: 0.98s, total: 9.91s, remaining: 994.56s\n",
      "*[0011/1024] loss: 35.51115, val_loss: 35.77321, best_epoch: 11, elapsed: 0.98s, total: 10.89s, remaining: 992.13s\n",
      "*[0012/1024] loss: 35.44765, val_loss: 35.71132, best_epoch: 12, elapsed: 0.98s, total: 11.87s, remaining: 991.02s\n",
      "*[0013/1024] loss: 35.36240, val_loss: 35.64683, best_epoch: 13, elapsed: 1.02s, total: 12.89s, remaining: 1029.96s\n",
      "*[0014/1024] loss: 35.27027, val_loss: 35.58048, best_epoch: 14, elapsed: 1.01s, total: 13.91s, remaining: 1021.33s\n",
      "*[0015/1024] loss: 35.14763, val_loss: 35.53622, best_epoch: 15, elapsed: 0.99s, total: 14.90s, remaining: 1001.32s\n",
      "*[0016/1024] loss: 35.05469, val_loss: 35.47040, best_epoch: 16, elapsed: 1.02s, total: 15.93s, remaining: 1028.71s\n",
      "*[0017/1024] loss: 34.93627, val_loss: 35.41932, best_epoch: 17, elapsed: 1.00s, total: 16.92s, remaining: 1002.45s\n",
      "*[0018/1024] loss: 34.81291, val_loss: 35.37353, best_epoch: 18, elapsed: 0.98s, total: 17.91s, remaining: 985.69s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./mc/best_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./mc/final_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 102\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, epochs, early_stopping, device, scheduler, metric_period, verbose, save_model_path, final_model_path, use_best_model, inverse_transform)\u001b[0m\n\u001b[1;32m     99\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[0;32mIn[40], line 168\u001b[0m, in \u001b[0;36mvalidation\u001b[0;34m(model, valid_loader, criterion, device, inverse_transform)\u001b[0m\n\u001b[1;32m    166\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ids,target \u001b[38;5;129;01min\u001b[39;00m valid_loader:\n\u001b[1;32m    169\u001b[0m         ids \u001b[38;5;241m=\u001b[39m ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    170\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[44], line 20\u001b[0m, in \u001b[0;36mSMILESDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     19\u001b[0m     smile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmiles[idx]\n\u001b[0;32m---> 20\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_test:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(encoded\u001b[38;5;241m.\u001b[39mids),\n\u001b[1;32m     25\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tokenizers/implementations/base_tokenizer.py:215\u001b[0m, in \u001b[0;36mBaseTokenizer.encode\u001b[0;34m(self, sequence, pair, is_pretokenized, add_special_tokens)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sequence \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencode: `sequence` can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be `None`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = train(\n",
    "    model, criterion, optimizer, train_loader, valid_loader,\n",
    "    1024, early_stopping, device, scheduler,\n",
    "    metric_period=1, verbose=True,\n",
    "    save_model_path='./mc/best_model.pt',\n",
    "    final_model_path='./mc/final_model.pt',\n",
    "    use_best_model=True,\n",
    "    inverse_transform=inverse_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f47c54",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c911b9e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(best_model,loader,device,inverse_transform):\n",
    "    best_model.to(device)\n",
    "\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for ids,target in iter(loader):\n",
    "            ids = ids.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = best_model(ids)\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "\n",
    "            true_list.append(target)\n",
    "            pred_list.append(output)\n",
    "\n",
    "    trues = torch.cat(true_list,dim=0)\n",
    "    preds = torch.cat(pred_list,dim=0)\n",
    "\n",
    "    trues = trues.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    return trues, preds\n",
    "\n",
    "def predict_test(best_model,loader,device,inverse_transform):\n",
    "    best_model.to(device)\n",
    "\n",
    "    #true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for ids in iter(loader):\n",
    "            ids = ids.to(device)\n",
    "            #target = target.to(device)\n",
    "\n",
    "            output = best_model(ids)\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                #target = inverse_transform(target)\n",
    "\n",
    "            #true_list.append(target)\n",
    "            pred_list.append(output)\n",
    "\n",
    "    #trues = torch.cat(true_list,dim=0)\n",
    "    preds = torch.cat(pred_list,dim=0)\n",
    "\n",
    "    #trues = trues.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1014153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = MultiTaskModel(feature_input_size,output_size,hidden_size,dropout_rate)\n",
    "best_model = RegressionModel(vocab_size=800, hidden_size=512)\n",
    "best_model.load_state_dict(torch.load('./mc/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8697d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_true, tr_pred = predict(best_model,train_loader,device,inverse_transform)\n",
    "va_true, va_pred = predict(best_model,valid_loader,device,inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c924e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(MultiRMSELoss()(torch.tensor(tr_true),torch.tensor(tr_pred)),\n",
    " MultiRMSELoss()(torch.tensor(va_true),torch.tensor(va_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_true[:10].round(1), tr_pred[:10].round(1)\n",
    "# va_true[:10].round(1), va_pred[:10].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(intercept,slope):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, linestyle='--', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552768c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "fig.add_subplot(121)\n",
    "sns.scatterplot(x=tr_true[:,0],y=tr_pred[:,0])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "fig.add_subplot(122)\n",
    "sns.scatterplot(x=tr_true[:,1],y=tr_pred[:,1])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.suptitle('train',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "fig.add_subplot(121)\n",
    "sns.scatterplot(x=va_true[:,0],y=va_pred[:,0])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "fig.add_subplot(122)\n",
    "sns.scatterplot(x=va_true[:,1],y=va_pred[:,1])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.suptitle('validation',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred = predict_test(best_model,test_loader,device,inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit[targets] = te_pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a14b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./out/mlt_efficientnet_mol&fps.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "88a5da79f9030d36a713e3ceec9ed9a47a216907c035af9944c458137c4e5cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
