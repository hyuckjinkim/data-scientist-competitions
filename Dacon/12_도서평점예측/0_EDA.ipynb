{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00ee3ceb-f77c-4630-b874-a09f47d81abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa792f1-1861-4a85-ac18-ff1f49d01b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setdiff(x,y):\n",
    "    return list(set(x)-set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1ae937-d335-4bce-a756-056286c49d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df  = pd.read_csv('./data/test.csv')\n",
    "train_df.columns = [col.replace('-','_').lower() for col in train_df.columns]\n",
    "test_df.columns  = [col.replace('-','_').lower() for col in test_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d574b2-84a6-4b1f-8ac2-21fa15a39185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 건수 : Train(871,393건), Test(159,621건)\n",
      "> Head of Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>age</th>\n",
       "      <th>location</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000000</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_044368</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Road Taken</td>\n",
       "      <td>Rona Jaffe</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Mira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_000001</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_081205</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Macbeth (New Penguin Shakespeare)</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_000002</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_086781</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Waverley (Penguin English Library)</td>\n",
       "      <td>Walter Scott</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Penguin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_000003</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_098622</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>Mother Earth Father Sky</td>\n",
       "      <td>Sue Harrison</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Avon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_000004</td>\n",
       "      <td>USER_00000</td>\n",
       "      <td>BOOK_180810</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>sackville, new brunswick, canada</td>\n",
       "      <td>She Who Remembers</td>\n",
       "      <td>Linda Lay Shuler</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Signet Book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     user_id      book_id  book_rating   age  \\\n",
       "0  TRAIN_000000  USER_00000  BOOK_044368            8  23.0   \n",
       "1  TRAIN_000001  USER_00000  BOOK_081205            8  23.0   \n",
       "2  TRAIN_000002  USER_00000  BOOK_086781            0  23.0   \n",
       "3  TRAIN_000003  USER_00000  BOOK_098622            0  23.0   \n",
       "4  TRAIN_000004  USER_00000  BOOK_180810            8  23.0   \n",
       "\n",
       "                           location                          book_title  \\\n",
       "0  sackville, new brunswick, canada                          Road Taken   \n",
       "1  sackville, new brunswick, canada   Macbeth (New Penguin Shakespeare)   \n",
       "2  sackville, new brunswick, canada  Waverley (Penguin English Library)   \n",
       "3  sackville, new brunswick, canada             Mother Earth Father Sky   \n",
       "4  sackville, new brunswick, canada                   She Who Remembers   \n",
       "\n",
       "           book_author  year_of_publication      publisher  \n",
       "0           Rona Jaffe               2001.0           Mira  \n",
       "1  William Shakespeare               1981.0  Penguin Books  \n",
       "2         Walter Scott               1981.0  Penguin Books  \n",
       "3         Sue Harrison               1991.0           Avon  \n",
       "4     Linda Lay Shuler               1989.0    Signet Book  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('> 건수 : Train({:,}건), Test({:,}건)'.format(len(train_df),len(test_df)))\n",
    "print('> Head of Data')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea620a89-d6bc-4d28-aa76-fccc3af9d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------#\n",
    "# > 도서정보\n",
    "#-----------------------------------------------------------------------------------------------#\n",
    "# (1) ID : 샘플 고유 ID\n",
    "#     - 모두 unique한 값들임\n",
    "#     - train/test는 서로 다 다른 id들임\n",
    "#     - 삭제해도 무관함\n",
    "#\n",
    "# (2) User-ID : 유저 고유 ID\n",
    "#     - 한번씩만 평가한 유저도 있고, 11,143번이나 평가한 유저도 있음\n",
    "#     - nunique : train(83,256건), test(21,909건)\n",
    "#     - train에만있는대상(70,192건), test에만있는대상(8,845건)\n",
    "#\n",
    "# (3) Book-ID : 도서 고유 ID\n",
    "#     - 한번씩만 평가된 책이 있고, 2,502번이나 평가된 책이 있음\n",
    "#     - nunique : train(243,441건), test(62,333건)\n",
    "#     - train에만있는대상(207,723건), test에만있는대상(26,615건)\n",
    "#\n",
    "# - (참조) https://dacon.io/competitions/official/236093/talkboard/408269?page=1&dtype=recent\n",
    "# > Book-ID가 다르더라도 책의 세부 정보가 동일한 경우가 있습니다. 이러한 상황은 다음과 같은 경우에서 발생할 수 있습니다.\n",
    "# 1. 다양한 출판사 및 발행국가 : 동일한 책이 여러 출판사에 의해 출간되거나, 다른 국가 혹은 지역에서 출간될 경우 서로 다른 Book-ID를 가질 수 있습니다.\n",
    "# 2. 다양한 에디션 및 인쇄: 책의 개정판, 갱신판, 확장판 등이 발행될 때마다 새로운 Book-ID가 부여될 수 있습니다. 또한, 책의 여러 인쇄에서도 서로 다른 Book-ID가 사용될 수 있습니다.\n",
    "# 3. 다양한 포맷: 동일한 제목의 책이 하드커버, 종이책, 오디오북, 전자책 등 다양한 형태로 출간될 경우, 각 포맷마다 고유한 Book-ID를 가지게 됩니다.\n",
    "#\n",
    "#-----------------------------------------------------------------------------------------------#\n",
    "# > 유저정보\n",
    "#-----------------------------------------------------------------------------------------------#\n",
    "# (4) Age : 유저의 나이\n",
    "#     - (최소,최대) = train(0,244), test(0,237)으로 데이터가 이상함\n",
    "#     - train에서 0살이 495건(0.06%), 100살 초과가 2,573건(0.30%)으로, 총 3,068건(0.35%) 있음.\n",
    "#     - 이것들을 어떻게 처리할지? (테스트에도 있어서 obs를 제거 할 수 없음.)\n",
    "#     - user_id별로 age의 nunique는 1개씩임 (unique하지 않으면 채워넣으려고 했었는데..)\n",
    "#\n",
    "# (5) Location : 유저의 지역\n",
    "#     - 유저지역이 1개인 곳도 있고, 12,267개인 곳도 있음\n",
    "#     - nunique : train(20,971건), test(8,581건)\n",
    "#     - train에만있는대상(13,897건), test에만있는대상(1,507건)\n",
    "#\n",
    "#-----------------------------------------------------------------------------------------------#\n",
    "# > 도서정보\n",
    "#-----------------------------------------------------------------------------------------------#\n",
    "# (6) Book-Title : 도서명\n",
    "#     - 도서명이 1개인 것도 있고, 2,502개인 것도 있음\n",
    "#     - nunique : train(217,829건), test(59,408건)\n",
    "#     - train에만있는대상(181,636건), test에만있는대상(23,215건)\n",
    "#\n",
    "# (7) Book-Author : 도서 저자\n",
    "#     - 도서저자가 1개인 것도 있고, 8,467개인 것도 있음\n",
    "#     - nunique : train(92,635건), test(32,605건)\n",
    "#     - train에만있는대상(68,980건), test에만있는대상(8,950건) \n",
    "#\n",
    "# (8) Year-Of-Publication : 도서 출판 년도 (-1일 경우 결측 혹은 알 수 없음)\n",
    "#     - 동일한 도서명인데도 출판년도가 다른게 있음 (개정본 등의 이유로 보임)\n",
    "#     - (최소,최대) = train(1376,2021), test(1909,2021)\n",
    "#     - -1인경우가 train에서 11,515(1.32%), test에서 2,425(1.52%)\n",
    "#\n",
    "# (9) Publisher : 출판사\n",
    "#     - 출판사가 1개인 것도 있고, 29,696개인 것도 있음\n",
    "#     - nunique : train(15,505건), test(6,584건)\n",
    "#     - train에만있는대상(10,123건), test에만있는대상(1,202건) \n",
    "\n",
    "#-----------------------------------------------------------------------------------------------#\n",
    "# > 타겟정보\n",
    "#-----------------------------------------------------------------------------------------------#\n",
    "# (10) Book-Rating : 유저가 도서에 부여한 평점 (0점 ~ 10점)\n",
    "#     - 0점은 inplict infomation(암시적 정보?)\n",
    "#     - Rating이 0인 경우는 해당 유저가 특정 책에 관심이 없고, 관련이 없는 경우로 보고 0점도 예측 할 수 있도록 개발필요\n",
    "#     - (참조) : https://dacon.io/competitions/official/236093/talkboard/408231?page=1&dtype=recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadd1640-f72e-4ea4-8f17-cf6d5d2dc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아이디어\n",
    "# (1) 책의 카테고리를 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b669b9-60d7-4997-a6d4-969de3570582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_numeric_infomation(data,string_columns,numeric_columns,agg=['mean','min','max']):\n",
    "    if isinstance(string_columns,str):\n",
    "        string_columns = [string_columns]\n",
    "    if isinstance(numeric_columns,str):\n",
    "        numeric_columns = [numeric_columns]\n",
    "    \n",
    "    new_data = data.copy()\n",
    "    for str_col in tqdm(string_columns):\n",
    "        cnt_data = new_data[str_col].value_counts().reset_index()\\\n",
    "            .rename(columns={'index':str_col,str_col:f'{str_col}_cnt'})\n",
    "        rank_data = new_data[str_col].value_counts().rank(ascending=False).reset_index()\\\n",
    "            .rename(columns={'index':str_col,str_col:f'{str_col}_rank'})\n",
    "        new_data = new_data\\\n",
    "            .merge(cnt_data,how='left',on=str_col)\\\n",
    "            .merge(rank_data,how='left',on=str_col)\n",
    "        for num_col in numeric_columns:\n",
    "            for _agg in agg:\n",
    "                mean_data = new_data.groupby(str_col)[num_col].agg(_agg).reset_index()\\\n",
    "                    .rename(columns={num_col:f'{str_col}_{_agg}_{num_col}'})\n",
    "                new_data = new_data\\\n",
    "                    .merge(mean_data,how='left',on=str_col)\n",
    "        new_data.drop(str_col,axis=1,inplace=True)\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0138a949-69f0-4449-ab81-aa56024d538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:21<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "train_df2 = train_df.copy()\n",
    "\n",
    "# (1) feature들의 type 정리\n",
    "unuse_features = ['id']\n",
    "cat_features   = ['user_id','book_id','location','book_title','book_author','publisher']\n",
    "num_features   = ['age','year_of_publication']\n",
    "target_feature = 'book_rating'\n",
    "\n",
    "# (2) 필요없는 컬럼 제거\n",
    "train_df2.drop(columns=unuse_features,inplace=True)\n",
    "\n",
    "# (3) categorical feature들을 numeric feature로 변환 (category가 너무 많아서 그대로 사용하기 힘듦)\n",
    "train_df2 = string_to_numeric_infomation(data=train_df2,string_columns=cat_features,numeric_columns=num_features)\n",
    "\n",
    "# (4) 모두 하나의 값을 가지는 컬럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c927b2c-8f7b-4afe-97cc-3b17c35ee628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871393, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_rating</th>\n",
       "      <th>age</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>user_id_cnt</th>\n",
       "      <th>user_id_rank</th>\n",
       "      <th>user_id_mean_age</th>\n",
       "      <th>user_id_min_age</th>\n",
       "      <th>user_id_max_age</th>\n",
       "      <th>user_id_mean_year_of_publication</th>\n",
       "      <th>user_id_min_year_of_publication</th>\n",
       "      <th>...</th>\n",
       "      <th>book_author_min_year_of_publication</th>\n",
       "      <th>book_author_max_year_of_publication</th>\n",
       "      <th>publisher_cnt</th>\n",
       "      <th>publisher_rank</th>\n",
       "      <th>publisher_mean_age</th>\n",
       "      <th>publisher_min_age</th>\n",
       "      <th>publisher_max_age</th>\n",
       "      <th>publisher_mean_year_of_publication</th>\n",
       "      <th>publisher_min_year_of_publication</th>\n",
       "      <th>publisher_max_year_of_publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11785.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1990.125</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>6510</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.939324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>2000.402304</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11785.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1990.125</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>14299</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.642492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1992.328345</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11785.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1990.125</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>14299</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.642492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1992.328345</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11785.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1990.125</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>14797</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.492600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1995.910117</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>8</td>\n",
       "      <td>11785.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1990.125</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>16018</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.905232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1996.427769</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_rating   age  year_of_publication  user_id_cnt  user_id_rank  \\\n",
       "0            8  23.0               2001.0            8       11785.0   \n",
       "1            8  23.0               1981.0            8       11785.0   \n",
       "2            0  23.0               1981.0            8       11785.0   \n",
       "3            0  23.0               1991.0            8       11785.0   \n",
       "4            8  23.0               1989.0            8       11785.0   \n",
       "\n",
       "   user_id_mean_age  user_id_min_age  user_id_max_age  \\\n",
       "0              23.0             23.0             23.0   \n",
       "1              23.0             23.0             23.0   \n",
       "2              23.0             23.0             23.0   \n",
       "3              23.0             23.0             23.0   \n",
       "4              23.0             23.0             23.0   \n",
       "\n",
       "   user_id_mean_year_of_publication  user_id_min_year_of_publication  ...  \\\n",
       "0                          1990.125                           1981.0  ...   \n",
       "1                          1990.125                           1981.0  ...   \n",
       "2                          1990.125                           1981.0  ...   \n",
       "3                          1990.125                           1981.0  ...   \n",
       "4                          1990.125                           1981.0  ...   \n",
       "\n",
       "   book_author_min_year_of_publication  book_author_max_year_of_publication  \\\n",
       "0                               1976.0                               2004.0   \n",
       "1                                 -1.0                               2004.0   \n",
       "2                               1972.0                               2002.0   \n",
       "3                               1990.0                               2002.0   \n",
       "4                               1988.0                               1997.0   \n",
       "\n",
       "   publisher_cnt  publisher_rank  publisher_mean_age  publisher_min_age  \\\n",
       "0           6510            22.0           37.939324                0.0   \n",
       "1          14299            10.0           35.642492                0.0   \n",
       "2          14299            10.0           35.642492                0.0   \n",
       "3          14797             9.0           37.492600                0.0   \n",
       "4          16018             8.0           36.905232                0.0   \n",
       "\n",
       "   publisher_max_age  publisher_mean_year_of_publication  \\\n",
       "0              204.0                         2000.402304   \n",
       "1              201.0                         1992.328345   \n",
       "2              201.0                         1992.328345   \n",
       "3              239.0                         1995.910117   \n",
       "4              239.0                         1996.427769   \n",
       "\n",
       "   publisher_min_year_of_publication  publisher_max_year_of_publication  \n",
       "0                             1992.0                             2004.0  \n",
       "1                               -1.0                             2004.0  \n",
       "2                               -1.0                             2004.0  \n",
       "3                             1964.0                             2004.0  \n",
       "4                               -1.0                             2004.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df2.shape)\n",
    "train_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0d5334-20d4-4bf0-9113-de9eca6cf187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_equal_columns(data):\n",
    "    new_data = data.copy()\n",
    "    \n",
    "    try_iter = 0\n",
    "    while True:\n",
    "        try_iter+=1\n",
    "        columns = new_data.columns\n",
    "        equal_column_list = []\n",
    "        \n",
    "        pbar = trange(new_data.shape[1])\n",
    "        for i in pbar:\n",
    "            pbar.set_description('Try({}) '.format(try_iter))\n",
    "            for j in range(new_data.shape[1]):\n",
    "                if i>j:\n",
    "                    col_i, col_j = columns[i], columns[j]\n",
    "\n",
    "                    if new_data[col_i].nunique() == new_data[col_j].nunique():\n",
    "                        ct = pd.crosstab(new_data[col_i],new_data[col_j])\n",
    "                        if np.diag(ct).sum() == len(new_data):\n",
    "                            equal_column_list.append([col_i,col_j])\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        if len(equal_column_list)>0:\n",
    "            delete_columns = pd.unique(np.array(equal_column_list)[:,-1])\n",
    "            new_data = new_data.drop(columns=delete_columns)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a1a3cb-280a-4e93-a578-4c644905d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Try(1) : 100%|██████████| 51/51 [00:17<00:00,  2.86it/s]\n",
      "Try(2) : 100%|██████████| 45/45 [00:13<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df3 = delete_equal_columns(train_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f7986a-c486-4f4e-b5c4-36c8d684a11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(871393, 51) (871393, 45)\n"
     ]
    }
   ],
   "source": [
    "print(train_df2.shape,train_df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "632f12be-478c-4b4e-b3a7-b1029210eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df3.drop(target_feature,axis=1)\n",
    "y = train_df3[target_feature]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2,shuffle=True,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91dbaa64-26d3-42d1-95cd-56df4afee136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.066556\n",
      "0:\tlearn: 2.1487805\ttest: 2.1486697\tbest: 2.1486697 (0)\ttotal: 536ms\tremaining: 44m 39s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7511cbd61039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5126\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5128\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5129\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m             \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   2356\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    #loss_function='RMSE',\n",
    "    random_state=0,\n",
    "    iterations=5000,\n",
    ")\n",
    "model.fit(\n",
    "    X_train,y_train,\n",
    "    eval_set=[(X_valid,y_valid)],\n",
    "    metric_period=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54b42e6b-2b8c-4299-a2cd-a0f9fb1283cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>15253</td>\n",
       "      <td>23892</td>\n",
       "      <td>24354</td>\n",
       "      <td>21716</td>\n",
       "      <td>16934</td>\n",
       "      <td>6224</td>\n",
       "      <td>906</td>\n",
       "      <td>185</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>89</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>142</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>210</td>\n",
       "      <td>323</td>\n",
       "      <td>149</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>301</td>\n",
       "      <td>495</td>\n",
       "      <td>221</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>344</td>\n",
       "      <td>1055</td>\n",
       "      <td>1936</td>\n",
       "      <td>2509</td>\n",
       "      <td>1465</td>\n",
       "      <td>224</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>248</td>\n",
       "      <td>667</td>\n",
       "      <td>1383</td>\n",
       "      <td>1923</td>\n",
       "      <td>896</td>\n",
       "      <td>141</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>529</td>\n",
       "      <td>1367</td>\n",
       "      <td>2697</td>\n",
       "      <td>3983</td>\n",
       "      <td>1916</td>\n",
       "      <td>397</td>\n",
       "      <td>159</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>697</td>\n",
       "      <td>1878</td>\n",
       "      <td>3459</td>\n",
       "      <td>5090</td>\n",
       "      <td>2951</td>\n",
       "      <td>705</td>\n",
       "      <td>266</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>386</td>\n",
       "      <td>1128</td>\n",
       "      <td>2157</td>\n",
       "      <td>3157</td>\n",
       "      <td>2012</td>\n",
       "      <td>606</td>\n",
       "      <td>204</td>\n",
       "      <td>139</td>\n",
       "      <td>261</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>469</td>\n",
       "      <td>1190</td>\n",
       "      <td>2182</td>\n",
       "      <td>3400</td>\n",
       "      <td>2530</td>\n",
       "      <td>1083</td>\n",
       "      <td>487</td>\n",
       "      <td>272</td>\n",
       "      <td>314</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        -2   -1      0      1      2      3      4     5     6    7   \\\n",
       "book_rating                                                                 \n",
       "0              3  246  15253  23892  24354  21716  16934  6224   906  185   \n",
       "1              0    0      5     20     39     52     89    42    10    2   \n",
       "2              0    0      6     33     48    100    142    64     8    2   \n",
       "3              0    0     16     45    108    210    323   149    21    3   \n",
       "4              0    0      6     68    163    301    495   221    29    8   \n",
       "5              0    0     57    344   1055   1936   2509  1465   224   45   \n",
       "6              0    0     33    248    667   1383   1923   896   141   33   \n",
       "7              0    1     79    529   1367   2697   3983  1916   397  159   \n",
       "8              0    0     95    697   1878   3459   5090  2951   705  266   \n",
       "9              0    0     42    386   1128   2157   3157  2012   606  204   \n",
       "10             0    0     46    469   1190   2182   3400  2530  1083  487   \n",
       "\n",
       "col_0         8    9    10  \n",
       "book_rating                 \n",
       "0             29   18    1  \n",
       "1              0    2    0  \n",
       "2              1    0    0  \n",
       "3              0    0    0  \n",
       "4              1    0    0  \n",
       "5             12   34    2  \n",
       "6             10    0    0  \n",
       "7             32   10    1  \n",
       "8            125  127    1  \n",
       "9            139  261    7  \n",
       "10           272  314   32  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_valid)\n",
    "preds = [int(np.round(p,0)) for p in preds]\n",
    "pd.crosstab(y_valid,preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
