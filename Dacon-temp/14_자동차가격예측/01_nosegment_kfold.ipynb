{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b987cd1-0680-4fb8-a482-f5567577e80f",
   "metadata": {},
   "source": [
    "# Library Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eeab870-95ed-41a6-b815-1bdf2dee38fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b6f33-3b7d-401a-a710-ea0f089f95a7",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b54b8f-874d-49c7-95db-a535b984b01d",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe03a3b-5d80-448f-ad15-50e77c5128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 0\n",
    "    \n",
    "    SUBSET_DEPTH = 3\n",
    "    INTERACTION = False\n",
    "    \n",
    "    N_SPLITS = 5\n",
    "    \n",
    "    LR = 0.03\n",
    "    EPOCHS = 10000\n",
    "    ES = 300\n",
    "    XGB_LR = 0.3     # default\n",
    "    XGB_EPOCHS = 100 # default\n",
    "    XGB_ES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f2cfe-7bf1-4cc3-b7e3-90b0886eab54",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbf58b-29ed-4ab7-9a2c-f51c6b08c00a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8ae59-c4c3-47f8-854a-6cfc780a2adc",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a824834-ad27-424a-8f55-7c4ca73eaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df  = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da88a595-b068-4b4b-97a9-4e6bcf863305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57920, 15), (14480, 14))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d6f038-af80-42c0-a33e-e62dcd8bdfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>생산년도</th>\n",
       "      <th>모델출시년도</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>차량모델명</th>\n",
       "      <th>판매도시</th>\n",
       "      <th>판매구역</th>\n",
       "      <th>주행거리</th>\n",
       "      <th>배기량</th>\n",
       "      <th>압축천연가스(CNG)</th>\n",
       "      <th>경유</th>\n",
       "      <th>가솔린</th>\n",
       "      <th>하이브리드</th>\n",
       "      <th>액화석유가스(LPG)</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>2018</td>\n",
       "      <td>2014</td>\n",
       "      <td>skoda</td>\n",
       "      <td>fabia</td>\n",
       "      <td>KAT</td>\n",
       "      <td>SLA</td>\n",
       "      <td>85231</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>toyota</td>\n",
       "      <td>auris</td>\n",
       "      <td>RKO</td>\n",
       "      <td>SWI</td>\n",
       "      <td>135000</td>\n",
       "      <td>1598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>clk-klasa</td>\n",
       "      <td>GNI</td>\n",
       "      <td>WIE</td>\n",
       "      <td>255223</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>nissan</td>\n",
       "      <td>x-trail</td>\n",
       "      <td>EHX</td>\n",
       "      <td>WIE</td>\n",
       "      <td>238000</td>\n",
       "      <td>2184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>fiat</td>\n",
       "      <td>bravo</td>\n",
       "      <td>OSW</td>\n",
       "      <td>MAL</td>\n",
       "      <td>251000</td>\n",
       "      <td>1910</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  생산년도  모델출시년도            브랜드      차량모델명 판매도시 판매구역    주행거리  \\\n",
       "0  TRAIN_00000  2018    2014          skoda      fabia  KAT  SLA   85231   \n",
       "1  TRAIN_00001  2010    2006         toyota      auris  RKO  SWI  135000   \n",
       "2  TRAIN_00002  2002    2002  mercedes-benz  clk-klasa  GNI  WIE  255223   \n",
       "3  TRAIN_00003  2006    2001         nissan    x-trail  EHX  WIE  238000   \n",
       "4  TRAIN_00004  2007    2007           fiat      bravo  OSW  MAL  251000   \n",
       "\n",
       "    배기량  압축천연가스(CNG)  경유  가솔린  하이브리드  액화석유가스(LPG)     가격  \n",
       "0   999            0   0    1      0            0  51.74  \n",
       "1  1598            0   0    1      0            0  41.47  \n",
       "2  1796            0   0    1      0            0  17.81  \n",
       "3  2184            0   1    0      0            0  18.20  \n",
       "4  1910            0   1    0      0            0  17.55  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c323f-9e86-4fe2-9e09-395d4e290050",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0aab2e-3a95-4013-a15e-d141663182ea",
   "metadata": {},
   "source": [
    "## Resetting Columns Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbffe1aa-eef1-4263-933e-492cbbf6cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeResetting:\n",
    "    def __init__(self):\n",
    "        self.cat_features = ['브랜드','차량모델명','판매도시','판매구역','생산년도','모델출시년도']\n",
    "        \n",
    "    def add_categorical_features(self,cat_features):\n",
    "        self.cat_features += cat_features\n",
    "        \n",
    "    def fit(self,data):\n",
    "        self.target_feature = ['가격']\n",
    "        self.unuse_features = ['ID']\n",
    "        self.dummy_features = ['압축천연가스(CNG)','액화석유가스(LPG)','경유','가솔린','하이브리드']\n",
    "        self.num_features   = [col for col in data.columns\n",
    "                               if col not in self.target_feature+self.unuse_features+self.dummy_features+self.cat_features]\n",
    "        \n",
    "    def transform(self,data):\n",
    "        d = data.copy()\n",
    "        for col in self.dummy_features:\n",
    "            if d[col].dtypes!=int:\n",
    "                d[col] = d[col].astype(int)\n",
    "        for col in self.cat_features:\n",
    "            if d[col].dtypes!=object:\n",
    "                d[col] = d[col].astype(str)\n",
    "        for col in self.num_features:\n",
    "            if d[col].dtypes!=float:\n",
    "                d[col] = d[col].astype(float)\n",
    "        for col in self.unuse_features:\n",
    "            if col in d.columns:\n",
    "                d.drop(col,axis=1,inplace=True)\n",
    "        return d\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "    def get_feature_type(self):\n",
    "        globals()['target_feature'] = self.target_feature\n",
    "        globals()['unuse_features'] = self.unuse_features\n",
    "        globals()['dummy_features'] = self.dummy_features\n",
    "        globals()['cat_features']   = self.cat_features\n",
    "        globals()['num_features']   = self.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5177c8-be0f-4363-8ec8-8849f4531ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_resetor = TypeResetting()\n",
    "type_resetor.fit(train_df)\n",
    "type_resetor.get_feature_type()\n",
    "\n",
    "train_df2 = type_resetor.transform(train_df)\n",
    "test_df2  = type_resetor.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9166d7-d880-4117-a2da-9422f62428ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"always\")\n",
    "\n",
    "def check_only_oneside(train,test,cat_features):\n",
    "    not_test_only_features = []\n",
    "    for iter,col in enumerate(cat_features):\n",
    "        print('[{}/{}] {}'.format(iter+1,len(cat_features),col))\n",
    "        \n",
    "        only_train = list(set(train[col].unique())-set(test[col].unique()))\n",
    "        only_test  = list(set(test[col].unique())-set(train[col].unique()))\n",
    "        print(' - Only Train:',len(only_train))\n",
    "        print(' - Only Test :',len(only_test))\n",
    "        if len(only_test)>0:\n",
    "            print('******Warning******')\n",
    "        else:\n",
    "            not_test_only_features.append(col)\n",
    "        print('')\n",
    "    return not_test_only_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8c40f7-1201-4598-9558-d086e9ab1575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/11] 브랜드\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[2/11] 차량모델명\n",
      " - Only Train: 2\n",
      " - Only Test : 0\n",
      "\n",
      "[3/11] 판매도시\n",
      " - Only Train: 1750\n",
      " - Only Test : 300\n",
      "******Warning******\n",
      "\n",
      "[4/11] 판매구역\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[5/11] 생산년도\n",
      " - Only Train: 3\n",
      " - Only Test : 1\n",
      "******Warning******\n",
      "\n",
      "[6/11] 모델출시년도\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[7/11] 압축천연가스(CNG)\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[8/11] 액화석유가스(LPG)\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[9/11] 경유\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[10/11] 가솔린\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n",
      "[11/11] 하이브리드\n",
      " - Only Train: 0\n",
      " - Only Test : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 브랜드, 차량모델명, 판매구역, 모델출시년도\n",
    "not_test_only_features = check_only_oneside(train_df2,test_df2,cat_features+dummy_features)\n",
    "not_test_only_features = list(set(not_test_only_features)-set(dummy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4fb877-5302-4a4d-8b79-7f5de66c6b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['브랜드', '차량모델명', '모델출시년도', '판매구역']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_test_only_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e4f9c9-329b-4595-bfef-b605db16860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>브랜드</th>\n",
       "      <th>차량모델명</th>\n",
       "      <th>압축천연가스(CNG)</th>\n",
       "      <th>액화석유가스(LPG)</th>\n",
       "      <th>경유</th>\n",
       "      <th>가솔린</th>\n",
       "      <th>하이브리드</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>gle-klasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bmw</td>\n",
       "      <td>seria-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bmw</td>\n",
       "      <td>x6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>nissan</td>\n",
       "      <td>patrol</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>fiat</td>\n",
       "      <td>doblo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               브랜드      차량모델명  압축천연가스(CNG)  액화석유가스(LPG)  경유  가솔린  하이브리드  cnt\n",
       "214  mercedes-benz  gle-klasa            0            0   0    1      0    1\n",
       "42             bmw    seria-5            0            0   0    0      1    1\n",
       "63             bmw         x6            0            0   0    0      1    1\n",
       "250         nissan     patrol            0            0   0    1      0    1\n",
       "81            fiat      doblo            1            0   0    0      0    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_df = train_df.groupby(['브랜드','차량모델명']+dummy_features).size().reset_index().rename(columns={0:'cnt'}).sort_values('cnt')\n",
    "print(seg_df.shape)\n",
    "seg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204816d7-af14-427d-bc50-32b876febd64",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5254fac-62ad-4ca8-98d9-0cc687d11af2",
   "metadata": {},
   "source": [
    "# New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1faf8654-f04e-43ed-be0a-965a18e71664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>생산년도</th>\n",
       "      <th>모델출시년도</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>차량모델명</th>\n",
       "      <th>판매도시</th>\n",
       "      <th>판매구역</th>\n",
       "      <th>주행거리</th>\n",
       "      <th>배기량</th>\n",
       "      <th>압축천연가스(CNG)</th>\n",
       "      <th>경유</th>\n",
       "      <th>가솔린</th>\n",
       "      <th>하이브리드</th>\n",
       "      <th>액화석유가스(LPG)</th>\n",
       "      <th>가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>2018</td>\n",
       "      <td>2014</td>\n",
       "      <td>skoda</td>\n",
       "      <td>fabia</td>\n",
       "      <td>KAT</td>\n",
       "      <td>SLA</td>\n",
       "      <td>85231</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>toyota</td>\n",
       "      <td>auris</td>\n",
       "      <td>RKO</td>\n",
       "      <td>SWI</td>\n",
       "      <td>135000</td>\n",
       "      <td>1598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>clk-klasa</td>\n",
       "      <td>GNI</td>\n",
       "      <td>WIE</td>\n",
       "      <td>255223</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>nissan</td>\n",
       "      <td>x-trail</td>\n",
       "      <td>EHX</td>\n",
       "      <td>WIE</td>\n",
       "      <td>238000</td>\n",
       "      <td>2184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>fiat</td>\n",
       "      <td>bravo</td>\n",
       "      <td>OSW</td>\n",
       "      <td>MAL</td>\n",
       "      <td>251000</td>\n",
       "      <td>1910</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  생산년도  모델출시년도            브랜드      차량모델명 판매도시 판매구역    주행거리  \\\n",
       "0  TRAIN_00000  2018    2014          skoda      fabia  KAT  SLA   85231   \n",
       "1  TRAIN_00001  2010    2006         toyota      auris  RKO  SWI  135000   \n",
       "2  TRAIN_00002  2002    2002  mercedes-benz  clk-klasa  GNI  WIE  255223   \n",
       "3  TRAIN_00003  2006    2001         nissan    x-trail  EHX  WIE  238000   \n",
       "4  TRAIN_00004  2007    2007           fiat      bravo  OSW  MAL  251000   \n",
       "\n",
       "    배기량  압축천연가스(CNG)  경유  가솔린  하이브리드  액화석유가스(LPG)     가격  \n",
       "0   999            0   0    1      0            0  51.74  \n",
       "1  1598            0   0    1      0            0  41.47  \n",
       "2  1796            0   0    1      0            0  17.81  \n",
       "3  2184            0   1    0      0            0  18.20  \n",
       "4  1910            0   1    0      0            0  17.55  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6541725-7cf0-4e7d-960b-cb96da805e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import chain, combinations\n",
    "def all_subsets(ss):\n",
    "    return list(chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1))))\n",
    "\n",
    "class FeatureEngineering:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _get_quantile(self,x,col):\n",
    "        x = np.array(x).flatten()\n",
    "        x = x[pd.notnull(x)]\n",
    "\n",
    "        agg_df = pd.DataFrame(index=[0])\n",
    "        for q in [0,25,50,75,100]:\n",
    "            agg_df[f'{col}_Q{q}'] = np.quantile(x,q/100)\n",
    "\n",
    "        return agg_df\n",
    "    \n",
    "    def _derived_features(self,data):\n",
    "        d = data.copy()\n",
    "\n",
    "        # (1) 모델출시년도에 생산된 차량인지\n",
    "        d['출시년도생산여부'] = np.where(d['생산년도'].astype(float)==d['모델출시년도'].astype(float),1,0)\n",
    "\n",
    "        # (2) 모델출시 이후에 몇년 지나서 생산됬는지\n",
    "        d['출시이후생산년수'] = d['생산년도'].astype(float)-d['모델출시년도'].astype(float)\n",
    "\n",
    "        # (3) 출시 이전에 생산되었는지\n",
    "        d['출시이전생산여부'] = np.where(d['출시이후생산년수']<0,1,0)\n",
    "\n",
    "        # (4) 브랜드의 국적 (구글링)\n",
    "        d['브랜드국적'] = ['체코' if brand=='skoda' else\n",
    "                        '일본' if brand in ['toyota','nissan','mazda','honda','mitsubishi'] else\n",
    "                        '독일' if brand in ['mercedes-benz','audi','volkswagen','bmw','opel'] else\n",
    "                        '이탈리아' if brand=='fiat' else\n",
    "                        '프랑스' if brand in ['renault','citroen','peugeot'] else\n",
    "                        '미국' if brand=='ford' else\n",
    "                        '한국' if brand in ['kia','hyundai'] else\n",
    "                        '스페인' if brand=='seat' else\n",
    "                        '스웨덴' if brand=='volvo' else\n",
    "                        np.nan for brand in d['브랜드']]\n",
    "\n",
    "        # (5) 브랜드 국적의 대륙명\n",
    "        d['브랜드대륙명'] = ['유럽' if country in ['체코','독일','이탈리아','프랑스','스페인','스웨덴'] else\n",
    "                          '아시아' if country in ['일본','한국'] else\n",
    "                          '아메리카' if country in ['미국'] else\n",
    "                          np.nan for country in d['브랜드국적']]\n",
    "        return d\n",
    "    \n",
    "    def fit(self,data,cat_features,subset_depth=1):\n",
    "        assert '가격' in data.columns, \\\n",
    "            'Input data must be training dataset'\n",
    "        assert len(cat_features)>=subset_depth, \\\n",
    "            'len(cat_features) >= subset_depth'\n",
    "        \n",
    "        self.cat_features = cat_features\n",
    "        self.new_cat_features = ['출시년도생산여부','출시이후생산년수','출시이전생산여부','브랜드국적','브랜드대륙명']\n",
    "        \n",
    "        # (6) 카테고리 변수에 따른 가격의 Quantile값\n",
    "        all_subset_list = all_subsets(cat_features)\n",
    "        all_subset_list = [subset for subset in all_subset_list if (len(subset)<=subset_depth) & (len(subset)>=1)]\n",
    "        \n",
    "        self.agg_dict = {}\n",
    "        for subset in tqdm(all_subset_list,desc=f'Get quantiles of target by categorical features (depth={subset_depth})'):\n",
    "            subset = list(subset)\n",
    "            subset_name = '_'.join(subset)\n",
    "            agg_fn = data.groupby(subset)['가격'].apply(lambda x: self._get_quantile(x,subset_name)).reset_index()\n",
    "            drop_cols = [col for col in agg_fn if col.find('level_')>=0]\n",
    "            agg_fn.drop(columns=drop_cols,inplace=True)\n",
    "            self.agg_dict[subset_name] = agg_fn\n",
    "            \n",
    "    def transform(self,data):\n",
    "        data = self._derived_features(data)\n",
    "        for key,agg_fn in self.agg_dict.items():\n",
    "            data = pd.merge(data,agg_fn,how='left',on=key.split('_'))\n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self,data,cat_features,subset_depth=1):\n",
    "        self.fit(data,cat_features,subset_depth)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a085347-abaa-4e5f-9f9b-f71f226bf84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get quantiles of target by categorical features (depth=3): 100%|██████████| 14/14 [00:16<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineering()\n",
    "fe.fit(\n",
    "    data=train_df2,\n",
    "    cat_features=not_test_only_features, \n",
    "    subset_depth=CFG.SUBSET_DEPTH,\n",
    ")\n",
    "train_df3 = fe.transform(train_df2)\n",
    "test_df3  = fe.transform(test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29021d0-ce57-42c8-8a78-0f9cc4209d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['출시년도생산여부', '출시이후생산년수', '출시이전생산여부', '브랜드국적', '브랜드대륙명']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.new_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa09b13-62ca-425d-bab5-299828454fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_resetor = TypeResetting()\n",
    "type_resetor.add_categorical_features(fe.new_cat_features)\n",
    "type_resetor.fit(train_df3)\n",
    "type_resetor.get_feature_type()\n",
    "\n",
    "train_df3 = type_resetor.transform(train_df3)\n",
    "test_df3  = type_resetor.transform(test_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af8e5c65-95f9-4a32-b63d-c074537853de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57920, 89)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65939305-7703-474a-912d-3841f3eed25d",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f1466-3f68-43ec-a104-181930321dce",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1e3686-4ea5-4147-a968-4dc93785c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_num_features = [col for col in num_features if col.find('_Q')<0]\n",
    "\n",
    "# i=0\n",
    "# for col in check_num_features:\n",
    "#     i+=1\n",
    "#     print('\\n({}/{}) {}'.format(i,len(check_num_features),col))\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.scatterplot(x=train_df3['가격'],y=train_df3[col])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920fd41-52ab-4de1-82a4-d9a5b28a4346",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6171ab-e115-43a0-906e-ea644ee74b86",
   "metadata": {},
   "source": [
    "# Add the Interaction Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c35453f-0aae-4d1c-b034-f47a24ec1798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import trange\n",
    "\n",
    "def get_abs_corr(x,y):\n",
    "    return np.abs(np.corrcoef(x,y))[0,1]\n",
    "\n",
    "class InteractionTerm:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,num_features,corr_cutoff=0.7):\n",
    "        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "        \n",
    "        d = data.copy()\n",
    "        self.interaction_list = []\n",
    "        for i in range(len(num_features)):\n",
    "            for j in range(len(num_features)):\n",
    "                if i>j:\n",
    "                    col_i = num_features[i]\n",
    "                    col_j = num_features[j]\n",
    "                    \n",
    "                    # 상관계수가 cutoff보다 큰 경우에는 interaction을 생성하지 않음\n",
    "                    if (get_abs_corr(d[col_i]*d[col_j],d[col_i])>=corr_cutoff) | (get_abs_corr(d[col_i]*d[col_j],d[col_j])>=corr_cutoff):\n",
    "                        pass\n",
    "                    else:\n",
    "                        self.interaction_list.append(f'{col_i}*{col_j}')\n",
    "    \n",
    "    def transform(self,data):\n",
    "        d = data.copy()\n",
    "        for interaction in self.interaction_list:\n",
    "            col_i,col_j = interaction.split('*')\n",
    "            d[interaction] = d[col_i]*d[col_j]\n",
    "        return d\n",
    "    \n",
    "    def fit_transform(self,data,num_features,corr_cutoff=0.7):\n",
    "        self.fit(data,num_features,corr_cutoff)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e973e0f2-e229-493c-9ad0-a42c086a35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4 = train_df3.copy()\n",
    "test_df4  = test_df3.copy()\n",
    "\n",
    "if CFG.INTERACTION:\n",
    "    interaction_maker = InteractionTerm()\n",
    "    interaction_maker.fit(\n",
    "        data=train_df3,\n",
    "        num_features=num_features,\n",
    "        corr_cutoff=0.7,\n",
    "    )\n",
    "    train_df4 = interaction_maker.transform(train_df4)\n",
    "    test_df4  = interaction_maker.transform(test_df4)\n",
    "\n",
    "    type_resetor = TypeResetting()\n",
    "    type_resetor.add_categorical_features(fe.new_cat_features)\n",
    "    type_resetor.fit(train_df4)\n",
    "    type_resetor.get_feature_type()\n",
    "\n",
    "    train_df4 = type_resetor.transform(train_df4)\n",
    "    test_df4  = type_resetor.transform(test_df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3732aa9-e9d7-41d5-8e8c-667699fe5a30",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec950f8-0d43-4b9a-97ed-6feac553dba3",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "880a07b7-5116-410a-a6d0-0d2c50b151b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=0\n",
    "# for i in range(len(num_features)):\n",
    "#     for j in range(len(num_features)):\n",
    "#         if i>j:\n",
    "#             col_i = num_features[i]\n",
    "#             col_j = num_features[j]\n",
    "#             corr = np.corrcoef(train_df4[col_i],train_df4[col_j])[0,1]\n",
    "#             if corr>=0.7:\n",
    "#                 k+=1\n",
    "#                 print(k,col_i,col_j,corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a54002d-d1fd-4c93-a29c-39556f48824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38e1e0d-3c13-4c6e-81a1-9e18d0f05e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_offset(x):\n",
    "    if min(x)>0:\n",
    "        offset = 0\n",
    "    elif min(x)==0:\n",
    "        offset = 1e-3\n",
    "    else:\n",
    "        offset = min(x)+1e-3\n",
    "        print('minimum = {:.3f}'.format(min(x)))\n",
    "    return np.log(x+offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40318716-a92d-459a-9ff7-9c1d262a107d",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8304c3-426d-4a24-89cc-d3c76a5ea249",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6e1cc67-3282-47c3-ada7-8c7776443b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81d460ab-4868-423a-8f9c-08e0b456ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:03<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "check_cat_features = [col for col in cat_features if train_df4[col].nunique()<=100]\n",
    "\n",
    "# (1) ANOVA를 해서 p-value가 0.05보다 높은 것들 확인\n",
    "pvalue_list = []\n",
    "for col in tqdm(check_cat_features):\n",
    "    d = train_df4[[col,'가격']].rename(columns={col:'feature'})\n",
    "    \n",
    "    model = ols(f'가격 ~ C(feature)',data=d).fit()\n",
    "    pvalue = anova_lm(model).values[0][-1]\n",
    "    pvalue_list.append([col,pvalue])\n",
    "    \n",
    "pvalue_df = pd.DataFrame(pvalue_list,columns=['feature','pvalue'])\\\n",
    "    .sort_values('pvalue',ascending=False)\n",
    "# pvalue_df[pvalue_df.pvalue>=alpha].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90277925-192b-4514-beb0-675a1dddd086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# (2) (1)에서 유의하지않은 feature들은 log적용 후에도 유의하지 않으면 제외\n",
    "pvalue_list2 = []\n",
    "unsignificant_features = pvalue_df[pvalue_df.pvalue>alpha].feature.tolist()\n",
    "for col in tqdm(unsignificant_features):\n",
    "    d = train_df4[[col,'target']].rename(columns={col:'feature'})\n",
    "    d['feature'] = log_offset(d['feature'])\n",
    "    \n",
    "    model = ols(f'feature ~ C(target)',data=d).fit()\n",
    "    pvalue = anova_lm(model).values[0][-1]\n",
    "    pvalue_list2.append([col,pvalue])\n",
    "    \n",
    "pvalue_df2 = pd.DataFrame(pvalue_list2,columns=['feature','pvalue'])\\\n",
    "    .sort_values('pvalue',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a33f82a-221e-4c73-a7e1-6edb0aec18f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> delete_features\n",
      "  - length : 0\n",
      "  - feature_name : []\n",
      "\n",
      "> log_features\n",
      "  - length : 0\n",
      "  - feature_name : []\n"
     ]
    }
   ],
   "source": [
    "delete_features = pvalue_df2[pvalue_df2.pvalue> alpha].feature.tolist()\n",
    "log_features    = pvalue_df2[pvalue_df2.pvalue<=alpha].feature.tolist()\n",
    "print('> delete_features')\n",
    "print('  - length : {}'.format(len(delete_features)))\n",
    "print('  - feature_name : {}'.format(delete_features))\n",
    "print('')\n",
    "print('> log_features')\n",
    "print('  - length : {}'.format(len(log_features)))\n",
    "print('  - feature_name : {}'.format(log_features))\n",
    "\n",
    "train_df5 = train_df4.copy()\n",
    "train_df5.drop(delete_features,axis=1,inplace=True)\n",
    "for col in log_features:\n",
    "    train_df5[col] = log_offset(train_df5[col])\n",
    "    \n",
    "test_df5 = test_df4.copy()\n",
    "test_df5.drop(delete_features,axis=1,inplace=True)\n",
    "for col in log_features:\n",
    "    test_df5[col] = log_offset(test_df5[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176ea54-23ec-469f-b732-88b6afcac30e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501bbc25-a915-4b50-9fb3-d6689c37a216",
   "metadata": {},
   "source": [
    "## Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c13b45c5-3c59-404e-bb14-b023dad4705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "pvalue_list = []\n",
    "for col in num_features:\n",
    "    corr,pvalue = scipy.stats.pearsonr(train_df5['가격'],train_df5[col])\n",
    "    pvalue_list.append([col,pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d178a263-70c2-4a52-9974-fa45e9dd5f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>판매구역_Q0</td>\n",
       "      <td>0.3518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>판매구역_Q100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>브랜드_Q0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>판매구역_Q25</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>브랜드_Q100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  pvalue\n",
       "17    판매구역_Q0  0.3518\n",
       "21  판매구역_Q100  0.0000\n",
       "2      브랜드_Q0  0.0000\n",
       "18   판매구역_Q25  0.0000\n",
       "6    브랜드_Q100  0.0000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_df = pd.DataFrame(pvalue_list,columns=['feature','pvalue'])\\\n",
    "    .sort_values('pvalue',ascending=False)\n",
    "\n",
    "pvalue_df.round(4).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc32ace-0b1a-4235-b3aa-b834096d6c02",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdebcae-a0db-4e33-8f6a-8d655989d04f",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "330d67f2-4951-4092-aefd-1be42b8577e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def mkdir(paths):\n",
    "    if type(paths)==str:\n",
    "        paths = [paths]\n",
    "    for path in paths:\n",
    "        if not os.path.isdir(path):\n",
    "            print('> Create Folder: {}'.format(path))\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01609cc3-d341-4d8c-9295-45934f1e4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir('./model_checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4369ef-ddbf-42f5-8d3b-008573b4b6b9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f1b72-9651-42d2-8410-52fd85595f88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CatBoost\n",
    "- public score : 6.2625421575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "251d6bfc-9f23-4ad2-bca5-16a3d57c42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8f0d0-b0cc-4990-8d0d-03517b587841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train_df5.drop(target_feature,axis=1)\n",
    "# y = train_df5[target_feature]\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da2683aa-dd52-4402-a77b-7560b27b9f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337d0e1-fed1-4419-8789-b4ced37563c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 22분\n",
    "\n",
    "X = train_df5.drop(target_feature,axis=1)\n",
    "y = train_df5[target_feature]\n",
    "\n",
    "kf = KFold(n_splits=CFG.N_SPLITS,random_state=CFG.SEED,shuffle=True)\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "k=0\n",
    "for train_idx, valid_idx in tqdm(kf.split(X,y),total=CFG.N_SPLITS):\n",
    "    k+=1\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    train_dataset = Pool(X_train,y_train,cat_features=cat_features)\n",
    "    valid_dataset = Pool(X_valid,y_valid,cat_features=cat_features)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        loss_function='MAE',\n",
    "        random_state=CFG.SEED,\n",
    "        iterations=CFG.EPOCHS,\n",
    "        learning_rate=CFG.LR,\n",
    "        allow_writing_files=False,\n",
    "    )\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        eval_set=valid_dataset,\n",
    "        metric_period=int(CFG.EPOCHS/5),\n",
    "        early_stopping_rounds=CFG.ES,\n",
    "    )\n",
    "    model.save_model(f'./model_checkpoints/kfold_model_{k}.cbm')\n",
    "    \n",
    "    y_pred = model.predict(valid_dataset).flatten()\n",
    "    y_true = y_valid.values\n",
    "    score = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "    \n",
    "    print('K-Fold {}, MAE: {:.4f}'.format(k,score))\n",
    "    \n",
    "    models.append(model)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d329a-8a2a-4b11-a184-dd86a24de2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model_checkpoints/kfold_models.pkl', 'wb') as f:\n",
    "\tpickle.dump(models, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model_checkpoints/kfold_scores.pkl', 'wb') as f:\n",
    "\tpickle.dump(scores, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf035e4-706f-45ec-b78b-5e373729779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 1/np.array(scores)\n",
    "weights /= sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0969eeb9-a26a-4aac-8f8c-a2c6f5da4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X = train_df5.drop(target_feature,axis=1)\n",
    "y = train_df5[target_feature]\n",
    "dataset = Pool(X,y,cat_features=cat_features)\n",
    "\n",
    "prediction = np.zeros(len(X))\n",
    "for w,m in zip(weights,models):\n",
    "    prediction += m.predict(dataset) * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbfa422-8e3b-4112-9942-4d1205ad00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_pred=prediction,y_true=y.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8729a-e170-4ca4-8765-9495eaf2aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_test = test_df5\n",
    "dataset = Pool(X_test,cat_features=cat_features)\n",
    "\n",
    "prediction = np.zeros(len(X_test))\n",
    "for w,m in zip(weights,models):\n",
    "    prediction += m.predict(dataset) * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57bf89-d566-476b-ac08-c22068441b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec7ecd-be47-4b0e-aac8-03f689a439b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['가격'] = prediction\n",
    "submit.to_csv('./out/1_catboost_kfold.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7a7e9-1c4b-47c3-8959-0412cfc188f6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34001f77-6935-4c16-8d86-2ee1e7ab27ef",
   "metadata": {},
   "source": [
    "## Weighted Ensemble\n",
    "- public score : 6.5505142995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e51d603f-56f8-4006-a62b-386cc14d51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,columns):\n",
    "        self.transform_list = []\n",
    "        for col in columns:\n",
    "            for i,value in enumerate(sorted(data[col].unique())):\n",
    "                if i>0:\n",
    "                    self.transform_list.append([col,value])\n",
    "        \n",
    "    def transform(self,data):\n",
    "        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "        new_data = data.copy()\n",
    "        for col,value in self.transform_list:\n",
    "            new_data[f'{col}_{value}'] = np.where(new_data[col]==value,1,0)\n",
    "        drop_columns = pd.unique(np.array(self.transform_list)[:,0])\n",
    "        new_data.drop(columns=drop_columns,inplace=True)\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c20d5c0-a506-418d-838c-65c44c753dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "class WeightedEnsembleRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._get_regressors()\n",
    "    \n",
    "    def _get_regressors(self):\n",
    "        max_depth = 10\n",
    "        n_jobs = -1\n",
    "        \n",
    "        params_catboost = {\n",
    "            'random_state':CFG.SEED,\n",
    "            'early_stopping_rounds' : CFG.ES,\n",
    "            'learning_rate' : CFG.LR,\n",
    "            'iterations' : CFG.EPOCHS,\n",
    "            'loss_function': 'MAE',\n",
    "            'grow_policy' : 'Lossguide', # 'SymmetricTree','Depthwise'\n",
    "            'use_best_model' : True,\n",
    "            'allow_writing_files' : False,\n",
    "            'verbose' : 0,\n",
    "            'max_depth': max_depth,\n",
    "            'l2_leaf_reg' : 1,\n",
    "        }\n",
    "    \n",
    "        params_xgboost = {\n",
    "            'random_state':CFG.SEED,\n",
    "            'early_stopping_rounds' : CFG.XGB_ES,\n",
    "            'learning_rate' : CFG.XGB_LR,\n",
    "            'n_estimators' : CFG.XGB_EPOCHS,\n",
    "            'objective': 'reg:absoluteerror',\n",
    "            'verbosity' : 0,\n",
    "            'max_depth': max_depth,\n",
    "            'n_jobs' : n_jobs,\n",
    "        }\n",
    "    \n",
    "        params_lgb = {\n",
    "            'objective': 'regression',\n",
    "            'random_state':CFG.SEED,\n",
    "            'early_stopping_round' : CFG.ES,\n",
    "            'learning_rate' : CFG.LR,\n",
    "            'n_estimators' : CFG.EPOCHS,\n",
    "            'metric': 'mean_absolute_error',\n",
    "            'verbosity' : -1,\n",
    "            'max_depth': max_depth,\n",
    "            'n_jobs' : n_jobs,\n",
    "        }\n",
    "        \n",
    "        self.regressors = [\n",
    "            CatBoostRegressor(**params_catboost),\n",
    "            XGBRegressor(**params_xgboost),\n",
    "            LGBMRegressor(**params_lgb),\n",
    "        ]\n",
    "        self.regressors_name = ['CatBoost','XGBoost','LightGBM']\n",
    "    \n",
    "    def fit(self,X,y,eval_set,oh_set,cat_features,verbose=1):\n",
    "        assert len(eval_set)==1, \\\n",
    "            \"eval_set length must be 1. len(eval_set)={}\".format(len(eval_set))\n",
    "        assert len(oh_set)==1, \\\n",
    "            \"oh_set length must be 1. len(oh_set)={}\".format(len(oh_set))\n",
    "        X_val, y_val = eval_set[0]\n",
    "        X_oh, X_val_oh = oh_set[0]\n",
    "        \n",
    "        self.cat_features = cat_features\n",
    "        \n",
    "        if verbose:\n",
    "            print('> (2) Fitting Model')\n",
    "        self.weights = []\n",
    "        self.fitting_elapsed = []\n",
    "        if verbose:\n",
    "            pbar = tqdm(zip(self.regressors_name,self.regressors),total=len(self.regressors))\n",
    "        else:\n",
    "            pbar = zip(self.regressors_name,self.regressors)\n",
    "        for name,regressor in pbar:\n",
    "            s = time.time()\n",
    "            if verbose:\n",
    "                pbar.set_description(name)\n",
    "            if name=='CatBoost':\n",
    "                train_dataset = Pool(X,y,cat_features=cat_features)\n",
    "                val_dataset   = Pool(X_val,y_val,cat_features=self.cat_features)\n",
    "                regressor.fit(\n",
    "                    train_dataset,\n",
    "                    eval_set=val_dataset,\n",
    "                    #metric_period=CFG.EPOCHS//5,\n",
    "                )\n",
    "                val_pred = regressor.predict(val_dataset)\n",
    "            elif name=='XGBoost':\n",
    "                regressor.fit(\n",
    "                    X_oh,y,\n",
    "                    eval_set=[(X_val_oh,y_val)],\n",
    "                    verbose=0,\n",
    "                )\n",
    "                val_pred = regressor.predict(X_val_oh)\n",
    "            elif name=='LightGBM':\n",
    "                warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                regressor.fit(\n",
    "                    X_oh,y,\n",
    "                    eval_set=[(X_val_oh,y_val)],\n",
    "                    verbose=-1,\n",
    "                )\n",
    "                val_pred = regressor.predict(X_val_oh)\n",
    "            else:\n",
    "                raise ValueError('Unknown Regressor: {}'.format(name))\n",
    "                \n",
    "            score = mean_absolute_error(y_pred=val_pred,y_true=y_val)\n",
    "            e = time.time()\n",
    "            \n",
    "            self.weights.append(1/score)\n",
    "            self.fitting_elapsed.append(e-s)\n",
    "        \n",
    "        self.weights /= sum(self.weights)\n",
    "                \n",
    "    def predict(self,X,X_oh):\n",
    "        assert len(X)==len(X_oh), \\\n",
    "            \"X and X_oh must be same length\"\n",
    "        \n",
    "        pred_list = []\n",
    "        for name,regressor in zip(self.regressors_name,self.regressors):\n",
    "            if name=='CatBoost':\n",
    "                dataset = Pool(X,cat_features=self.cat_features)\n",
    "            else:\n",
    "                dataset = X_oh\n",
    "            \n",
    "            y_pred = regressor.predict(dataset)\n",
    "            y_pred = np.array(y_pred).flatten()\n",
    "            pred_list.append(y_pred)\n",
    "            \n",
    "        final_pred = np.zeros(len(X))\n",
    "        for pred,weight in zip(pred_list,self.weights):\n",
    "            final_pred += np.array(pred)*weight\n",
    "            \n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d7b987e-bd81-4f45-b72a-c866e3a105cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4304a568-d9e6-436b-8cdb-4aab93e0e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2653fa8a-01d9-49b0-803c-2d01b055aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> (2) Fitting Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:  33%|███▎      | 1/3 [06:15<12:30, 375.11s/it]\u001b[A\n",
      "XGBoost:  33%|███▎      | 1/3 [06:15<12:30, 375.11s/it] \u001b[A\n",
      "XGBoost:  67%|██████▋   | 2/3 [10:44<05:13, 313.13s/it]\u001b[A\n",
      "LightGBM:  67%|██████▋   | 2/3 [10:44<05:13, 313.13s/it]\u001b[A\n",
      "LightGBM: 100%|██████████| 3/3 [11:54<00:00, 238.30s/it]\u001b[A\n",
      " 20%|██        | 1/5 [12:00<48:03, 720.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold 1, MAE: 5.9480\n",
      "> (2) Fitting Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:  33%|███▎      | 1/3 [06:18<12:36, 378.10s/it]\u001b[A\n",
      "XGBoost:  33%|███▎      | 1/3 [06:18<12:36, 378.10s/it] \u001b[A\n",
      "XGBoost:  67%|██████▋   | 2/3 [10:46<05:13, 313.75s/it]\u001b[A\n",
      "LightGBM:  67%|██████▋   | 2/3 [10:46<05:13, 313.75s/it]\u001b[A\n",
      "LightGBM: 100%|██████████| 3/3 [12:12<00:00, 244.09s/it]\u001b[A\n",
      " 40%|████      | 2/5 [24:16<36:28, 729.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold 2, MAE: 5.9895\n",
      "> (2) Fitting Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:  33%|███▎      | 1/3 [06:20<12:41, 380.91s/it]\u001b[A\n",
      "XGBoost:  33%|███▎      | 1/3 [06:20<12:41, 380.91s/it] \u001b[A\n",
      "XGBoost:  67%|██████▋   | 2/3 [09:52<04:41, 281.28s/it]\u001b[A\n",
      "LightGBM:  67%|██████▋   | 2/3 [09:52<04:41, 281.28s/it]\u001b[A\n",
      "LightGBM: 100%|██████████| 3/3 [10:46<00:00, 215.38s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [35:05<23:05, 692.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold 3, MAE: 5.8836\n",
      "> (2) Fitting Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:  33%|███▎      | 1/3 [05:58<11:57, 358.73s/it]\u001b[A\n",
      "XGBoost:  33%|███▎      | 1/3 [05:58<11:57, 358.73s/it] \u001b[A\n",
      "XGBoost:  67%|██████▋   | 2/3 [09:30<04:32, 272.45s/it]\u001b[A\n",
      "LightGBM:  67%|██████▋   | 2/3 [09:30<04:32, 272.45s/it]\u001b[A\n",
      "LightGBM: 100%|██████████| 3/3 [10:31<00:00, 210.46s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [45:40<11:09, 669.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold 4, MAE: 5.9810\n",
      "> (2) Fitting Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "CatBoost:  33%|███▎      | 1/3 [06:01<12:02, 361.31s/it]\u001b[A\n",
      "XGBoost:  33%|███▎      | 1/3 [06:01<12:02, 361.31s/it] \u001b[A\n",
      "XGBoost:  67%|██████▋   | 2/3 [10:01<04:50, 290.26s/it]\u001b[A\n",
      "LightGBM:  67%|██████▋   | 2/3 [10:01<04:50, 290.26s/it]\u001b[A\n",
      "LightGBM: 100%|██████████| 3/3 [11:06<00:00, 222.09s/it]\u001b[A\n",
      "100%|██████████| 5/5 [56:49<00:00, 682.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold 5, MAE: 6.0434\n",
      "CPU times: user 4h 23min 16s, sys: 26min 24s, total: 4h 49min 40s\n",
      "Wall time: 57min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k=5 : iteration 당 12분\n",
    "\n",
    "X = train_df5.drop(target_feature,axis=1)\n",
    "y = train_df5[target_feature]\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X,cat_features)\n",
    "X_oh = ohe.transform(X)\n",
    "\n",
    "kf = KFold(n_splits=CFG.N_SPLITS,random_state=CFG.SEED,shuffle=True)\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "k=0\n",
    "for tr_idx, val_idx in tqdm(kf.split(X,y),total=CFG.N_SPLITS):\n",
    "    k+=1\n",
    "    X_train, y_train = X.iloc[tr_idx] , y.iloc[tr_idx]\n",
    "    X_val  , y_val   = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    X_train_oh = X_oh.iloc[tr_idx]\n",
    "    X_val_oh   = X_oh.iloc[val_idx]\n",
    "\n",
    "    ensemble_model = WeightedEnsembleRegressor()\n",
    "    ensemble_model.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_val,y_val)],\n",
    "        oh_set=[(X_train_oh,X_val_oh)],\n",
    "        cat_features=cat_features,\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    y_pred = ensemble_model.predict(X_val,X_val_oh).flatten()\n",
    "    y_true = y_val.values\n",
    "    score = mean_absolute_error(y_true=y_true,y_pred=y_pred)\n",
    "    print('K-Fold {}, MAE: {:.4f}'.format(k,score))\n",
    "    \n",
    "    models.append(ensemble_model)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cc03e7c-861e-4096-8a06-c663efed603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 1/np.array(scores)\n",
    "weights /= sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98903bdc-0a12-49d0-ac1b-bdada21c97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X = train_df5.drop(target_feature,axis=1)\n",
    "y = train_df5[target_feature]\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X,cat_features)\n",
    "X_oh = ohe.transform(X)\n",
    "\n",
    "prediction = np.zeros(len(X))\n",
    "for w,m in zip(weights,models):\n",
    "    prediction += m.predict(X,X_oh) * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6f5657b-53c9-460b-b308-3aa5007d424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.128814618764771"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred=prediction,y_true=y.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e8f2c90-e430-4590-a567-ac22d62937ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_test = test_df5\n",
    "X_test_oh = ohe.transform(X_test)\n",
    "\n",
    "prediction = np.zeros(len(X_test))\n",
    "for w,m in zip(weights,models):\n",
    "    prediction += m.predict(X_test,X_test_oh) * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06d2c7bd-e9f4-4fad-8836-f473a09004a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.39274694, 26.53542805, 82.84549379, ..., 95.80957018,\n",
       "       49.68591462, 43.09463356])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6bf333c-066a-4c39-81f2-8a20a8839e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit['가격'] = prediction\n",
    "submit.to_csv('./out/2_ensemble_kfold.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92abc4-eb0a-4d71-861f-200a40356c20",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6f0e6-6fa4-458d-838e-32a5db3df13d",
   "metadata": {},
   "source": [
    "## 참조 pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e7ce5-6c68-4d17-b54b-c33c821ced59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da0375-b3dc-45d9-af61-33e733136308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# regression.setup(data=train_df5,target='가격',remove_outliers=True,verbose=True)\n",
    "# best = regression.compare_models(n_select=5,fold=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
