{"cells":[{"cell_type":"markdown","id":"6d9f576b-4071-4648-8a4e-23dbf55f15fc","metadata":{"id":"6d9f576b-4071-4648-8a4e-23dbf55f15fc"},"source":["# Setting"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","REF_PATH = '/content/drive/MyDrive/Github/10_도배하자유형분류'\n","os.chdir(REF_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Az094lVqe0CX","executionInfo":{"status":"ok","timestamp":1683021815330,"user_tz":-540,"elapsed":21554,"user":{"displayName":"김혁진","userId":"00473223970764510069"}},"outputId":"2bcaf39c-fc26-4abe-ddaa-807a1bc30095"},"id":"Az094lVqe0CX","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","id":"a2bcba5f-002e-4f49-9622-ada6117faf0a","metadata":{"id":"a2bcba5f-002e-4f49-9622-ada6117faf0a"},"source":["<br>\n","\n","## Import"]},{"cell_type":"code","execution_count":2,"id":"5994fbc9-c221-42bd-b1e4-1ffae6170222","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5994fbc9-c221-42bd-b1e4-1ffae6170222","executionInfo":{"status":"ok","timestamp":1683021815331,"user_tz":-540,"elapsed":3,"user":{"displayName":"김혁진","userId":"00473223970764510069"}},"outputId":"8ae4becf-d314-4b1f-ab6e-31e85b7b1da1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["25"]},"metadata":{},"execution_count":2}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":3,"id":"2b0d9b68-7102-4eca-9543-3b9b8acafc6e","metadata":{"id":"2b0d9b68-7102-4eca-9543-3b9b8acafc6e","executionInfo":{"status":"ok","timestamp":1683021824886,"user_tz":-540,"elapsed":9557,"user":{"displayName":"김혁진","userId":"00473223970764510069"}}},"outputs":[],"source":["import os,sys\n","import random\n","import joblib\n","import pandas as pd\n","import numpy as np\n","import glob\n","import cv2\n","import itertools\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","# import torchvision.models as models\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm, trange\n","\n","import warnings\n","warnings.filterwarnings(action='ignore') \n","\n","from PIL import Image"]},{"cell_type":"markdown","id":"fc7df3f2-62d0-4499-a46e-47d01699def0","metadata":{"id":"fc7df3f2-62d0-4499-a46e-47d01699def0"},"source":["<br>\n","\n","## Hyperparameter Setting"]},{"cell_type":"code","execution_count":4,"id":"d13862e3-bb27-47af-9b58-a9fbf804df71","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683021824886,"user":{"displayName":"김혁진","userId":"00473223970764510069"},"user_tz":-540},"id":"d13862e3-bb27-47af-9b58-a9fbf804df71","outputId":"54db0d5d-cb6e-4ea0-e3bb-c4a540f1c562"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["MC_PATH = './mc/gan'\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)"]},{"cell_type":"code","execution_count":5,"id":"460f9d43-b441-44a6-8ab4-cde01e3c67f8","metadata":{"id":"460f9d43-b441-44a6-8ab4-cde01e3c67f8","executionInfo":{"status":"ok","timestamp":1683021824886,"user_tz":-540,"elapsed":4,"user":{"displayName":"김혁진","userId":"00473223970764510069"}}},"outputs":[],"source":["CFG = {\n","    'IMG_SIZE':224, #224,320,384\n","    'EPOCHS':128,\n","    'LEARNING_RATE':3e-4,\n","    'BATCH_SIZE':16,\n","    'SEED':41,\n","}"]},{"cell_type":"markdown","id":"4254e860-ff82-43ba-bfa3-fcee4eb3ddbd","metadata":{"id":"4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"},"source":["<br>\n","\n","## Fixed RandomSeed"]},{"cell_type":"code","execution_count":6,"id":"101a714b-71b6-4475-a4ce-fa5f98bc2731","metadata":{"id":"101a714b-71b6-4475-a4ce-fa5f98bc2731","executionInfo":{"status":"ok","timestamp":1683021824887,"user_tz":-540,"elapsed":4,"user":{"displayName":"김혁진","userId":"00473223970764510069"}}},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(CFG['SEED']) # Seed 고정"]},{"cell_type":"markdown","id":"26cb6963-c1d5-4bf8-bd37-3e9b7cbae18d","metadata":{"id":"26cb6963-c1d5-4bf8-bd37-3e9b7cbae18d"},"source":["<br></br>\n","\n","# Data Load"]},{"cell_type":"markdown","id":"05a4172e-5791-446f-9616-35c09d8bf25a","metadata":{"id":"05a4172e-5791-446f-9616-35c09d8bf25a"},"source":["<br>\n","\n","## Data Pre-processing"]},{"cell_type":"code","execution_count":7,"id":"a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d","metadata":{"id":"a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d","executionInfo":{"status":"ok","timestamp":1683021837381,"user_tz":-540,"elapsed":12498,"user":{"displayName":"김혁진","userId":"00473223970764510069"}}},"outputs":[],"source":["all_img_list = glob.glob('./data/train/*/*')"]},{"cell_type":"code","execution_count":8,"id":"4119733d-adef-436c-afca-4112a9225d33","metadata":{"id":"4119733d-adef-436c-afca-4112a9225d33","executionInfo":{"status":"ok","timestamp":1683021837381,"user_tz":-540,"elapsed":17,"user":{"displayName":"김혁진","userId":"00473223970764510069"}}},"outputs":[],"source":["df = pd.DataFrame(columns=['img_path', 'label'])\n","df['img_path'] = all_img_list\n","df['label'] = df['img_path'].apply(lambda x : x.split('/')[-2].replace('.png',''))"]},{"cell_type":"code","execution_count":null,"id":"4db41c93-3515-4fcd-936b-0a01f5388b3f","metadata":{"id":"4db41c93-3515-4fcd-936b-0a01f5388b3f"},"outputs":[],"source":["train_data, val_data, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"]},{"cell_type":"markdown","id":"bb1f117e-105d-4e9e-b9bd-938d4271a940","metadata":{"id":"bb1f117e-105d-4e9e-b9bd-938d4271a940"},"source":["<br>\n","\n","## Label-Encoding"]},{"cell_type":"code","execution_count":null,"id":"6c8c5916-8065-4b5c-aa37-f3fb2b9fa422","metadata":{"id":"6c8c5916-8065-4b5c-aa37-f3fb2b9fa422"},"outputs":[],"source":["le = preprocessing.LabelEncoder()\n","train_data['label'] = le.fit_transform(train_data['label'])\n","val_data  ['label'] = le.transform(val_data['label'])"]},{"cell_type":"code","execution_count":null,"id":"f41bbf52-8b7c-4ca0-9868-837f6dc0bfdb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f41bbf52-8b7c-4ca0-9868-837f6dc0bfdb","executionInfo":{"status":"ok","timestamp":1682441479406,"user_tz":-540,"elapsed":4,"user":{"displayName":"김혁진","userId":"00473223970764510069"}},"outputId":"17c894e7-0085-4c13-fd5a-2bafb6bdaceb"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 가구수정\n","1 걸레받이수정\n","2 곰팡이\n","3 꼬임\n","4 녹오염\n","5 들뜸\n","6 면불량\n","7 몰딩수정\n","8 반점\n","9 석고수정\n","10 오염\n","11 오타공\n","12 울음\n","13 이음부불량\n","14 창틀,문틀수정\n","15 터짐\n","16 틈새과다\n","17 피스\n","18 훼손\n"]}],"source":["for i,label in enumerate(le.classes_):\n","    print(i,label)"]},{"cell_type":"code","execution_count":null,"id":"4b04d78a-4d17-409c-b80d-e208dd60a382","metadata":{"id":"4b04d78a-4d17-409c-b80d-e208dd60a382"},"outputs":[],"source":["# 한글을 le.inverse_transform() 할 경우에 안맞는 현상생김\n","# -> 손코딩 필요\n","def label_decoder(label):\n","    new_label =[\n","        '가구수정' if l==0 else\n","        '걸레받이수정' if l==1 else\n","        '곰팡이' if l==2 else\n","        '꼬임' if l==3 else\n","        '녹오염' if l==4 else\n","        '들뜸' if l==5 else\n","        '면불량' if l==6 else\n","        '몰딩수정' if l==7 else\n","        '반점' if l==8 else\n","        '석고수정' if l==9 else\n","        '오염' if l==10 else\n","        '오타공' if l==11 else\n","        '울음' if l==12 else\n","        '이음부불량' if l==13 else\n","        '창틀,문틀수정' if l==14 else\n","        '터짐' if l==15 else\n","        '틈새과다' if l==16 else\n","        '피스' if l==17 else\n","        '훼손' if l==18 else\n","        'NaN' for l in label\n","    ]\n","    return np.array(new_label)"]},{"cell_type":"markdown","id":"56aa2a84-272a-42b7-afc7-de73260e0e7e","metadata":{"id":"56aa2a84-272a-42b7-afc7-de73260e0e7e"},"source":["<br></br>"]},{"cell_type":"markdown","id":"b9d76df7-cf42-42bc-a6e4-46356309d098","metadata":{"id":"b9d76df7-cf42-42bc-a6e4-46356309d098"},"source":["# Image Generate by GAN"]},{"cell_type":"markdown","id":"90e6faeb-a402-4b59-add3-cae60507ab17","metadata":{"id":"90e6faeb-a402-4b59-add3-cae60507ab17"},"source":["## Pre-trained Model"]},{"cell_type":"code","execution_count":null,"id":"a2cac68b-d8eb-4b28-bb5e-127ecf2e8a27","metadata":{"id":"a2cac68b-d8eb-4b28-bb5e-127ecf2e8a27"},"outputs":[],"source":["# import torch\n","# torch.hub.list('NVIDIA/DeepLearningExamples:torchhub')\n","# torch.hub.list('facebookresearch/pytorch_GAN_zoo')"]},{"cell_type":"code","execution_count":null,"id":"3d9cfd45-4179-4f03-845c-a68960790e37","metadata":{"id":"3d9cfd45-4179-4f03-845c-a68960790e37"},"outputs":[],"source":["# import torch\n","# model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'StyleGAN', pretrained=True)\n","# model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True)"]},{"cell_type":"markdown","id":"10d860fc-4d12-4a92-96b4-0180cd28bb82","metadata":{"id":"10d860fc-4d12-4a92-96b4-0180cd28bb82"},"source":["<br>\n","\n","## Make Model - Kaggle\n","- 참조 : [Kaggle](https://www.kaggle.com/code/jesucristo/gan-introduction)"]},{"cell_type":"code","execution_count":null,"id":"fd459a9e-949d-4bba-9ba3-53893694ad79","metadata":{"id":"fd459a9e-949d-4bba-9ba3-53893694ad79"},"outputs":[],"source":["from torch.autograd import Variable\n","import torchvision.utils as vutils"]},{"cell_type":"code","source":["def conv_output_size(input_size, kernel_size, stride, padding):\n","    # 입력 이미지에 대한 Tensor 객체 생성\n","    input_tensor = torch.rand(1, 1, input_size, input_size)\n","\n","    # conv2d 연산 수행하여 출력 크기 계산\n","    conv = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=padding)\n","    output_tensor = conv(input_tensor)\n","    _, _, output_size, _ = output_tensor.shape\n","\n","    # 출력 크기 반환\n","    return output_size"],"metadata":{"id":"5aK9TfxvbRMD"},"id":"5aK9TfxvbRMD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["## generator\n","# conv_output_size(64,4,1,0)\n","# conv_output_size(61,4,2,1)\n","# conv_output_size(30,4,2,1)\n","# conv_output_size(15,4,2,1)\n","# conv_output_size(7,4,2,1)\n","\n","## discriminator\n","# conv_output_size(64,4,2,1)\n","# conv_output_size(32,4,2,1)\n","# conv_output_size(16,4,2,1)\n","# conv_output_size(8,4,2,1)\n","# conv_output_size(4,4,2,0)"],"metadata":{"id":"Uj21_p1Lci0C"},"id":"Uj21_p1Lci0C","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining the generator\n","class G(nn.Module):\n","    def __init__(self):\n","        # Used to inherit the torch.nn Module\n","        super(G, self).__init__()\n","        # Meta Module - consists of different layers of Modules\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(100, 512, 4, stride=1, padding=0, bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1, bias=False),\n","            nn.Tanh()\n","        )\n","        \n","    def forward(self, input):\n","        output = self.main(input)\n","        return output\n","\n","# Defining the discriminator\n","class D(nn.Module):\n","    def __init__(self):\n","        super(D, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=False),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","            nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","            nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","            nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","            nn.Conv2d(512, 1, 4, stride=1, padding=0, bias=False),\n","            nn.Sigmoid()\n","        )\n","        \n","    def forward(self, input):\n","        output = self.main(input)\n","        # .view(-1) = Flattens the output into 1D instead of 2D\n","        return output.view(-1)\n","\n","def weights_init(m):\n","    \"\"\"\n","    Takes as input a neural network m that will initialize all its weights.\n","    \"\"\"\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)"],"metadata":{"id":"S2TccyGXhUNL"},"id":"S2TccyGXhUNL","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"eabcd3b7-8b92-4cf0-b3d8-914f7557249a","metadata":{"id":"eabcd3b7-8b92-4cf0-b3d8-914f7557249a"},"outputs":[],"source":["# brainAI 이희원님 공유내용\n","# (참조) https://dacon.io/competitions/official/236082/codeshare/7891?page=1&dtype=recent\n","class GANDataset(Dataset):\n","    def __init__(self, img_path_list):\n","        self.img_path_list = img_path_list\n","        self.transforms = A.Compose([\n","            A.Resize(64,64),\n","            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), p=1),\n","            ToTensorV2(),\n","        ])\n","        \n","        self.features = []\n","        for img_path in tqdm(self.img_path_list,desc='Load Dataset'):\n","            # (1) raw image\n","            image = cv2.imread(img_path)\n","            image = self.transforms(image=image)['image']\n","            self.features.append(image)\n","\n","    def __getitem__(self, index):\n","        return self.features[index]\n","        \n","    def __len__(self):\n","        return len(self.features)"]},{"cell_type":"code","source":["import time\n","\n","class ImageGenerator:\n","    def __init__(self):\n","        self.generator = G().apply(weights_init)\n","        self.discriminator = D().apply(weights_init)\n","\n","    def get_generator(self):\n","        return self.generator\n","\n","    def get_discriminator(self):\n","        return self.discriminator\n","\n","    def train(\n","        self,\n","        epochs,dataloader,lr,device,metric_period,save_period,\n","        generator_save_path,image_save_path,\n","    ):\n","        self.generator = self.generator.to(device)\n","        self.discriminator = self.discriminator.to(device)\n","\n","        criterion = nn.BCELoss().to(device)\n","        optimizerG = optim.Adam(self.generator.parameters()    , lr=lr, betas=(0.5, 0.999), weight_decay=5e-4)\n","        optimizerD = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=5e-4)\n","        \n","        period_start_time = time.time()\n","        \n","        for epoch in range(epochs):\n","            for i, real in enumerate(dataloader, 0):\n","                # 1st Step: Updating the weights of the neural network of the discriminator\n","                self.discriminator.zero_grad()\n","\n","                # Training the discriminator with a real image of the dataset\n","                input = Variable(real).float()\n","                target = Variable(torch.ones(input.size()[0])).to(device)\n","                output = self.discriminator(input.to(device))\n","                errD_real = criterion(output, target)\n","\n","                # Training the discriminator with a fake image generated by the generator\n","                noise = Variable(torch.randn(input.size()[0], 100, 1, 1)).to(device)\n","                fake = self.generator(noise.to(device))\n","                target = Variable(torch.zeros(input.size()[0])).to(device)\n","                output = self.discriminator(fake.detach())\n","                errD_fake = criterion(output, target).to(device)\n","\n","                # Backpropagating the total error\n","                errD = errD_real + errD_fake\n","                errD.backward()\n","                optimizerD.step()\n","\n","                # 2nd Step: Updating the weights of the neural network of the generator\n","                self.generator.zero_grad()\n","                target = Variable(torch.ones(input.size()[0])).to(device)\n","                output = self.discriminator(fake.to(device))\n","                errG = criterion(output, target)\n","                errG.backward()\n","                optimizerG.step()\n","\n","                # # 3rd Step: Printing the losses and saving the real images and the generated images of the minibatch every 100 steps\n","                # epoch_str = str(epoch+1).zfill(len(str(epochs)))\n","                # i_str = str(i+1).zfill(len(str(len(dataloader))))\n","                # print('Epochs[{}/{}] Batch[{}/{}] Loss_D: {:.4f}; Loss_G: {:.4f}'.format(epoch_str, epochs, i_str, len(dataloader), errD.item(), errG.item()))\n","                # if (i+1)==len(dataloader):\n","                #     vutils.save_image(real, './out/gan_images/real_samples.png', normalize=True)\n","                #     fake = netG(noise)\n","                #     vutils.save_image(fake.data, './out/gan_images/fake_samples_epoch_{}.png'.format(epoch_str), normalize=True)\n","\n","            if (epoch+1) % metric_period == 0:\n","                period_end_time = time.time()\n","                elapsed = period_end_time - period_start_time\n","                remaining = (epochs-epoch)/metric_period*elapsed\n","                \n","                # 3rd Step: Printing the losses and saving the real images and the generated images of the minibatch every 100 steps\n","                epoch_str = str(epoch+1).zfill(len(str(epochs)))\n","                progress = 'Epoch[{}/{}] Loss_D: {:.4f}, Loss_G: {:.4f}, elapsed: {:.1f}, remaining: {:.1f}'\\\n","                    .format(epoch_str, epochs, errD.item(), errG.item(), elapsed, remaining)\n","                print(progress)\n","                period_start_time = time.time()\n","\n","            if (epoch+1) % save_period == 0:\n","                vutils.save_image(real, image_save_path + 'real_samples_epoch_{}.png'.format(epoch_str), normalize=True)\n","                fake = self.generator(noise)\n","                vutils.save_image(fake.data, image_save_path + 'fake_samples_epoch_{}.png'.format(epoch_str), normalize=True)\n","          \n","        # 최종모델 저장\n","        torch.save(self.generator    .state_dict(), generator_save_path)\n","\n","    def generate(self,n_generate,save_path):\n","        for i in trange(n_generate):\n","            i_str = str(i).zfill(len(str(n_generate)))\n","            noise = torch.randn(1, 100, 1, 1).to(device)\n","            fake = self.generator(noise)\n","            vutils.save_image(fake, save_path + 'fake_samples_{}.png'.format(i_str), normalize=True)"],"metadata":{"id":"GODcQpBEg8is"},"id":"GODcQpBEg8is","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mkdir(path):\n","    import os\n","    if not os.path.exists(path):\n","        print(\"folder created: {}\".format(path))\n","        os.mkdir(path)"],"metadata":{"id":"a5dH3f0AJTSa"},"id":"a5dH3f0AJTSa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.label.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgC4ABM9Q6uT","executionInfo":{"status":"ok","timestamp":1682441487053,"user_tz":-540,"elapsed":4,"user":{"displayName":"김혁진","userId":"00473223970764510069"}},"outputId":"86608651-92ad-460d-bbdd-67cc71f502bb"},"id":"bgC4ABM9Q6uT","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18    983\n","10    416\n","1     215\n","3     147\n","15    113\n","2     102\n","11     99\n","7      91\n","6      69\n","9      40\n","5      38\n","17     36\n","14     19\n","12     15\n","13     12\n","4      10\n","0       8\n","16      4\n","8       2\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# # 기존파일 삭제\n","# import shutil\n","# shutil.rmtree(f'./out/gan_images')\n","# shutil.rmtree(f'./mc/gan')"],"metadata":{"id":"2mcX8PbIYSEI"},"id":"2mcX8PbIYSEI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 이미지 저장을 위한 디렉토리 생성\n","mkdir(f'./out')\n","mkdir(f'./out/gan_images')\n","mkdir(f'./out/gan_images/train')\n","mkdir(f'./out/gan_images/generate')\n","\n","# 결과파일 저장을 위한 디렉토리 생성\n","mkdir(f'./mc/gan')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiblYoqtJV8U","executionInfo":{"status":"ok","timestamp":1682349277859,"user_tz":-540,"elapsed":10,"user":{"displayName":"김혁진","userId":"00473223970764510069"}},"outputId":"c9cc8ed9-b45b-43c5-a674-43f8533354b1"},"id":"LiblYoqtJV8U","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["folder created: ./out/gan_images\n","folder created: ./out/gan_images/train\n","folder created: ./out/gan_images/generate\n","folder created: ./mc/gan\n"]}]},{"cell_type":"code","source":["def main_iteration(label,epochs,metric_peroid,save_period):\n","    gc.collect()\n","\n","    generator_save_path     = MC_PATH + f'/generator_{label}.pt'\n","    image_save_path         = f'./out/gan_images/train/{label}/'\n","    gen_image_save_path     = f'./out/gan_images/generate/{label}/'\n","    mkdir(image_save_path)\n","    mkdir(gen_image_save_path)\n","\n","    sub_data = train_data[train_data.label==label]\n","    # Image.open(sub_data.img_path.values[0])\n","    train_dataset = GANDataset(img_path_list=sub_data.img_path.values)\n","    train_loader  = DataLoader(train_dataset, batch_size=32, num_workers=0, shuffle=True)\n","\n","    # GAN의 목적은 Discriminator loss를 높이는 것과 Generator loss를 낮추는 것\n","    image_gen = ImageGenerator()\n","\n","    # GAN 모델 학습\n","    image_gen.train(\n","        epochs=epochs,\n","        dataloader=train_loader,\n","        lr=5e-4,\n","        device=device,\n","        metric_period=metric_peroid,\n","        save_period=save_period,\n","        generator_save_path=generator_save_path,\n","        image_save_path=image_save_path,\n","    )\n","\n","    # GAN 모델을 통해서 이미지생성\n","    image_gen.generate(\n","        n_generate=100,\n","        save_path=gen_image_save_path,\n","    )\n","\n","    return image_gen"],"metadata":{"id":"6YLdfT_ZXeoQ"},"id":"6YLdfT_ZXeoQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label = 2\n","# image_gen = main_iteration(label=label,epochs=100,metric_peroid=500,save_period=1000)"],"metadata":{"id":"jiMZcW9rxU8E"},"id":"jiMZcW9rxU8E","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --------------------------------------------------------------------------------\n","# > (18/19) 17\n","# --------------------------------------------------------------------------------\n","#!!!! 17,18해야하는데 왜 18/19인지?"],"metadata":{"id":"l4FfPQ8-kXwX"},"id":"l4FfPQ8-kXwX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["vc = train_data.label.value_counts()\n","label_list = vc[vc<vc.max()].index.tolist()\n","label_list = sorted(label_list)\n","\n","# for iter,label in enumerate(label_list):\n","for iter,label in enumerate([17]):\n","    print()\n","    print('-'*80)\n","    print('> ({}/{}) {}'.format(iter+1,len(label_list),label))\n","    print('-'*80)\n","    main_iteration(label=label,epochs=5000,metric_peroid=500,save_period=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HTrHV2NmIwlJ","outputId":"4519d2fb-eee5-48df-ba97-cf6ee4233ef0","executionInfo":{"status":"ok","timestamp":1682442188723,"user_tz":-540,"elapsed":317483,"user":{"displayName":"김혁진","userId":"00473223970764510069"}}},"id":"HTrHV2NmIwlJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--------------------------------------------------------------------------------\n","> (1/18) 17\n","--------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Load Dataset: 100%|██████████| 36/36 [00:28<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch[0500/5000] Loss_D: 0.0516, Loss_G: 8.0418, elapsed: 32.8, remaining: 295.6\n","Epoch[1000/5000] Loss_D: 2.3743, Loss_G: 5.9121, elapsed: 26.3, remaining: 210.4\n","Epoch[1500/5000] Loss_D: 0.0145, Loss_G: 26.9942, elapsed: 28.2, remaining: 197.6\n","Epoch[2000/5000] Loss_D: 0.0238, Loss_G: 10.2667, elapsed: 27.7, remaining: 166.1\n","Epoch[2500/5000] Loss_D: 0.0017, Loss_G: 18.1709, elapsed: 28.5, remaining: 142.8\n","Epoch[3000/5000] Loss_D: 0.0106, Loss_G: 5.6145, elapsed: 27.4, remaining: 109.6\n","Epoch[3500/5000] Loss_D: 0.0142, Loss_G: 7.2781, elapsed: 28.5, remaining: 85.5\n","Epoch[4000/5000] Loss_D: 0.0217, Loss_G: 6.7062, elapsed: 28.1, remaining: 56.2\n","Epoch[4500/5000] Loss_D: 0.0475, Loss_G: 16.1553, elapsed: 27.4, remaining: 27.5\n","Epoch[5000/5000] Loss_D: 0.1012, Loss_G: 8.2037, elapsed: 28.1, remaining: 0.1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:01<00:00, 93.10it/s]\n"]}]},{"cell_type":"code","execution_count":null,"id":"ec8c30d0-d44d-4f24-b9f2-972fe3cbce58","metadata":{"id":"ec8c30d0-d44d-4f24-b9f2-972fe3cbce58","executionInfo":{"status":"ok","timestamp":1682442975496,"user_tz":-540,"elapsed":1874,"user":{"displayName":"김혁진","userId":"00473223970764510069"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7f22b5c-ee40-4cb4-d5c4-ce1d594861c8"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:00<00:00, 14.60it/s]\n"]}],"source":["label = 2\n","# mkdir(f'./out/gan_images/generate/{label}')\n","\n","final_generator = G().apply(weights_init)\n","final_generator.load_state_dict(torch.load(MC_PATH + f'/generator_{label}.pt'))\n","final_generator = final_generator.to(device)\n","\n","n_generate = 5\n","for i in trange(n_generate):\n","    i_str = str(i).zfill(len(str(n_generate)))\n","    noise = torch.randn(16, 100, 1, 1).to(device)\n","    fake = final_generator(noise)\n","    #vutils.save_image(fake, './out/gan_images/generate/{}/fake_samples_{}.png'.format(label,i_str), normalize=True)\n","    vutils.save_image(fake, './temp/fake_samples_{}.png'.format(i_str), normalize=True)"]},{"cell_type":"code","source":["import glob\n","from PIL import Image\n","\n","img_paths = glob.glob(f'./out/gan_images/generate/{label}/*')\n","img = Image.open(img_paths[1])\n","img\n","\n","# img.resize((224,224))\n","# np.array(img).shape"],"metadata":{"id":"t6Fsmr5jvptO"},"id":"t6Fsmr5jvptO","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b8mV4Ht0z0ls"},"id":"b8mV4Ht0z0ls","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"toc-autonumbering":true},"nbformat":4,"nbformat_minor":5}