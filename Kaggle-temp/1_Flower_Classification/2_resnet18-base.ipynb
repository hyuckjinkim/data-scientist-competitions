{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16 16\n"
     ]
    }
   ],
   "source": [
    "train_imgs = os.listdir(\"./data/tfrecords-jpeg-192x192/train\")\n",
    "test_imgs = os.listdir(\"./data/tfrecords-jpeg-192x192/test\")\n",
    "val_imgs = os.listdir(\"./data/tfrecords-jpeg-192x192/val\")\n",
    "print(len(train_imgs),len(test_imgs),len(val_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from torchvision import transforms , models\n",
    "from torch.optim import SGD\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_description = {\n",
    "    'class': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "test_feature_description = {\n",
    "    'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_image_function(example_proto):\n",
    " return tf.io.parse_single_example(example_proto, train_feature_description)\n",
    "def second_parse_image_function(example_proto):\n",
    " return tf.io.parse_single_example(example_proto, test_feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lis = []\n",
    "val_lis = []\n",
    "test_lis = []\n",
    "\n",
    "for i in train_imgs:\n",
    "  train_lis.append(tf.data.TFRecordDataset(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/train/\"+i))\n",
    "\n",
    "for i in val_imgs:\n",
    "  val_lis.append(tf.data.TFRecordDataset(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/val/\"+i))\n",
    "\n",
    "for i in test_imgs:\n",
    "  test_lis.append(tf.data.TFRecordDataset(\"/kaggle/input/tpu-getting-started/tfrecords-jpeg-192x192/test/\"+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "train_classes = []\n",
    "train_images = []\n",
    "\n",
    "val_ids = []\n",
    "val_classes = []\n",
    "val_images = []\n",
    "\n",
    "test_ids = []\n",
    "test_images = []\n",
    "\n",
    "for tl in train_lis:\n",
    "  temp = tl.map(_parse_image_function)\n",
    "  for t in temp:\n",
    "    train_classes.append(t[\"class\"].numpy())\n",
    "    train_ids.append(str(t[\"id\"].numpy())[2:-1])\n",
    "    train_images.append(t[\"image\"].numpy())\n",
    "    \n",
    "for tl in val_lis:\n",
    "  temp = tl.map(_parse_image_function)\n",
    "  for t in temp:\n",
    "    val_classes.append(t[\"class\"].numpy())\n",
    "    val_ids.append(str(t[\"id\"].numpy())[2:-1])\n",
    "    val_images.append(t[\"image\"].numpy())\n",
    "\n",
    "for tl in test_lis:\n",
    "  temp = tl.map(second_parse_image_function)\n",
    "  for t in temp:\n",
    "    test_ids.append(str(t[\"id\"].numpy())[2:-1])\n",
    "    test_images.append(t[\"image\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustDat(Dataset):\n",
    "    def __init__(self , images , classes , ids , transform , mode):\n",
    "        self.images = images\n",
    "        self.classes = classes\n",
    "        self.ids = ids\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self , idx):\n",
    "        img = Image.open(io.BytesIO(self.images[idx]))\n",
    "        img = self.transform(img)\n",
    "        if self.mode == \"test\":\n",
    "            idd = self.ids[idx]\n",
    "            return (img , idd)\n",
    "        else:\n",
    "            label = self.classes[idx]\n",
    "            return (img , label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((120 , 120)) , \n",
    "    transforms.ToTensor() , \n",
    "    transforms.Normalize((0 , 0 , 0) , (1 , 1 , 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cust = CustDat(train_images , train_classes , None , transform , \"train\")\n",
    "val_cust = CustDat(val_images , val_classes , None , transform , \"val\")\n",
    "test_cust = CustDat(test_images , None , test_ids , transform , \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self,\n",
    "                 image_size: int,\n",
    "                 in_channels: int,\n",
    "                 num_classes: int,\n",
    "                 base_width=8,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.embed = nn.Conv2d(in_channels=in_channels, out_channels=base_width * 1, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(base_width * 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.block1 = BasicBlock(in_channels=base_width * 1, out_channels=base_width * 1)\n",
    "        self.block2 = BasicBlock(in_channels=base_width * 1, out_channels=base_width * 2)\n",
    "        self.block3 = BasicBlock(in_channels=base_width * 2, out_channels=base_width * 4)\n",
    "        self.block4 = BasicBlock(in_channels=base_width * 4, out_channels=base_width * 8)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(base_width * 8, num_classes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.embed(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_fr = temp_model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model.fc = nn.Linear(tot_fr , len(train_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = ResNet18(192, 3, len(train_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
    "WRAPPED_MODEL = xmp.MpModelWrapper(temp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank):\n",
    "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "      train_cust , \n",
    "      num_replicas = 8 , \n",
    "      rank = xm.get_ordinal() , \n",
    "      shuffle = True , \n",
    "      seed = 0\n",
    "  )\n",
    "  val_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "      val_cust , \n",
    "      num_replicas = 8 , \n",
    "      rank = xm.get_ordinal() , \n",
    "      shuffle = True , \n",
    "      seed = 0\n",
    "  )\n",
    "  train_loader = DataLoader(\n",
    "      train_cust , \n",
    "      batch_size = 16 , \n",
    "      sampler = train_sampler , \n",
    "      num_workers = 1 , \n",
    "      drop_last = False\n",
    "  )\n",
    "  val_loader = DataLoader(\n",
    "      val_cust , \n",
    "      batch_size = 16 , \n",
    "      sampler = val_sampler , \n",
    "      num_workers = 1 , \n",
    "      drop_last = False\n",
    "  )\n",
    "  test_loader = DataLoader(\n",
    "      test_cust , \n",
    "      batch_size = 16 ,\n",
    "      num_workers = 1 , \n",
    "      drop_last = False\n",
    "  )\n",
    "  device = xm.xla_device()\n",
    "  model = WRAPPED_MODEL.to(device)\n",
    "  lr = 0.01 * xm.xrt_world_size()\n",
    "  optimizer = SGD(model.parameters() , lr = lr)\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  num_epochs = 10\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    #training\n",
    "    para_loader = pl.ParallelLoader(train_loader , [device])\n",
    "    train_loss = []\n",
    "    train_corr = 0\n",
    "    train_sam = 0\n",
    "    model.train()\n",
    "    for x , (data , label) in enumerate(para_loader.per_device_loader(device)):\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data)\n",
    "      loss = loss_fn(output , label)\n",
    "      #accuracy\n",
    "      _ , pred = torch.max(output , 1)\n",
    "      train_corr += (pred == label).sum()\n",
    "      train_sam += label.shape[0]\n",
    "      loss.backward()\n",
    "      train_loss.append(loss.item())\n",
    "      xm.optimizer_step(optimizer)\n",
    "      \n",
    "    #evaluation\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    val_corr = 0\n",
    "    val_sam = 0\n",
    "    with torch.no_grad():\n",
    "      para_loader = pl.ParallelLoader(val_loader , [device])\n",
    "      for x , (data , label) in enumerate(para_loader.per_device_loader(device)):\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output , label)\n",
    "        #accuracy\n",
    "        _ , pred = torch.max(output , 1)\n",
    "        val_corr += (pred == label).sum()\n",
    "        val_sam += label.shape[0]\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    t_ac = 100.0 * train_corr / train_sam\n",
    "    v_ac = 100.0 * val_corr / val_sam\n",
    "    t_lo = torch.sum(torch.Tensor(train_loss))\n",
    "    v_lo = torch.sum(torch.Tensor(val_loss))\n",
    "    \n",
    "    print(\"epoch is \",epoch,\" train accu \",t_ac,\" train loss \",t_lo,\" val accu \",v_ac,\" val loss \",v_lo)\n",
    "  \n",
    "  if xm.is_master_ordinal():\n",
    "    dic = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      para_loader = pl.ParallelLoader(test_loader , [device])\n",
    "      for x , (data , ids) in enumerate(para_loader.per_device_loader(device)):\n",
    "        output = model(data)\n",
    "        _ , pred = torch.max(output , 1)\n",
    "        for i in range(pred.shape[0]):\n",
    "          dic[ids[i]] = int(pred[i].cpu().detach().numpy())\n",
    "      df = pd.DataFrame(dic.items())\n",
    "      df.to_csv(\"fin_sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmp.spawn(run , nprocs = 8 , start_method = \"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('fin_sub.csv')\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = pd.DataFrame({\"id\":dff[\"0\"].values , \"label\":dff[\"1\"].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin.to_csv('submission.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"fin_sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
