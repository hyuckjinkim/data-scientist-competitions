{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농산물 가격 예측을 위한 AI 모델 개발 \n",
    "- '2024 농산물 가격 예측 AI 경진대회'는 데이터와 AI 기술을 활용하여 농산물 가격 예측 능력을 향상시키는 것을 목표로 합니다.<br>  이 대회는 농업 분야의 복잡한 시계열 데이터를 효율적으로 분석하고 예측할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br> <br>\n",
    "- 이 대회의 궁극적 목적은 참가자들의 시계열 데이터 분석 및 예측 역량을 강화하고, <br> AI 기술이 실제 농산물 가격 예측과 관련 정책 결정에 어떻게 기여할 수 있는지 탐구하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_dir = \"g:/My Drive/Storage/Github/hyuckjinkim\"\n",
    "sys.path.append(lib_dir)\n",
    "\n",
    "from lib.python.graph import MatplotlibFontManager\n",
    "fm = MatplotlibFontManager()\n",
    "fm.set_korean_font(check=False)\n",
    "\n",
    "from lib.python.torch import seed_everything\n",
    "from lib.python.torch.build_model import train, predict\n",
    "from lib.python.log import get_logger\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# train_df = pd.read_csv('data/train/train.csv')\n",
    "\n",
    "# train_meta1_df = pd.read_csv('data/train/meta/TRAIN_산지공판장_2018-2021.csv')\n",
    "# train_meta1_df.drop(['품목코드','품종코드','공판장코드'], axis=1, inplace=True)\n",
    "\n",
    "# train_meta2_df = pd.read_csv('data/train/meta/TRAIN_전국도매_2018-2021.csv')\n",
    "# train_meta2_df.drop(['품목코드','품종코드','시장코드']  , axis=1, inplace=True)\n",
    "\n",
    "# train_df.head(2) # ['평년 평균가격(원)','평균가격(원)']\n",
    "# train_meta1_df.head(2)\n",
    "# train_meta2_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from types import SimpleNamespace\n",
    "import pickle\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for Feature Engineering\n",
    "- 타겟의 필터 조건을 제외한 메타데이터의 필터 조건은 참가자들 각자의 기준에 맞춰 자유롭게 사용가능 \n",
    "- 밑의 필터 조건은 임의로 제공하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_convert(data):\n",
    "    data['연도'] -= 2018\n",
    "\n",
    "    offset = 0.1\n",
    "    map_dict = {'상순':offset, '중순':offset+1/3, '하순':offset+2/3}\n",
    "    data['연도'] += data['시점'].str.extract(r'(상순|중순|하순)')[0].map(map_dict)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scalers=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 품목코드, 품종코드, 공판장코드, 시장코드 제거\n",
    "    산지공판장.drop(['품목코드','품종코드','공판장코드'], axis=1, inplace=True)\n",
    "    전국도매  .drop(['품목코드','품종코드','시장코드']  , axis=1, inplace=True)\n",
    "\n",
    "    # 연도에 상/중/하순에 대한 정보도 추가\n",
    "    산지공판장 = year_convert(산지공판장)\n",
    "    전국도매 = year_convert(전국도매)\n",
    "\n",
    "    # 이상값(0이하) 처리\n",
    "    for col in ['전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR']:\n",
    "        loc = 전국도매[col] < 0\n",
    "        전국도매.loc[loc,col] = 0\n",
    "\n",
    "    # log변환\n",
    "    raw_cols = ['평년 평균가격(원)', '평균가격(원)']\n",
    "    산지공판장_cols =  ['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '중간가(원/kg)', '최저가(원/kg)', '최고가(원/kg)', '경매 건수', \n",
    "                       '전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR', '평년 평균가격(원) Common Year SOON']\n",
    "    전국도매_cols = ['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '중가(60%) 평균가 ', '저가(20%) 평균가', '중간가(원/kg)', '최저가(원/kg)',\n",
    "                    '최고가(원/kg)', '경매 건수', '전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR', '평년 평균가격(원) Common Year SOON']\n",
    "    for col in raw_cols: raw_data[col] = np.log1p(raw_data[col])\n",
    "    for col in 산지공판장_cols: 산지공판장[col] = np.log1p(산지공판장[col])\n",
    "    for col in 전국도매_cols: 전국도매[col] = np.log1p(전국도매[col])\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # 다른 품종에 대한 파생변수 생성\n",
    "    other_data = raw_품목[~target_mask]\n",
    "    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "        temp_df = other_data[mask]\n",
    "        for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "    # 공판장 데이터 처리\n",
    "    if conditions[품목명]['공판장']:\n",
    "        filtered_공판장 = 산지공판장\n",
    "        for key, value in conditions[품목명]['공판장'].items():\n",
    "            filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "        filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # 도매 데이터 처리\n",
    "    if conditions[품목명]['도매']:\n",
    "        filtered_도매 = 전국도매\n",
    "        for key, value in conditions[품목명]['도매'].items():\n",
    "            filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "        filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # 정규화 적용\n",
    "    if scalers is None:\n",
    "        scalers = {}\n",
    "        for col in numeric_columns:\n",
    "            scaler = MinMaxScaler()\n",
    "            filtered_data[col] = scaler.fit_transform(filtered_data[col].values.reshape(-1,1))\n",
    "            scalers[col] = scaler\n",
    "    else:\n",
    "        for col in numeric_columns:\n",
    "            scaler = scalers[col]\n",
    "            filtered_data[col] = scaler.transform(filtered_data[col].values.reshape(-1,1))\n",
    "\n",
    "    return filtered_data, scalers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturePriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        self.price_column = '평균가격(원)'\n",
    "        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        self.sequences = []\n",
    "        if not self.is_test:\n",
    "            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n",
    "                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n",
    "                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n",
    "                self.sequences.append((x, y))\n",
    "        else:\n",
    "            self.sequences = [self.data[self.numeric_columns].values]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            x, y = self.sequences[idx]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        else:\n",
    "            return torch.FloatTensor(self.sequences[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinformerSelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, num_heads, k=32, dropout=0.1):\n",
    "        super(LinformerSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.k = k  # Low-rank projection dimension\n",
    "        assert self.head_dim * num_heads == input_dim, \"input_dim must be divisible by num_heads\"\n",
    "\n",
    "        # Linear projections for queries, keys, and values\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Low-rank projection matrices for keys and values\n",
    "        self.proj_key = nn.Linear(seq_len, seq_len)  # 수정: 투영 차원을 원래 시퀀스 길이와 일치시킴\n",
    "        self.proj_value = nn.Linear(seq_len, seq_len)  # 수정: 투영 차원을 맞춤\n",
    "\n",
    "        # Output projection\n",
    "        self.out = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, _ = x.size()\n",
    "\n",
    "        # Project to queries, keys, and values\n",
    "        queries = self.query(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        keys = self.key(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = self.value(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Apply low-rank projection to keys and values\n",
    "        keys = self.proj_key(keys).transpose(1, 2)  # 투영 후 크기 맞춤\n",
    "        values = self.proj_value(values).transpose(1, 2)  # 투영 후 크기 맞춤\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(queries, keys.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # Attention output\n",
    "        output = torch.matmul(attn, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seq_len, self.num_heads * self.head_dim)\n",
    "\n",
    "        return self.out(output)\n",
    "\n",
    "class PerformerSelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, kernel_size=32, dropout=0.1):\n",
    "        super(PerformerSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.kernel_size = kernel_size\n",
    "        assert self.head_dim * num_heads == input_dim, \"input_dim must be divisible by num_heads\"\n",
    "\n",
    "        # Linear projections for queries, keys, and values\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Output projection\n",
    "        self.out = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def feature_map(self, x):\n",
    "        # Random Fourier feature mapping (or kernel approximation)\n",
    "        return torch.exp(-x ** 2 / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, _ = x.size()\n",
    "\n",
    "        # Project to queries, keys, and values\n",
    "        queries = self.feature_map(self.query(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2))\n",
    "        keys = self.feature_map(self.key(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2))\n",
    "        values = self.value(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Perform efficient attention\n",
    "        kv = torch.einsum('bhse,bhsc->bhsec', keys, values)\n",
    "        qkv = torch.einsum('bhse,bhsec->bhsc', queries, kv)\n",
    "\n",
    "        # Attention output\n",
    "        output = qkv.transpose(1, 2).contiguous().view(bsz, seq_len, self.num_heads * self.head_dim)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Time2Vec, self).__init__()\n",
    "        periodic_dim = (input_dim-1) // 2\n",
    "        self.linear = nn.Linear(input_dim, input_dim - periodic_dim*2)\n",
    "        self.periodic = nn.Linear(input_dim, periodic_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        linear_out = self.linear(x)\n",
    "        periodic_sin = torch.sin(self.periodic(x))\n",
    "        periodic_cos = torch.cos(self.periodic(x))  # cosine 추가\n",
    "        periodic_out = torch.cat([periodic_sin, periodic_cos], dim=-1)  # sin과 cos 결합\n",
    "        return torch.cat([linear_out, periodic_out], dim=-1)\n",
    "\n",
    "# Define Transformer Encoder Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dropout, method='multihead', seq_len=None):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.method = method\n",
    "        \n",
    "        if method == 'multihead':\n",
    "            self.attention = nn.MultiheadAttention(input_dim, num_heads, dropout=dropout)\n",
    "        elif method == 'linformer':\n",
    "            self.attention = LinformerSelfAttention(input_dim, seq_len, num_heads, dropout=dropout)\n",
    "        elif method == 'performer':\n",
    "            self.attention = PerformerSelfAttention(input_dim, num_heads, dropout=dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4 * input_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * input_dim, input_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.method=='multihead':\n",
    "            attended, _ = self.attention(x, x, x) # 1. Attention\n",
    "        else:\n",
    "            attended = self.attention(x)\n",
    "        x = self.norm1(attended + x)              # 2. 잔차 연결 + Layer Normalization\n",
    "        feedforward = self.ff(x)                  # 3. Feedforward + BatchNorm 적용\n",
    "        x = self.norm2(feedforward + x)           # 4. 잔차 연결 + Layer Normalization\n",
    "        return x\n",
    "\n",
    "# Define main model architecture\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, output_size, dropout, method, seq_len):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.max_len = 10\n",
    "\n",
    "        self.time2vec = Time2Vec(input_size)\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.position_encoding = self.generate_position_encoding(hidden_size, self.max_len)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(hidden_size, num_heads, dropout, method, seq_len) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, output_size)\n",
    "        )\n",
    "\n",
    "    def generate_position_encoding(self, hidden_size, max_len):\n",
    "        pe = torch.zeros(max_len, hidden_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-np.log(10000.0) / hidden_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, s, f = x.shape\n",
    "        x = self.time2vec(x)\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.position_encoding[:, :s, :].to(x.device)\n",
    "        x = self.dropout(x)\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(true,pred):\n",
    "    true, pred = np.array(true), np.array(pred)\n",
    "    return np.mean(np.abs(true - pred) / true)\n",
    "\n",
    "def minmax_inverse_transform(x, scaler, is_train=True):\n",
    "    origin = scaler.data_min_[0] + x * (scaler.data_max_[0] - scaler.data_min_[0])\n",
    "    origin = torch.expm1(origin) if is_train else np.expm1(origin)\n",
    "    return origin\n",
    "\n",
    "def variance_threshold_select(data, threshold=0.01, ignore_features=list()):\n",
    "    cols = data.select_dtypes(include=[np.number]).columns\n",
    "    cols = list(set(cols)-set(ignore_features))\n",
    "\n",
    "    del_features = []\n",
    "    for col in cols:\n",
    "        variance = train_data[col].std()**2\n",
    "        if variance<threshold:\n",
    "            del_features.append(col)\n",
    "    \n",
    "    return del_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(best_model, loader, device, inverse_transform):\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    \n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for data,label in loader:\n",
    "            data = data.float().to(device)\n",
    "\n",
    "            output = best_model(data)\n",
    "            output = inverse_transform(output)\n",
    "            output = output.cpu().numpy().tolist()\n",
    "\n",
    "            label  = inverse_transform(label)\n",
    "            label = label.cpu().numpy().tolist()\n",
    "\n",
    "            true_list += label\n",
    "            pred_list += output\n",
    "\n",
    "    return true_list, pred_list\n",
    "\n",
    "def inference(best_model, loader, device, inverse_transform):\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    \n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.float().to(device)\n",
    "\n",
    "            output = best_model(data)\n",
    "            output = inverse_transform(output)\n",
    "            output = output.cpu().numpy().tolist()\n",
    "\n",
    "            pred_list += output\n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"epoch\": 4048,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 3,\n",
    "    \"output_size\": 3,\n",
    "    \"dropout\": 0.2,\n",
    "    \"num_heads\": 8,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"test_size\": 0.2,\n",
    "    \"seed\": 42,\n",
    "    \"threshold\": 0.005,\n",
    "    \"device\": 'cpu',\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']\n",
    "# 품목_리스트 = ['감자']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================================================================================================\n",
      "> [01/10] 건고추\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0100/4048] tr_loss: 88100.1523, val_loss: 32423.4102, best: 32423.4102(100), elapsed: 41.1s, total: 41.1s, remaining: 1622.1s\n",
      " [0200/4048] tr_loss: 73002.6914, val_loss: 34428.2969, best: 22214.0449(185), elapsed: 36.8s, total: 78.0s, remaining: 1416.0s\n",
      " [0300/4048] tr_loss: 65984.5547, val_loss: 23737.2246, best: 22192.8711(247), elapsed: 34.8s, total: 112.8s, remaining: 1303.1s\n",
      " [0400/4048] tr_loss: 62530.0957, val_loss: 28955.0254, best: 22319.3223(392), elapsed: 34.5s, total: 147.3s, remaining: 1259.5s\n",
      " [0500/4048] tr_loss: 60944.4863, val_loss: 26231.5332, best: 22319.3223(392), elapsed: 34.9s, total: 182.3s, remaining: 1239.0s\n",
      "<Stopped> [0592/4048] tr_loss: 68583.0020, val_loss: 24191.9668, best: 22319.3223(392), elapsed: 33.8s, total: 216.0s, remaining: 1166.6s\n",
      "<Score> train_nmae=0.0579, val_nmae=0.0423\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [02/10] 사과\n",
      "======================================================================================================================================================\n",
      "\n",
      " [0100/4048] tr_loss: 2680.1761, val_loss: 2638.4236, best: 1907.4352(99), elapsed: 41.7s, total: 41.7s, remaining: 1644.4s\n",
      "*[0200/4048] tr_loss: 2319.2667, val_loss: 1714.1896, best: 1714.1896(200), elapsed: 37.1s, total: 78.8s, remaining: 1427.9s\n",
      " [0300/4048] tr_loss: 1825.7295, val_loss: 1567.4104, best: 1460.0778(278), elapsed: 36.7s, total: 115.6s, remaining: 1376.6s\n",
      " [0400/4048] tr_loss: 1714.7228, val_loss: 1623.9977, best: 1335.0591(375), elapsed: 35.5s, total: 151.1s, remaining: 1296.8s\n",
      " [0500/4048] tr_loss: 1665.6774, val_loss: 1347.7170, best: 1335.0591(375), elapsed: 34.6s, total: 185.7s, remaining: 1226.1s\n",
      "<Stopped> [0575/4048] tr_loss: 1681.0968, val_loss: 1400.1886, best: 1335.0591(375), elapsed: 26.0s, total: 211.7s, remaining: 901.5s\n",
      "<Score> train_nmae=0.0531, val_nmae=0.0562\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [03/10] 감자\n",
      "======================================================================================================================================================\n",
      "\n",
      " [0100/4048] tr_loss: 8391.0356, val_loss: 5640.7729, best: 5296.3623(92), elapsed: 44.6s, total: 44.6s, remaining: 1758.9s\n",
      " [0200/4048] tr_loss: 7558.1470, val_loss: 4973.9990, best: 4586.7783(183), elapsed: 36.1s, total: 80.7s, remaining: 1390.0s\n",
      " [0300/4048] tr_loss: 6876.3223, val_loss: 4999.7197, best: 4553.8003(250), elapsed: 35.2s, total: 115.9s, remaining: 1319.0s\n",
      " [0400/4048] tr_loss: 5898.4788, val_loss: 5844.1582, best: 4553.8003(250), elapsed: 35.2s, total: 151.1s, remaining: 1283.8s\n",
      "<Stopped> [0450/4048] tr_loss: 5747.2285, val_loss: 5016.3472, best: 4553.8003(250), elapsed: 18.7s, total: 169.7s, remaining: 672.0s\n",
      "<Score> train_nmae=0.1390, val_nmae=0.1456\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [04/10] 배\n",
      "======================================================================================================================================================\n",
      "\n",
      " [0100/4048] tr_loss: 3527.8022, val_loss: 3527.0483, best: 3005.5288(98), elapsed: 44.0s, total: 44.0s, remaining: 1736.7s\n",
      " [0200/4048] tr_loss: 3325.4043, val_loss: 3541.6624, best: 2428.7729(196), elapsed: 37.2s, total: 81.2s, remaining: 1429.9s\n",
      " [0300/4048] tr_loss: 2975.0459, val_loss: 2975.1604, best: 2336.6504(208), elapsed: 37.0s, total: 118.1s, remaining: 1385.0s\n",
      " [0400/4048] tr_loss: 2538.4845, val_loss: 2522.6277, best: 2336.6504(208), elapsed: 34.5s, total: 152.6s, remaining: 1258.3s\n",
      "<Stopped> [0408/4048] tr_loss: 2666.4807, val_loss: 2543.1086, best: 2336.6504(208), elapsed: 2.7s, total: 155.3s, remaining: 98.6s\n",
      "<Score> train_nmae=0.0672, val_nmae=0.0704\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [05/10] 깐마늘(국산)\n",
      "======================================================================================================================================================\n",
      "\n",
      " [0100/4048] tr_loss: 14732.3521, val_loss: 24680.5547, best: 10782.7559(61), elapsed: 37.6s, total: 37.6s, remaining: 1484.9s\n",
      " [0200/4048] tr_loss: 12083.1680, val_loss: 16611.9414, best: 10782.7559(61), elapsed: 34.2s, total: 71.8s, remaining: 1314.4s\n",
      "<Stopped> [0261/4048] tr_loss: 11488.2305, val_loss: 15443.2002, best: 10782.7559(61), elapsed: 21.1s, total: 92.8s, remaining: 797.9s\n",
      "<Score> train_nmae=0.1037, val_nmae=0.1301\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [06/10] 무\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0100/4048] tr_loss: 3809.6464, val_loss: 3127.3730, best: 3127.3730(100), elapsed: 44.4s, total: 44.4s, remaining: 1751.3s\n",
      " [0200/4048] tr_loss: 3438.0455, val_loss: 2628.7300, best: 2549.5952(197), elapsed: 42.7s, total: 87.2s, remaining: 1642.0s\n",
      " [0300/4048] tr_loss: 3177.2335, val_loss: 2783.0518, best: 2546.6384(223), elapsed: 34.4s, total: 121.5s, remaining: 1287.5s\n",
      " [0400/4048] tr_loss: 2979.1622, val_loss: 2903.3887, best: 2546.6384(223), elapsed: 34.6s, total: 156.1s, remaining: 1262.8s\n",
      "<Stopped> [0423/4048] tr_loss: 2599.9758, val_loss: 2861.9097, best: 2546.6384(223), elapsed: 8.4s, total: 164.5s, remaining: 302.7s\n",
      "<Score> train_nmae=0.1574, val_nmae=0.2026\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [07/10] 상추\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0100/4048] tr_loss: 288.2836, val_loss: 263.4948, best: 263.4948(100), elapsed: 40.8s, total: 40.8s, remaining: 1610.4s\n",
      " [0200/4048] tr_loss: 232.9420, val_loss: 212.5868, best: 201.9155(181), elapsed: 39.2s, total: 80.1s, remaining: 1509.6s\n",
      " [0300/4048] tr_loss: 190.8493, val_loss: 206.8142, best: 195.2834(222), elapsed: 33.9s, total: 114.0s, remaining: 1269.7s\n",
      " [0400/4048] tr_loss: 181.9413, val_loss: 201.7368, best: 195.2834(222), elapsed: 34.2s, total: 148.2s, remaining: 1245.8s\n",
      " [0500/4048] tr_loss: 188.7241, val_loss: 200.4302, best: 201.2508(409), elapsed: 35.6s, total: 183.7s, remaining: 1261.5s\n",
      " [0600/4048] tr_loss: 186.4453, val_loss: 200.9698, best: 201.2508(409), elapsed: 35.8s, total: 219.6s, remaining: 1235.7s\n",
      "<Stopped> [0609/4048] tr_loss: 171.6032, val_loss: 200.8716, best: 201.2508(409), elapsed: 3.2s, total: 222.7s, remaining: 108.4s\n",
      "<Score> train_nmae=0.1350, val_nmae=0.1659\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [08/10] 배추\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0100/4048] tr_loss: 2773.9904, val_loss: 2512.9187, best: 2512.9187(100), elapsed: 44.1s, total: 44.1s, remaining: 1742.8s\n",
      " [0200/4048] tr_loss: 2538.3325, val_loss: 2404.7107, best: 2233.0227(191), elapsed: 38.9s, total: 83.2s, remaining: 1496.8s\n",
      " [0300/4048] tr_loss: 2460.1318, val_loss: 2016.7606, best: 1970.3237(299), elapsed: 36.2s, total: 119.4s, remaining: 1357.1s\n",
      " [0400/4048] tr_loss: 2051.3328, val_loss: 2187.6992, best: 1885.5961(396), elapsed: 37.1s, total: 156.5s, remaining: 1353.1s\n",
      " [0500/4048] tr_loss: 2097.3403, val_loss: 2101.8218, best: 1834.1962(422), elapsed: 34.5s, total: 191.0s, remaining: 1224.7s\n",
      " [0600/4048] tr_loss: 1895.4077, val_loss: 1954.6808, best: 1834.1962(422), elapsed: 34.0s, total: 225.0s, remaining: 1172.9s\n",
      "<Stopped> [0622/4048] tr_loss: 1799.9968, val_loss: 2035.4608, best: 1834.1962(422), elapsed: 7.8s, total: 232.8s, remaining: 266.9s\n",
      "<Score> train_nmae=0.2185, val_nmae=0.2720\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [09/10] 양파\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0100/4048] tr_loss: 173.1626, val_loss: 134.0358, best: 134.0358(100), elapsed: 40.8s, total: 40.8s, remaining: 1611.4s\n",
      " [0200/4048] tr_loss: 152.2869, val_loss: 131.1211, best: 112.8764(190), elapsed: 37.9s, total: 78.8s, remaining: 1459.4s\n",
      " [0300/4048] tr_loss: 136.9431, val_loss: 147.3089, best: 106.4029(281), elapsed: 33.7s, total: 112.5s, remaining: 1261.5s\n",
      " [0400/4048] tr_loss: 124.4757, val_loss: 110.0015, best: 96.8589(390), elapsed: 33.1s, total: 145.6s, remaining: 1207.8s\n",
      " [0500/4048] tr_loss: 121.8506, val_loss: 106.5480, best: 96.8589(390), elapsed: 34.9s, total: 180.5s, remaining: 1238.0s\n",
      "<Stopped> [0590/4048] tr_loss: 117.3942, val_loss: 104.3065, best: 96.8589(390), elapsed: 29.6s, total: 210.1s, remaining: 1022.3s\n",
      "<Score> train_nmae=0.1019, val_nmae=0.1450\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [10/10] 대파\n",
      "======================================================================================================================================================\n",
      "\n",
      " [0100/4048] tr_loss: 556.8357, val_loss: 447.1059, best: 403.5266(88), elapsed: 37.1s, total: 37.1s, remaining: 1466.1s\n",
      " [0200/4048] tr_loss: 431.3417, val_loss: 328.8747, best: 279.3794(194), elapsed: 34.2s, total: 71.3s, remaining: 1314.4s\n",
      " [0300/4048] tr_loss: 342.8054, val_loss: 254.0173, best: 251.6438(294), elapsed: 34.8s, total: 106.1s, remaining: 1305.4s\n",
      " [0400/4048] tr_loss: 332.1459, val_loss: 248.2020, best: 226.0447(394), elapsed: 33.6s, total: 139.7s, remaining: 1226.5s\n",
      " [0500/4048] tr_loss: 327.2498, val_loss: 232.0767, best: 218.0640(428), elapsed: 34.2s, total: 174.0s, remaining: 1214.6s\n",
      " [0600/4048] tr_loss: 294.3166, val_loss: 220.2234, best: 205.8486(598), elapsed: 33.2s, total: 207.2s, remaining: 1144.8s\n",
      " [0700/4048] tr_loss: 302.6960, val_loss: 224.5936, best: 194.5975(685), elapsed: 32.2s, total: 239.3s, remaining: 1076.4s\n",
      " [0800/4048] tr_loss: 315.6321, val_loss: 245.0361, best: 191.8569(782), elapsed: 31.9s, total: 271.2s, remaining: 1035.8s\n",
      " [0900/4048] tr_loss: 267.5845, val_loss: 196.9220, best: 191.1817(867), elapsed: 33.8s, total: 305.0s, remaining: 1064.4s\n",
      "*[1000/4048] tr_loss: 319.3100, val_loss: 183.1672, best: 183.1672(1000), elapsed: 32.3s, total: 337.3s, remaining: 983.7s\n",
      " [1100/4048] tr_loss: 274.8280, val_loss: 192.5578, best: 183.1672(1000), elapsed: 32.3s, total: 369.7s, remaining: 953.1s\n",
      " [1200/4048] tr_loss: 265.2836, val_loss: 210.4786, best: 183.1672(1000), elapsed: 34.0s, total: 403.7s, remaining: 968.7s\n",
      "<Stopped> [1200/4048] tr_loss: 265.2836, val_loss: 210.4786, best: 183.1672(1000), elapsed: 0.0s, total: 403.7s, remaining: 0.0s\n",
      "<Score> train_nmae=0.1044, val_nmae=0.1268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logger = get_logger(save_path='log/TimeSeriesTransformer_log.log')\n",
    "# trace_func = logger.info\n",
    "trace_func = print\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "품목별_scalers = {}\n",
    "품목별_delcols = {}\n",
    "품목별_hyperparams = {}\n",
    "\n",
    "train_nmae_list = []\n",
    "val_nmae_list = []\n",
    "\n",
    "for i, 품목명 in enumerate(품목_리스트):\n",
    "    model_path = f'models/TimeSeriesTransformer_{품목명}.pth'\n",
    "    trace_func('')\n",
    "    trace_func('='*150)\n",
    "    trace_func(f'> [{i+1:02d}/{len(품목_리스트)}] {품목명}')\n",
    "    trace_func('='*150)\n",
    "    trace_func('')\n",
    "\n",
    "    # preprocessing\n",
    "    train_data, scalers = process_data(\"data/train/train.csv\", \"data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \"data/train/meta/TRAIN_전국도매_2018-2021.csv\", 품목명)\n",
    "    품목별_scalers[품목명] = scalers\n",
    "    \n",
    "    # 분산이 threshold보다 작은 컬럼 제거\n",
    "    del_cols = variance_threshold_select(train_data, threshold=CFG.threshold, ignore_features=['평균가격(원)'])\n",
    "    train_data.drop(del_cols, axis=1, inplace=True)\n",
    "    품목별_delcols[품목명] = del_cols\n",
    "\n",
    "    # train, validation split\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "    tr_data, val_data = train_test_split(dataset, test_size=CFG.test_size, random_state=CFG.seed, shuffle=True)\n",
    "    train_loader = DataLoader(tr_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    # define model\n",
    "    품목별_hyperparams[품목명] = dict(\n",
    "        input_size=len(dataset.numeric_columns),\n",
    "        hidden_size=CFG.hidden_size,\n",
    "        num_layers=CFG.num_layers,\n",
    "        output_size=CFG.output_size,\n",
    "        dropout=CFG.dropout,\n",
    "        num_heads=CFG.num_heads,\n",
    "        method='performer', # multihead, linformer, performer\n",
    "        seq_len=32,\n",
    "    )\n",
    "    model = TimeSeriesTransformer(**품목별_hyperparams[품목명]).to(CFG.device)\n",
    "    criterion = nn.HuberLoss() #nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50)\n",
    "    # scheduler = None\n",
    "\n",
    "    price_scaler = 품목별_scalers[품목명][dataset.price_column]\n",
    "    inverse_transform = lambda x: minmax_inverse_transform(x, price_scaler)\n",
    "    # inverse_transform = None\n",
    "\n",
    "    # train\n",
    "    best_model = train(\n",
    "        model, optimizer, train_loader, val_loader, CFG.epoch,\n",
    "        early_stopping=True, early_stopping_patience=200, early_stopping_verbose=False,\n",
    "        device='cpu', scheduler=scheduler, metric_period=100, \n",
    "        verbose=True, save_model_path=model_path,\n",
    "        inverse_transform=inverse_transform,\n",
    "    )\n",
    "\n",
    "    # scoring\n",
    "    true, pred = predict(best_model, train_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "    train_nmae = nmae(true,pred)\n",
    "    true, pred = predict(best_model, val_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "    val_nmae = nmae(true,pred)\n",
    "    trace_func(f'<Score> {train_nmae=:.4f}, {val_nmae=:.4f}')\n",
    "    trace_func('')\n",
    "\n",
    "    train_nmae_list.append(train_nmae)\n",
    "    val_nmae_list.append(val_nmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_nmae0.1138, val_nmae=0.1357'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'train_nmae{np.mean(train_nmae_list):.4f}, val_nmae={np.mean(val_nmae_list):.4f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/scalers.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(품목별_scalers, pickle_file)\n",
    "\n",
    "with open('out/delcols.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(품목별_delcols, pickle_file)\n",
    "\n",
    "with open('out/hyperparams.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(품목별_hyperparams, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true, pred = predict(best_model, train_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "# print(criterion(torch.tensor(true), torch.tensor(pred)).item())\n",
    "# true[:5], pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/scalers.pkl', 'rb') as pickle_file:\n",
    "    품목별_scalers = pickle.load(pickle_file)\n",
    "\n",
    "with open('out/delcols.pkl', 'rb') as pickle_file:\n",
    "    품목별_delcols = pickle.load(pickle_file)\n",
    "\n",
    "with open('out/hyperparams.pkl', 'rb') as pickle_file:\n",
    "    품목별_hyperparams = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "건고추 []\n",
      "사과 []\n",
      "감자 ['감자 수미(햇)_20키로상자_중_평년 평균가격(원)', '감자 수미(저장)_20키로상자_중_평년 평균가격(원)', '감자_20키로상자_중_평년 평균가격(원)', '감자 조풍_20키로상자_중_평년 평균가격(원)', '감자 수미(저장)_20키로상자_상_평년 평균가격(원)', '감자 수미(햇)_20키로상자_하_평년 평균가격(원)', '감자 수미(햇)_20키로상자_특_평년 평균가격(원)', '감자 두백_20키로상자_특_평년 평균가격(원)', '감자 수미(저장)_20키로상자_하_평년 평균가격(원)', '감자 조풍_20키로상자_특_평균가격(원)', '감자_20키로상자_특_평년 평균가격(원)', '홍감자_10키로상자_상_평년 평균가격(원)', '감자 조풍_20키로상자_상_평균가격(원)', '감자 수입_23키로상자_상_평년 평균가격(원)', '감자 조풍_20키로상자_상_평년 평균가격(원)', '감자 조풍_20키로상자_특_평년 평균가격(원)', '감자 수미(햇)_20키로상자_상_평년 평균가격(원)', '감자 조풍_20키로상자_하_평균가격(원)', '감자 두백_20키로상자_상_평년 평균가격(원)', '감자_20키로상자_상_평년 평균가격(원)', '홍감자_10키로상자_중_평년 평균가격(원)', '감자 수미(저장)_20키로상자_특_평년 평균가격(원)', '감자 조풍_20키로상자_중_평균가격(원)', '감자 두백_20키로상자_중_평년 평균가격(원)', '감자 두백_20키로상자_하_평년 평균가격(원)', '감자_20키로상자_하_평년 평균가격(원)', '홍감자_10키로상자_하_평년 평균가격(원)', '홍감자_10키로상자_특_평년 평균가격(원)', '감자 조풍_20키로상자_하_평년 평균가격(원)']\n",
      "배 ['공판장_등급코드']\n",
      "깐마늘(국산) ['깐마늘(국산)_20 kg_중품_평년 평균가격(원)', '평년 평균가격(원)']\n",
      "무 ['다발무_5000키로_상_평년 평균가격(원)', '다발무_1000키로_특_평년 평균가격(원)', '열무_4키로상자_중_평년 평균가격(원)', '다발무_1000키로_중_평년 평균가격(원)', '다발무_5000키로_상_평균가격(원)', '다발무_8톤트럭_중_평년 평균가격(원)', '다발무_5000키로_특_평균가격(원)', '무_20키로상자_특_평년 평균가격(원)', '다발무_1000키로_하_평균가격(원)', '공판장_등급코드', '다발무_5000키로_하_평년 평균가격(원)', '다발무_1000키로_하_평년 평균가격(원)', '평년 평균가격(원)', '다발무_8톤트럭_상_평년 평균가격(원)', '다발무_5000키로_특_평년 평균가격(원)', '무_20키로상자_중_평년 평균가격(원)', '다발무_10키로_중_평년 평균가격(원)', '다발무_10키로_특_평년 평균가격(원)', '다발무_5000키로_하_평균가격(원)', '다발무_10키로_상_평년 평균가격(원)', '다발무_10키로_하_평년 평균가격(원)', '다발무_1000키로_특_평균가격(원)', '무_20키로상자_하_평년 평균가격(원)', '다발무_1000키로_중_평균가격(원)', '다발무_5000키로_중_평년 평균가격(원)', '다발무_1000키로_상_평년 평균가격(원)', '다발무_5000키로_중_평균가격(원)', '다발무_8톤트럭_하_평년 평균가격(원)', '도매_평년 평균가격(원) Common Year SOON', '다발무_1000키로_상_평균가격(원)']\n",
      "상추 ['공판장_전달 평균가격(원) PreVious MMonth', '공판장_평년 평균가격(원) Common Year SOON', '공판장_전순 평균가격(원) PreVious SOON']\n",
      "배추 ['얼갈이배추_8키로상자_상_평년 평균가격(원)', '봄동배추_15키로상자_중_평년 평균가격(원)', '얼갈이배추_8키로상자_하_평년 평균가격(원)', '쌈배추_1키로상자_중_평년 평균가격(원)', '쌈배추_1키로상자_특_평년 평균가격(원)', '쌈배추_1키로상자_상_평년 평균가격(원)', '얼갈이배추_8키로상자_중_평년 평균가격(원)', '도매_평년 평균가격(원) Common Year SOON', '봄동배추_15키로상자_하_평년 평균가격(원)', '쌈배추_1키로상자_하_평년 평균가격(원)']\n",
      "양파 ['조생양파_15키로_상_평년 평균가격(원)', '조생양파_12키로_하_평균가격(원)', '양파_12키로_하_평년 평균가격(원)', '저장양파_20키로_상_평년 평균가격(원)', '조생양파_15키로_상_평균가격(원)', '자주양파_1키로_중_평년 평균가격(원)', '조생양파_12키로_하_평년 평균가격(원)', '양파_10키로_중_평년 평균가격(원)', '양파 수입_1키로_특_평년 평균가격(원)', '양파_15키로_특_평년 평균가격(원)', '저장양파_12키로_중_평년 평균가격(원)', '양파(햇)_12키로_특_평년 평균가격(원)', '공판장_등급코드', '양파_15키로_하_평년 평균가격(원)', '양파(햇)_12키로_상_평년 평균가격(원)', '저장양파_20키로_특_평년 평균가격(원)', '조생양파_12키로_중_평균가격(원)', '양파(햇)_15키로_특_평년 평균가격(원)', '조생양파_15키로_특_평년 평균가격(원)', '양파(햇)_20키로_중_평년 평균가격(원)', '자주양파_1키로_상_평년 평균가격(원)', '양파_10키로_특_평년 평균가격(원)', '저장양파_15키로_하_평년 평균가격(원)', '조생양파_15키로_특_평균가격(원)', '양파_15키로_중_평년 평균가격(원)', '저장양파_12키로_하_평년 평균가격(원)', '양파_12키로_특_평년 평균가격(원)', '저장양파_15키로_특_평년 평균가격(원)', '저장양파_12키로_상_평년 평균가격(원)', '양파(햇)_20키로_하_평년 평균가격(원)', '자주양파_1키로_특_평년 평균가격(원)', '조생양파_15키로_중_평균가격(원)', '양파(햇)_20키로_상_평년 평균가격(원)', '조생양파_12키로_상_평년 평균가격(원)', '양파_10키로_하_평년 평균가격(원)', '저장양파_12키로_특_평년 평균가격(원)', '조생양파_12키로_특_평균가격(원)', '양파_12키로_상_평년 평균가격(원)', '조생양파_15키로_하_평년 평균가격(원)', '양파_12키로_중_평년 평균가격(원)', '자주양파_1키로_하_평년 평균가격(원)', '조생양파_12키로_상_평균가격(원)', '양파_10키로_상_평년 평균가격(원)', '저장양파_20키로_중_평년 평균가격(원)', '조생양파_15키로_중_평년 평균가격(원)', '저장양파_15키로_중_평년 평균가격(원)', '조생양파_12키로_특_평년 평균가격(원)', '양파(햇)_15키로_하_평년 평균가격(원)', '조생양파_15키로_하_평균가격(원)', '양파(햇)_15키로_상_평년 평균가격(원)', '양파(햇)_12키로_중_평년 평균가격(원)', '양파(햇)_15키로_중_평년 평균가격(원)', '조생양파_12키로_중_평년 평균가격(원)', '양파(햇)_20키로_특_평년 평균가격(원)', '양파(햇)_12키로_하_평년 평균가격(원)', '양파_15키로_상_평년 평균가격(원)', '저장양파_15키로_상_평년 평균가격(원)', '저장양파_20키로_하_평년 평균가격(원)']\n",
      "대파 ['대파(일반)_10키로묶음_특_평균가격(원)', '대파(일반)_10키로묶음_중_평균가격(원)', '대파(일반)_10키로묶음_상_평년 평균가격(원)', '대파 수입_10키로상자_상_평년 평균가격(원)', '대파(일반)_10키로묶음_특_평년 평균가격(원)', '대파(일반)_10키로묶음_상_평균가격(원)', '대파(일반)_10키로묶음_하_평균가격(원)', '대파(일반)_10키로묶음_중_평년 평균가격(원)', '대파(일반)_10키로묶음_하_평년 평균가격(원)']\n"
     ]
    }
   ],
   "source": [
    "for k,v in 품목별_delcols.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d442594d354fb7960685013b7d9bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5962c940fc488ca639fac492ca54be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cb03fce7a140e4934abc1446f04f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154a4c5c743445b2a6aac447759dca03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e429f139c704652b22f6b2869d9f094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def6a2d48f4d45d0b7488ecf359c38ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c45e6461b5a4cea8ddc781ddb11031c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8da698a67a2404cb7672b99ff6c4812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9f3c3c84f843d9bf54adeda51319db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0674a387799e4326b4d03c4aafefdd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7dd6ea947740e493a2d970166f6e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "품목별_predictions = {}\n",
    "\n",
    "pbar_outer = tqdm(품목_리스트, position=0)\n",
    "for 품목명 in pbar_outer:\n",
    "    pbar_outer.set_description(품목명)\n",
    "    model_path = f'models/TimeSeriesTransformer_{품목명}.pth'\n",
    "\n",
    "    # define model\n",
    "    model = TimeSeriesTransformer(**품목별_hyperparams[품목명]).to(CFG.device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # inference\n",
    "    품목_predictions = []\n",
    "    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n",
    "    for i in pbar_inner:\n",
    "        test_file = f\"data/test/TEST_{i:02d}.csv\"\n",
    "        산지공판장_file = f\"data/test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "        전국도매_file = f\"data/test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "\n",
    "        test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scalers=품목별_scalers[품목명])\n",
    "        test_data.drop(품목별_delcols[품목명], axis=1, inplace=True)\n",
    "        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        price_scaler = 품목별_scalers[품목명][test_dataset.price_column]\n",
    "        inverse_transform = lambda x: minmax_inverse_transform(x, price_scaler)\n",
    "\n",
    "        predictions = inference(model, test_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "        predictions = np.concatenate(predictions)\n",
    "        \n",
    "        if np.isnan(predictions).any():\n",
    "            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n",
    "            raise ValueError\n",
    "        else:\n",
    "            pbar_inner.set_postfix({\"상태\": \"정상\"})\n",
    "            품목_predictions.extend(predictions.flatten())\n",
    "\n",
    "    품목별_predictions[품목명] = 품목_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "for 품목명, predictions in 품목별_predictions.items():\n",
    "    sample_submission[품목명] = predictions\n",
    "\n",
    "# 결과 저장\n",
    "save_path = 'out/baseline_submission_8.csv'\n",
    "sample_submission.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시점</th>\n",
       "      <th>감자</th>\n",
       "      <th>건고추</th>\n",
       "      <th>깐마늘(국산)</th>\n",
       "      <th>대파</th>\n",
       "      <th>무</th>\n",
       "      <th>배추</th>\n",
       "      <th>사과</th>\n",
       "      <th>상추</th>\n",
       "      <th>양파</th>\n",
       "      <th>배</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00+1순</td>\n",
       "      <td>42525.945312</td>\n",
       "      <td>506869.65625</td>\n",
       "      <td>183690.796875</td>\n",
       "      <td>1642.616821</td>\n",
       "      <td>15125.791992</td>\n",
       "      <td>11944.115234</td>\n",
       "      <td>30389.492188</td>\n",
       "      <td>1161.661377</td>\n",
       "      <td>903.362244</td>\n",
       "      <td>30842.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00+2순</td>\n",
       "      <td>39920.003906</td>\n",
       "      <td>502257.96875</td>\n",
       "      <td>200335.000000</td>\n",
       "      <td>1633.035522</td>\n",
       "      <td>14614.766602</td>\n",
       "      <td>8350.434570</td>\n",
       "      <td>29342.046875</td>\n",
       "      <td>1075.500854</td>\n",
       "      <td>908.290833</td>\n",
       "      <td>30363.361328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00+3순</td>\n",
       "      <td>38372.023438</td>\n",
       "      <td>503067.62500</td>\n",
       "      <td>202348.078125</td>\n",
       "      <td>1644.846558</td>\n",
       "      <td>13541.884766</td>\n",
       "      <td>6710.583496</td>\n",
       "      <td>29171.673828</td>\n",
       "      <td>994.754333</td>\n",
       "      <td>868.916199</td>\n",
       "      <td>31405.814453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_01+1순</td>\n",
       "      <td>44263.695312</td>\n",
       "      <td>583607.75000</td>\n",
       "      <td>183654.531250</td>\n",
       "      <td>1529.945190</td>\n",
       "      <td>13934.520508</td>\n",
       "      <td>8440.171875</td>\n",
       "      <td>28856.148438</td>\n",
       "      <td>962.416443</td>\n",
       "      <td>913.465576</td>\n",
       "      <td>30517.808594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_01+2순</td>\n",
       "      <td>41750.437500</td>\n",
       "      <td>575217.12500</td>\n",
       "      <td>199787.625000</td>\n",
       "      <td>1513.524658</td>\n",
       "      <td>13433.417969</td>\n",
       "      <td>7233.039062</td>\n",
       "      <td>28257.222656</td>\n",
       "      <td>939.898804</td>\n",
       "      <td>904.462585</td>\n",
       "      <td>30110.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TEST_23+2순</td>\n",
       "      <td>49752.140625</td>\n",
       "      <td>613444.75000</td>\n",
       "      <td>200405.328125</td>\n",
       "      <td>1477.261719</td>\n",
       "      <td>9706.476562</td>\n",
       "      <td>6125.318848</td>\n",
       "      <td>28466.066406</td>\n",
       "      <td>722.732361</td>\n",
       "      <td>923.762939</td>\n",
       "      <td>30239.214844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>TEST_23+3순</td>\n",
       "      <td>45767.785156</td>\n",
       "      <td>611481.62500</td>\n",
       "      <td>202500.203125</td>\n",
       "      <td>1516.331421</td>\n",
       "      <td>9382.199219</td>\n",
       "      <td>6080.461426</td>\n",
       "      <td>28575.574219</td>\n",
       "      <td>742.771912</td>\n",
       "      <td>882.899780</td>\n",
       "      <td>31099.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>TEST_24+1순</td>\n",
       "      <td>38576.734375</td>\n",
       "      <td>534925.25000</td>\n",
       "      <td>168197.140625</td>\n",
       "      <td>1524.353271</td>\n",
       "      <td>10799.892578</td>\n",
       "      <td>10938.084961</td>\n",
       "      <td>35017.027344</td>\n",
       "      <td>748.899963</td>\n",
       "      <td>567.506287</td>\n",
       "      <td>34598.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>TEST_24+2순</td>\n",
       "      <td>36103.441406</td>\n",
       "      <td>536602.68750</td>\n",
       "      <td>181658.093750</td>\n",
       "      <td>1633.351074</td>\n",
       "      <td>10580.342773</td>\n",
       "      <td>9403.125977</td>\n",
       "      <td>34105.507812</td>\n",
       "      <td>756.600769</td>\n",
       "      <td>595.250427</td>\n",
       "      <td>33710.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>TEST_24+3순</td>\n",
       "      <td>32473.464844</td>\n",
       "      <td>533676.87500</td>\n",
       "      <td>177158.453125</td>\n",
       "      <td>1620.224976</td>\n",
       "      <td>10971.614258</td>\n",
       "      <td>8803.198242</td>\n",
       "      <td>34236.382812</td>\n",
       "      <td>796.223206</td>\n",
       "      <td>578.648254</td>\n",
       "      <td>34217.808594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            시점            감자           건고추        깐마늘(국산)           대파  \\\n",
       "0   TEST_00+1순  42525.945312  506869.65625  183690.796875  1642.616821   \n",
       "1   TEST_00+2순  39920.003906  502257.96875  200335.000000  1633.035522   \n",
       "2   TEST_00+3순  38372.023438  503067.62500  202348.078125  1644.846558   \n",
       "3   TEST_01+1순  44263.695312  583607.75000  183654.531250  1529.945190   \n",
       "4   TEST_01+2순  41750.437500  575217.12500  199787.625000  1513.524658   \n",
       "..         ...           ...           ...            ...          ...   \n",
       "70  TEST_23+2순  49752.140625  613444.75000  200405.328125  1477.261719   \n",
       "71  TEST_23+3순  45767.785156  611481.62500  202500.203125  1516.331421   \n",
       "72  TEST_24+1순  38576.734375  534925.25000  168197.140625  1524.353271   \n",
       "73  TEST_24+2순  36103.441406  536602.68750  181658.093750  1633.351074   \n",
       "74  TEST_24+3순  32473.464844  533676.87500  177158.453125  1620.224976   \n",
       "\n",
       "               무            배추            사과           상추          양파  \\\n",
       "0   15125.791992  11944.115234  30389.492188  1161.661377  903.362244   \n",
       "1   14614.766602   8350.434570  29342.046875  1075.500854  908.290833   \n",
       "2   13541.884766   6710.583496  29171.673828   994.754333  868.916199   \n",
       "3   13934.520508   8440.171875  28856.148438   962.416443  913.465576   \n",
       "4   13433.417969   7233.039062  28257.222656   939.898804  904.462585   \n",
       "..           ...           ...           ...          ...         ...   \n",
       "70   9706.476562   6125.318848  28466.066406   722.732361  923.762939   \n",
       "71   9382.199219   6080.461426  28575.574219   742.771912  882.899780   \n",
       "72  10799.892578  10938.084961  35017.027344   748.899963  567.506287   \n",
       "73  10580.342773   9403.125977  34105.507812   756.600769  595.250427   \n",
       "74  10971.614258   8803.198242  34236.382812   796.223206  578.648254   \n",
       "\n",
       "               배  \n",
       "0   30842.589844  \n",
       "1   30363.361328  \n",
       "2   31405.814453  \n",
       "3   30517.808594  \n",
       "4   30110.117188  \n",
       "..           ...  \n",
       "70  30239.214844  \n",
       "71  31099.503906  \n",
       "72  34598.562500  \n",
       "73  33710.242188  \n",
       "74  34217.808594  \n",
       "\n",
       "[75 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('data/train/train.csv')\n",
    "tmp.groupby('품목명')['평균가격(원)'].describe().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "품목명 = '무'\n",
    "train_data, scaler = process_data(\"data/train/train.csv\", \"data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \"data/train/meta/TRAIN_전국도매_2018-2021.csv\", 품목명)\n",
    "scaler = 품목별_scalers[품목명]['평균가격(원)']\n",
    "tmp = minmax_inverse_transform(train_data['평균가격(원)'], scaler, is_train=False)\n",
    "tmp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "test_file = f\"data/test/TEST_{i:02d}.csv\"\n",
    "산지공판장_file = f\"data/test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "전국도매_file = f\"data/test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "\n",
    "test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scalers=품목별_scalers[품목명])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train/train.csv')\n",
    "t = train_df[train_df['품목명']==품목명]\n",
    "t['평균가격(원)'].describe().astype(int)\n",
    "\n",
    "# plt.hist(t['평균가격(원)'], bins=50)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.boxplot(t['평균가격(원)'])\n",
    "plt.show()\n",
    "plt.boxplot(np.log1p(t['평균가격(원)']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t['평균가격(원)']>10000000]\n",
    "t.groupby('거래단위')['평균가격(원)'].mean().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('data/sample_submission.csv')\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv('out/baseline_submission.csv')\n",
    "# sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
