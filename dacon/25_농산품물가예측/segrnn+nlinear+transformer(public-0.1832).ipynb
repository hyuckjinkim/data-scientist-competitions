{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농산물 가격 예측을 위한 AI 모델 개발 \n",
    "- '2024 농산물 가격 예측 AI 경진대회'는 데이터와 AI 기술을 활용하여 농산물 가격 예측 능력을 향상시키는 것을 목표로 합니다.<br>  이 대회는 농업 분야의 복잡한 시계열 데이터를 효율적으로 분석하고 예측할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br> <br>\n",
    "- 이 대회의 궁극적 목적은 참가자들의 시계열 데이터 분석 및 예측 역량을 강화하고, <br> AI 기술이 실제 농산물 가격 예측과 관련 정책 결정에 어떻게 기여할 수 있는지 탐구하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_dir = \"g:/My Drive/Storage/Github/hyuckjinkim\"\n",
    "sys.path.append(lib_dir)\n",
    "\n",
    "from lib.python.graph import MatplotlibFontManager\n",
    "fm = MatplotlibFontManager()\n",
    "fm.set_korean_font(check=False)\n",
    "\n",
    "from lib.python.torch import seed_everything\n",
    "from lib.python.torch.build_model import train, predict\n",
    "from lib.python.log import get_logger\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# train_df = pd.read_csv('data/train/train.csv')\n",
    "\n",
    "# train_meta1_df = pd.read_csv('data/train/meta/TRAIN_산지공판장_2018-2021.csv')\n",
    "# train_meta1_df.drop(['품목코드','품종코드','공판장코드'], axis=1, inplace=True)\n",
    "\n",
    "# train_meta2_df = pd.read_csv('data/train/meta/TRAIN_전국도매_2018-2021.csv')\n",
    "# train_meta2_df.drop(['품목코드','품종코드','시장코드']  , axis=1, inplace=True)\n",
    "\n",
    "# train_df.head(2) # ['평년 평균가격(원)','평균가격(원)']\n",
    "# train_meta1_df.head(2)\n",
    "# train_meta2_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from types import SimpleNamespace\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for Feature Engineering\n",
    "- 타겟의 필터 조건을 제외한 메타데이터의 필터 조건은 참가자들 각자의 기준에 맞춰 자유롭게 사용가능 \n",
    "- 밑의 필터 조건은 임의로 제공하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_convert(data):\n",
    "    data['연도'] -= 2018\n",
    "\n",
    "    offset = 0.1\n",
    "    map_dict = {'상순':offset, '중순':offset+1/3, '하순':offset+2/3}\n",
    "    data['연도'] += data['시점'].str.extract(r'(상순|중순|하순)')[0].map(map_dict)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scalers=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 품목코드, 품종코드, 공판장코드, 시장코드 제거\n",
    "    산지공판장.drop(['품목코드','품종코드','공판장코드'], axis=1, inplace=True)\n",
    "    전국도매  .drop(['품목코드','품종코드','시장코드']  , axis=1, inplace=True)\n",
    "\n",
    "    # 연도에 상/중/하순에 대한 정보도 추가\n",
    "    산지공판장 = year_convert(산지공판장)\n",
    "    전국도매 = year_convert(전국도매)\n",
    "\n",
    "    # 이상값(0이하) 처리\n",
    "    for col in ['전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR']:\n",
    "        loc = 전국도매[col] < 0\n",
    "        전국도매.loc[loc,col] = 0\n",
    "\n",
    "    # log변환\n",
    "    raw_cols = ['평년 평균가격(원)', '평균가격(원)']\n",
    "    산지공판장_cols =  ['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '중간가(원/kg)', '최저가(원/kg)', '최고가(원/kg)', '경매 건수', \n",
    "                       '전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR', '평년 평균가격(원) Common Year SOON']\n",
    "    전국도매_cols = ['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '중가(60%) 평균가 ', '저가(20%) 평균가', '중간가(원/kg)', '최저가(원/kg)',\n",
    "                    '최고가(원/kg)', '경매 건수', '전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR', '평년 평균가격(원) Common Year SOON']\n",
    "    for col in raw_cols: raw_data[col] = np.log1p(raw_data[col])\n",
    "    for col in 산지공판장_cols: 산지공판장[col] = np.log1p(산지공판장[col])\n",
    "    for col in 전국도매_cols: 전국도매[col] = np.log1p(전국도매[col])\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # 다른 품종에 대한 파생변수 생성\n",
    "    other_data = raw_품목[~target_mask]\n",
    "    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "        temp_df = other_data[mask]\n",
    "        for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "    # 공판장 데이터 처리\n",
    "    if conditions[품목명]['공판장']:\n",
    "        filtered_공판장 = 산지공판장\n",
    "        for key, value in conditions[품목명]['공판장'].items():\n",
    "            filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "        filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # 도매 데이터 처리\n",
    "    if conditions[품목명]['도매']:\n",
    "        filtered_도매 = 전국도매\n",
    "        for key, value in conditions[품목명]['도매'].items():\n",
    "            filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "        filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # 정규화 적용\n",
    "    if scalers is None:\n",
    "        scalers = {}\n",
    "        for col in numeric_columns:\n",
    "            scaler = MinMaxScaler()\n",
    "            filtered_data[col] = scaler.fit_transform(filtered_data[col].values.reshape(-1,1))\n",
    "            scalers[col] = scaler\n",
    "    else:\n",
    "        for col in numeric_columns:\n",
    "            scaler = scalers[col]\n",
    "            filtered_data[col] = scaler.transform(filtered_data[col].values.reshape(-1,1))\n",
    "\n",
    "    return filtered_data, scalers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturePriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        self.price_column = '평균가격(원)'\n",
    "        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        self.sequences = []\n",
    "        if not self.is_test:\n",
    "            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n",
    "                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n",
    "                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n",
    "                self.sequences.append((x, y))\n",
    "        else:\n",
    "            self.sequences = [self.data[self.numeric_columns].values]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            x, y = self.sequences[idx]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        else:\n",
    "            return torch.FloatTensor(self.sequences[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinformerSelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, num_heads, k=32, dropout=0.1):\n",
    "        super(LinformerSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.k = k  # Low-rank projection dimension\n",
    "        assert self.head_dim * num_heads == input_dim, \"input_dim must be divisible by num_heads\"\n",
    "\n",
    "        # Linear projections for queries, keys, and values\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Low-rank projection matrices for keys and values\n",
    "        self.proj_key = nn.Linear(seq_len, seq_len)  # 수정: 투영 차원을 원래 시퀀스 길이와 일치시킴\n",
    "        self.proj_value = nn.Linear(seq_len, seq_len)  # 수정: 투영 차원을 맞춤\n",
    "\n",
    "        # Output projection\n",
    "        self.out = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, _ = x.size()\n",
    "\n",
    "        # Project to queries, keys, and values\n",
    "        queries = self.query(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        keys = self.key(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = self.value(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Apply low-rank projection to keys and values\n",
    "        keys = self.proj_key(keys).transpose(1, 2)  # 투영 후 크기 맞춤\n",
    "        values = self.proj_value(values).transpose(1, 2)  # 투영 후 크기 맞춤\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(queries, keys.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # Attention output\n",
    "        output = torch.matmul(attn, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seq_len, self.num_heads * self.head_dim)\n",
    "\n",
    "        return self.out(output)\n",
    "\n",
    "class PerformerSelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, kernel_size=32, dropout=0.1):\n",
    "        super(PerformerSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = input_dim // num_heads\n",
    "        self.kernel_size = kernel_size\n",
    "        assert self.head_dim * num_heads == input_dim, \"input_dim must be divisible by num_heads\"\n",
    "\n",
    "        # Linear projections for queries, keys, and values\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Output projection\n",
    "        self.out = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def feature_map(self, x):\n",
    "        # Random Fourier feature mapping (or kernel approximation)\n",
    "        return torch.exp(-x ** 2 / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, _ = x.size()\n",
    "\n",
    "        # Project to queries, keys, and values\n",
    "        queries = self.feature_map(self.query(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2))\n",
    "        keys = self.feature_map(self.key(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2))\n",
    "        values = self.value(x).view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Perform efficient attention\n",
    "        kv = torch.einsum('bhse,bhsc->bhsec', keys, values)\n",
    "        qkv = torch.einsum('bhse,bhsec->bhsc', queries, kv)\n",
    "\n",
    "        # Attention output\n",
    "        output = qkv.transpose(1, 2).contiguous().view(bsz, seq_len, self.num_heads * self.head_dim)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        periodic_dim = (input_dim-1) // 2\n",
    "        self.linear = nn.Linear(input_dim, input_dim - periodic_dim*2)\n",
    "        self.periodic = nn.Linear(input_dim, periodic_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        linear_out = self.linear(x)\n",
    "        periodic_sin = torch.sin(self.periodic(x))\n",
    "        periodic_cos = torch.cos(self.periodic(x))  # cosine 추가\n",
    "        periodic_out = torch.cat([periodic_sin, periodic_cos], dim=-1)  # sin과 cos 결합\n",
    "        return torch.cat([linear_out, periodic_out], dim=-1)\n",
    "\n",
    "# Define Transformer Encoder Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dropout, method='multihead', seq_len=None):\n",
    "        super().__init__()\n",
    "        self.method = method\n",
    "        \n",
    "        if method == 'multihead':\n",
    "            self.attention = nn.MultiheadAttention(input_dim, num_heads, dropout=dropout)\n",
    "        elif method == 'linformer':\n",
    "            self.attention = LinformerSelfAttention(input_dim, seq_len, num_heads, dropout=dropout)\n",
    "        elif method == 'performer':\n",
    "            self.attention = PerformerSelfAttention(input_dim, num_heads, dropout=dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4 * input_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * input_dim, input_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.method=='multihead':\n",
    "            attended, _ = self.attention(x, x, x) # 1. Attention\n",
    "        else:\n",
    "            attended = self.attention(x)\n",
    "        x = self.norm1(attended + x)              # 2. 잔차 연결 + Layer Normalization\n",
    "        feedforward = self.ff(x)                  # 3. Feedforward + BatchNorm 적용\n",
    "        x = self.norm2(feedforward + x)           # 4. 잔차 연결 + Layer Normalization\n",
    "        return x\n",
    "\n",
    "# Define main model architecture\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.max_len = 10\n",
    "\n",
    "        self.time2vec = Time2Vec(config.d_model)\n",
    "        self.embedding = nn.Linear(config.d_model, config.hidden_size)\n",
    "        self.position_encoding = self.generate_position_encoding(config.hidden_size, self.max_len)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(config.hidden_size, config.num_heads, config.dropout, config.method, config.seq_len) \n",
    "            for _ in range(config.num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.hidden_size // 2, config.pred_len)\n",
    "        )\n",
    "\n",
    "    def generate_position_encoding(self, hidden_size, max_len):\n",
    "        pe = torch.zeros(max_len, hidden_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-np.log(10000.0) / hidden_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, s, f = x.shape\n",
    "        x = self.time2vec(x)\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.position_encoding[:, :s, :].to(x.device)\n",
    "        x = self.dropout(x)\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/lss-1138/SegRNN/blob/main/models/SegRNN.py\n",
    "from lib.python.torch.models.SegRNN import Model as SegRNNModel\n",
    "from lib.python.torch.models.NLinear import Model as NLinearModel\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.segrnn_layer = SegRNNModel(config)\n",
    "        self.nlinear_layer = NLinearModel(config.seq_len, config.pred_len, config.channels, config.individual, config.dropout)\n",
    "        self.transformer_layer = TimeSeriesTransformer(config)\n",
    "\n",
    "        self.fc_segrnn = nn.Linear(config.d_model, 1)\n",
    "        self.fc_nlinear = nn.Linear(config.d_model, 1)\n",
    "\n",
    "        self.fc = nn.Linear(3*config.pred_len, config.pred_len)\n",
    "        self.layernorm = nn.LayerNorm(3*config.pred_len)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        segrnn_out = self.fc_segrnn(self.segrnn_layer(x)).squeeze(-1)\n",
    "        nlinear_out = self.fc_nlinear(self.nlinear_layer(x)).squeeze(-1)\n",
    "        transformer_out = self.transformer_layer(x)\n",
    "\n",
    "        mixed = torch.cat([segrnn_out, nlinear_out, transformer_out], dim=-1)\n",
    "        mixed = self.layernorm(mixed)\n",
    "        mixed = self.dropout(mixed)\n",
    "        mixed = self.fc(mixed)\n",
    "\n",
    "        return mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(true,pred):\n",
    "    true, pred = np.array(true), np.array(pred)\n",
    "    return np.mean(np.abs(true - pred) / true)\n",
    "\n",
    "def minmax_inverse_transform(x, scaler, is_train=True):\n",
    "    origin = scaler.data_min_[0] + x * (scaler.data_max_[0] - scaler.data_min_[0])\n",
    "    origin = torch.expm1(origin) if is_train else np.expm1(origin)\n",
    "    return origin\n",
    "\n",
    "def variance_threshold_select(data, threshold=0.01, ignore_features=list()):\n",
    "    cols = data.select_dtypes(include=[np.number]).columns\n",
    "    cols = list(set(cols)-set(ignore_features))\n",
    "\n",
    "    del_features = []\n",
    "    for col in cols:\n",
    "        variance = train_data[col].std()**2\n",
    "        if variance<threshold:\n",
    "            del_features.append(col)\n",
    "    \n",
    "    return del_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(best_model, loader, device, inverse_transform):\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    \n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for data,label in loader:\n",
    "            data = data.float().to(device)\n",
    "\n",
    "            output = best_model(data)\n",
    "            output = inverse_transform(output)\n",
    "            output = output.cpu().numpy().tolist()\n",
    "\n",
    "            label  = inverse_transform(label)\n",
    "            label = label.cpu().numpy().tolist()\n",
    "\n",
    "            true_list += label\n",
    "            pred_list += output\n",
    "\n",
    "    return true_list, pred_list\n",
    "\n",
    "def inference(best_model, loader, device, inverse_transform):\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    \n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.float().to(device)\n",
    "\n",
    "            output = best_model(data)\n",
    "            output = inverse_transform(output)\n",
    "            output = output.cpu().numpy().tolist()\n",
    "\n",
    "            pred_list += output\n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 5e-4, #0.001,\n",
    "    \"epoch\": 10_000,\n",
    "    \"batch_size\": 16,\n",
    "    \"output_size\": 3,\n",
    "    \"weight_decay\": 5e-3,\n",
    "    \"test_size\": 0.2,\n",
    "    \"seed\": 42,\n",
    "    \"threshold\": 0.01,\n",
    "    \"device\": 'cpu',\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"seq_len\": 9,\n",
    "    \"pred_len\": 3,\n",
    "    \"dropout\": 0.5,\n",
    "\n",
    "    # SegRNN\n",
    "    \"rnn_type\": 'rnn', # rnn, gru, lstm\n",
    "    \"dec_way\": 'pmf',  # rmf, pmf\n",
    "    \"seg_len\": 3,\n",
    "    \"channel_id\": False,\n",
    "    \"revin\": True,\n",
    "\n",
    "    # NLinear\n",
    "    \"channels\": 3,\n",
    "    \"individual\": True,\n",
    "\n",
    "    # TimeSeriesTransfromer\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 3,\n",
    "    \"num_heads\": 8,\n",
    "    \"method\": 'multihead', # multihead, performer, linformer\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "MODEL_CFG = SimpleNamespace(**model_config)\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================================================================================================\n",
      "> [01/10] 건고추\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 76758.5837, val_loss: 38070.9482, best: 34042.0977(99), elapsed: 44.7s, total: 44.7s, remaining: 4422.5s\n",
      " [00200/10000] tr_loss: 47612.5971, val_loss: 27980.0840, best: 26224.3643(197), elapsed: 39.7s, total: 84.3s, remaining: 3886.2s\n",
      " [00300/10000] tr_loss: 42750.1705, val_loss: 28739.5156, best: 24078.4707(261), elapsed: 37.9s, total: 122.2s, remaining: 3673.4s\n",
      " [00400/10000] tr_loss: 44975.6641, val_loss: 25798.6953, best: 24078.4707(261), elapsed: 37.8s, total: 160.0s, remaining: 3627.8s\n",
      "<Stopped> [00461/10000] tr_loss: 44152.1914, val_loss: 25207.4170, best: 24078.4707(261), elapsed: 23.5s, total: 183.5s, remaining: 2243.9s\n",
      "<Score> train_nmae=0.0407, val_nmae=0.0462\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [02/10] 사과\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 3047.6153, val_loss: 1909.0969, best: 1759.9404(97), elapsed: 50.1s, total: 50.1s, remaining: 4957.8s\n",
      " [00200/10000] tr_loss: 2291.4347, val_loss: 1529.0728, best: 1473.1660(198), elapsed: 44.5s, total: 94.6s, remaining: 4364.3s\n",
      " [00300/10000] tr_loss: 1947.1517, val_loss: 1382.8323, best: 1312.4364(288), elapsed: 43.6s, total: 138.2s, remaining: 4231.0s\n",
      " [00400/10000] tr_loss: 1774.9800, val_loss: 1342.0410, best: 1301.7156(354), elapsed: 41.9s, total: 180.1s, remaining: 4019.9s\n",
      " [00500/10000] tr_loss: 1668.1253, val_loss: 1303.9549, best: 1293.1938(473), elapsed: 42.2s, total: 222.3s, remaining: 4005.6s\n",
      " [00600/10000] tr_loss: 1855.0714, val_loss: 1301.1403, best: 1293.1938(473), elapsed: 42.9s, total: 265.1s, remaining: 4030.7s\n",
      "<Stopped> [00673/10000] tr_loss: 1570.0564, val_loss: 1296.7965, best: 1293.1938(473), elapsed: 32.4s, total: 297.5s, remaining: 3021.2s\n",
      "<Score> train_nmae=0.0416, val_nmae=0.0537\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [03/10] 감자\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 10369.9298, val_loss: 7467.1709, best: 7443.9844(99), elapsed: 68.7s, total: 68.7s, remaining: 6805.2s\n",
      "*[00200/10000] tr_loss: 7288.6127, val_loss: 5204.7097, best: 5204.7097(200), elapsed: 70.3s, total: 139.0s, remaining: 6886.7s\n",
      " [00300/10000] tr_loss: 5685.9360, val_loss: 4952.9233, best: 4791.3157(271), elapsed: 69.9s, total: 209.0s, remaining: 6778.9s\n",
      " [00400/10000] tr_loss: 5487.3182, val_loss: 5025.7429, best: 4791.3157(271), elapsed: 73.2s, total: 282.2s, remaining: 7026.1s\n",
      "<Stopped> [00471/10000] tr_loss: 5932.8514, val_loss: 5004.1580, best: 4791.3157(271), elapsed: 53.9s, total: 336.2s, remaining: 5140.3s\n",
      "<Score> train_nmae=0.1205, val_nmae=0.1510\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [04/10] 배\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 4863.4116, val_loss: 3223.3102, best: 3162.7816(97), elapsed: 55.9s, total: 55.9s, remaining: 5535.3s\n",
      " [00200/10000] tr_loss: 3797.5325, val_loss: 3091.1345, best: 2674.9592(172), elapsed: 45.6s, total: 101.5s, remaining: 4466.4s\n",
      " [00300/10000] tr_loss: 3466.6067, val_loss: 2954.3265, best: 2677.0891(213), elapsed: 49.5s, total: 151.0s, remaining: 4805.9s\n",
      " [00400/10000] tr_loss: 2909.4643, val_loss: 2934.1521, best: 2677.0891(213), elapsed: 59.2s, total: 210.2s, remaining: 5683.4s\n",
      "<Stopped> [00413/10000] tr_loss: 3351.8164, val_loss: 2963.7991, best: 2677.0891(213), elapsed: 8.1s, total: 218.3s, remaining: 774.7s\n",
      "<Score> train_nmae=0.0703, val_nmae=0.0794\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [05/10] 깐마늘(국산)\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[00100/10000] tr_loss: 21946.2065, val_loss: 13425.5127, best: 13425.5127(100), elapsed: 64.7s, total: 64.7s, remaining: 6406.5s\n",
      " [00200/10000] tr_loss: 16965.5636, val_loss: 8970.8159, best: 8492.2361(180), elapsed: 57.0s, total: 121.8s, remaining: 5586.0s\n",
      " [00300/10000] tr_loss: 12272.8365, val_loss: 8156.0347, best: 7341.2732(290), elapsed: 57.7s, total: 179.5s, remaining: 5594.7s\n",
      " [00400/10000] tr_loss: 10326.6293, val_loss: 7671.9114, best: 6460.4695(364), elapsed: 58.5s, total: 238.0s, remaining: 5612.2s\n",
      " [00500/10000] tr_loss: 10046.0997, val_loss: 6655.6423, best: 6460.4695(364), elapsed: 57.5s, total: 295.5s, remaining: 5467.2s\n",
      "<Stopped> [00564/10000] tr_loss: 8485.6140, val_loss: 6952.0286, best: 6460.4695(364), elapsed: 40.9s, total: 336.4s, remaining: 3860.0s\n",
      "<Score> train_nmae=0.0618, val_nmae=0.0691\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [06/10] 무\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 3684.9525, val_loss: 3412.4264, best: 3228.7269(99), elapsed: 103.6s, total: 103.6s, remaining: 10258.9s\n",
      " [00200/10000] tr_loss: 2837.1828, val_loss: 2769.2308, best: 2741.8807(199), elapsed: 90.7s, total: 194.3s, remaining: 8889.7s\n",
      " [00300/10000] tr_loss: 2424.5459, val_loss: 2767.0499, best: 2647.0545(206), elapsed: 86.6s, total: 280.9s, remaining: 8398.2s\n",
      " [00400/10000] tr_loss: 2386.8145, val_loss: 2785.1895, best: 2647.0545(206), elapsed: 88.5s, total: 369.4s, remaining: 8493.5s\n",
      "<Stopped> [00406/10000] tr_loss: 2120.9371, val_loss: 2790.9668, best: 2647.0545(206), elapsed: 5.2s, total: 374.6s, remaining: 497.6s\n",
      "<Score> train_nmae=0.1370, val_nmae=0.1833\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [07/10] 상추\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 234.5688, val_loss: 211.7957, best: 210.0472(99), elapsed: 64.9s, total: 64.9s, remaining: 6426.1s\n",
      " [00200/10000] tr_loss: 216.4630, val_loss: 184.2031, best: 175.9986(172), elapsed: 60.1s, total: 125.0s, remaining: 5893.7s\n",
      " [00300/10000] tr_loss: 174.6658, val_loss: 173.0364, best: 170.5498(276), elapsed: 58.1s, total: 183.1s, remaining: 5632.9s\n",
      " [00400/10000] tr_loss: 159.0591, val_loss: 166.6654, best: 162.6926(339), elapsed: 57.8s, total: 240.9s, remaining: 5544.8s\n",
      " [00500/10000] tr_loss: 160.6029, val_loss: 165.9341, best: 162.6926(339), elapsed: 56.9s, total: 297.8s, remaining: 5404.5s\n",
      "<Stopped> [00539/10000] tr_loss: 137.9401, val_loss: 165.8026, best: 162.6926(339), elapsed: 22.4s, total: 320.2s, remaining: 2123.5s\n",
      "<Score> train_nmae=0.0896, val_nmae=0.1304\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [08/10] 배추\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[00100/10000] tr_loss: 2872.7081, val_loss: 2109.4816, best: 2109.4816(100), elapsed: 80.9s, total: 80.9s, remaining: 8011.8s\n",
      " [00200/10000] tr_loss: 2361.6752, val_loss: 1630.4719, best: 1632.4078(178), elapsed: 81.3s, total: 162.3s, remaining: 7969.8s\n",
      " [00300/10000] tr_loss: 1666.5940, val_loss: 1662.0756, best: 1522.8973(252), elapsed: 79.2s, total: 241.5s, remaining: 7678.1s\n",
      " [00400/10000] tr_loss: 1807.7002, val_loss: 1686.4649, best: 1522.8973(252), elapsed: 75.3s, total: 316.8s, remaining: 7227.4s\n",
      "<Stopped> [00452/10000] tr_loss: 1767.5686, val_loss: 1705.9934, best: 1522.8973(252), elapsed: 38.8s, total: 355.5s, remaining: 3700.4s\n",
      "<Score> train_nmae=0.1565, val_nmae=0.2262\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [09/10] 양파\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 224.1276, val_loss: 150.9131, best: 148.3596(98), elapsed: 70.8s, total: 70.8s, remaining: 7011.6s\n",
      " [00200/10000] tr_loss: 176.5981, val_loss: 110.7478, best: 110.3575(199), elapsed: 72.9s, total: 143.8s, remaining: 7148.5s\n",
      " [00300/10000] tr_loss: 123.5330, val_loss: 110.0535, best: 105.5436(291), elapsed: 66.4s, total: 210.2s, remaining: 6444.5s\n",
      " [00400/10000] tr_loss: 127.2916, val_loss: 108.5936, best: 106.1566(377), elapsed: 67.7s, total: 277.9s, remaining: 6499.9s\n",
      " [00500/10000] tr_loss: 135.2917, val_loss: 111.2782, best: 106.1566(377), elapsed: 65.3s, total: 343.3s, remaining: 6207.2s\n",
      "<Stopped> [00577/10000] tr_loss: 113.4396, val_loss: 111.3820, best: 106.1566(377), elapsed: 50.4s, total: 393.6s, remaining: 4748.3s\n",
      "<Score> train_nmae=0.0871, val_nmae=0.1534\n",
      "\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [10/10] 대파\n",
      "======================================================================================================================================================\n",
      "\n",
      " [00100/10000] tr_loss: 502.1814, val_loss: 349.4672, best: 334.6932(87), elapsed: 92.8s, total: 92.8s, remaining: 9187.4s\n",
      " [00200/10000] tr_loss: 422.7166, val_loss: 329.0653, best: 313.0066(193), elapsed: 86.3s, total: 179.1s, remaining: 8455.3s\n",
      " [00300/10000] tr_loss: 540.1287, val_loss: 319.1663, best: 301.7814(214), elapsed: 84.9s, total: 263.9s, remaining: 8231.0s\n",
      " [00400/10000] tr_loss: 394.5037, val_loss: 319.5232, best: 301.7814(214), elapsed: 83.2s, total: 347.1s, remaining: 7982.5s\n",
      "<Stopped> [00414/10000] tr_loss: 428.8060, val_loss: 318.0153, best: 301.7814(214), elapsed: 12.3s, total: 359.4s, remaining: 1176.1s\n",
      "<Score> train_nmae=0.1678, val_nmae=0.1793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logger = get_logger(save_path='log/TimeSeriesTransformer_log.log')\n",
    "# trace_func = logger.info\n",
    "trace_func = print\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "품목별_scalers = {}\n",
    "품목별_delcols = {}\n",
    "품목별_hyperparams = {}\n",
    "\n",
    "train_nmae_list = []\n",
    "val_nmae_list = []\n",
    "\n",
    "for i, 품목명 in enumerate(품목_리스트):\n",
    "    model_path = f'models/SegRNN_{품목명}.pth'\n",
    "    trace_func('')\n",
    "    trace_func('='*150)\n",
    "    trace_func(f'> [{i+1:02d}/{len(품목_리스트)}] {품목명}')\n",
    "    trace_func('='*150)\n",
    "    trace_func('')\n",
    "\n",
    "    # preprocessing\n",
    "    train_data, scalers = process_data(\"data/train/train.csv\", \"data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \"data/train/meta/TRAIN_전국도매_2018-2021.csv\", 품목명)\n",
    "    품목별_scalers[품목명] = scalers\n",
    "    \n",
    "    # 분산이 threshold보다 작은 컬럼 제거\n",
    "    del_cols = variance_threshold_select(train_data, threshold=CFG.threshold, ignore_features=['평균가격(원)'])\n",
    "    train_data.drop(del_cols, axis=1, inplace=True)\n",
    "    품목별_delcols[품목명] = del_cols\n",
    "\n",
    "    # train, validation split\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "    tr_data, val_data = train_test_split(dataset, test_size=CFG.test_size, random_state=CFG.seed, shuffle=True)\n",
    "    train_loader = DataLoader(tr_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    # define model\n",
    "    model_cfg = deepcopy(MODEL_CFG)\n",
    "    model_cfg.enc_in = len(dataset.numeric_columns)\n",
    "    model_cfg.d_model = len(dataset.numeric_columns)\n",
    "    품목별_hyperparams[품목명] = model_cfg\n",
    "    model = HybridModel(model_cfg).to(CFG.device)\n",
    "\n",
    "    criterion = nn.HuberLoss() #nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50)\n",
    "    # scheduler = None\n",
    "\n",
    "    price_scaler = 품목별_scalers[품목명][dataset.price_column]\n",
    "    inverse_transform = lambda x: minmax_inverse_transform(x, price_scaler)\n",
    "    # inverse_transform = None\n",
    "\n",
    "    # train\n",
    "    best_model = train(\n",
    "        model, optimizer, train_loader, val_loader, CFG.epoch,\n",
    "        early_stopping=True, early_stopping_patience=200, early_stopping_verbose=False,\n",
    "        device=CFG.device, scheduler=scheduler, metric_period=100, \n",
    "        verbose=True, save_model_path=model_path,\n",
    "        inverse_transform=inverse_transform,\n",
    "    )\n",
    "\n",
    "    # scoring\n",
    "    true, pred = predict(best_model, train_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "    train_nmae = nmae(true,pred)\n",
    "    true, pred = predict(best_model, val_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "    val_nmae = nmae(true,pred)\n",
    "    trace_func(f'<Score> {train_nmae=:.4f}, {val_nmae=:.4f}')\n",
    "    trace_func('')\n",
    "\n",
    "    train_nmae_list.append(train_nmae)\n",
    "    val_nmae_list.append(val_nmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_nmae=0.0973, val_nmae=0.1272'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'train_nmae={np.mean(train_nmae_list):.4f}, val_nmae={np.mean(val_nmae_list):.4f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/scalers.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(품목별_scalers, pickle_file)\n",
    "\n",
    "with open('out/delcols.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(품목별_delcols, pickle_file)\n",
    "\n",
    "with open('out/hyperparams.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(품목별_hyperparams, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true, pred = predict(best_model, train_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "# print(criterion(torch.tensor(true), torch.tensor(pred)).item())\n",
    "# true[:5], pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/scalers.pkl', 'rb') as pickle_file:\n",
    "    품목별_scalers = pickle.load(pickle_file)\n",
    "\n",
    "with open('out/delcols.pkl', 'rb') as pickle_file:\n",
    "    품목별_delcols = pickle.load(pickle_file)\n",
    "\n",
    "with open('out/hyperparams.pkl', 'rb') as pickle_file:\n",
    "    품목별_hyperparams = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "건고추 ['양건_30 kg_상품_평균가격(원)', '화건_30 kg_중품_평균가격(원)', '양건_30 kg_중품_평균가격(원)']\n",
      "사과 []\n",
      "감자 ['홍감자_10키로상자_상_평년 평균가격(원)', '감자 조풍_20키로상자_특_평년 평균가격(원)', '감자_20키로상자_특_평년 평균가격(원)', '홍감자_10키로상자_중_평년 평균가격(원)', '감자_20키로상자_상_평년 평균가격(원)', '감자 조풍_20키로상자_상_평균가격(원)', '감자_20키로상자_중_평년 평균가격(원)', '감자 조풍_20키로상자_하_평년 평균가격(원)', '홍감자_10키로상자_특_평년 평균가격(원)', '감자 수미(햇)_20키로상자_중_평년 평균가격(원)', '홍감자_10키로상자_하_평균가격(원)', '감자 수미(저장)_20키로상자_특_평년 평균가격(원)', '홍감자_10키로상자_특_평균가격(원)', '감자 조풍_20키로상자_하_평균가격(원)', '홍감자_10키로상자_상_평균가격(원)', '홍감자_10키로상자_하_평년 평균가격(원)', '감자 수미(햇)_20키로상자_상_평년 평균가격(원)', '감자 수미(저장)_20키로상자_하_평년 평균가격(원)', '감자 조풍_20키로상자_상_평년 평균가격(원)', '감자 수미(햇)_20키로상자_특_평년 평균가격(원)', '감자_20키로상자_하_평년 평균가격(원)', '감자 수미(햇)_20키로상자_하_평년 평균가격(원)', '감자 두백_20키로상자_상_평년 평균가격(원)', '감자 수미(저장)_20키로상자_중_평년 평균가격(원)', '감자 조풍_20키로상자_중_평균가격(원)', '감자 조풍_20키로상자_중_평년 평균가격(원)', '홍감자_10키로상자_중_평균가격(원)', '감자 두백_20키로상자_하_평년 평균가격(원)', '감자 수입_23키로상자_상_평년 평균가격(원)', '감자 수미(저장)_20키로상자_상_평년 평균가격(원)', '감자 조풍_20키로상자_특_평균가격(원)', '감자 두백_20키로상자_특_평년 평균가격(원)', '감자 두백_20키로상자_중_평년 평균가격(원)']\n",
      "배 ['공판장_등급코드']\n",
      "깐마늘(국산) ['평년 평균가격(원)', '깐마늘(국산)_20 kg_중품_평년 평균가격(원)']\n",
      "무 ['다발무_1000키로_중_평균가격(원)', '다발무_1000키로_하_평년 평균가격(원)', '다발무_1000키로_특_평균가격(원)', '다발무_5000키로_하_평균가격(원)', '다발무_8톤트럭_상_평년 평균가격(원)', '무_20키로상자_특_평년 평균가격(원)', '다발무_5000키로_중_평년 평균가격(원)', '다발무_1000키로_상_평균가격(원)', '다발무_8톤트럭_중_평년 평균가격(원)', '다발무_10키로_상_평년 평균가격(원)', '다발무_10키로_중_평년 평균가격(원)', '다발무_1000키로_상_평년 평균가격(원)', '도매_평년 평균가격(원) Common Year SOON', '다발무_5000키로_특_평년 평균가격(원)', '무_20키로상자_중_평년 평균가격(원)', '다발무_8톤트럭_하_평년 평균가격(원)', '다발무_1000키로_하_평균가격(원)', '다발무_5000키로_상_평균가격(원)', '열무_4키로상자_중_평년 평균가격(원)', '다발무_10키로_특_평년 평균가격(원)', '공판장_전년 평균가격(원) PreVious YeaR', '무_20키로상자_하_평년 평균가격(원)', '공판장_등급코드', '다발무_10키로_하_평년 평균가격(원)', '다발무_1000키로_특_평년 평균가격(원)', '다발무_5000키로_특_평균가격(원)', '다발무_5000키로_중_평균가격(원)', '다발무_5000키로_상_평년 평균가격(원)', '다발무_1000키로_중_평년 평균가격(원)', '평년 평균가격(원)', '다발무_5000키로_하_평년 평균가격(원)']\n",
      "상추 ['공판장_전달 평균가격(원) PreVious MMonth', '공판장_전년 평균가격(원) PreVious YeaR', '공판장_평년 평균가격(원) Common Year SOON', '도매_총반입량(kg)', '공판장_전순 평균가격(원) PreVious SOON', '도매_경매 건수']\n",
      "배추 ['쌈배추_1키로상자_중_평년 평균가격(원)', '쌈배추_1키로상자_상_평년 평균가격(원)', '봄동배추_15키로상자_하_평년 평균가격(원)', '도매_평년 평균가격(원) Common Year SOON', '봄동배추_15키로상자_중_평년 평균가격(원)', '얼갈이배추_8키로상자_상_평년 평균가격(원)', '쌈배추_1키로상자_특_평년 평균가격(원)', '얼갈이배추_8키로상자_하_평년 평균가격(원)', '얼갈이배추_8키로상자_중_평년 평균가격(원)', '쌈배추_1키로상자_하_평년 평균가격(원)']\n",
      "양파 ['양파(햇)_15키로_특_평년 평균가격(원)', '조생양파_15키로_중_평균가격(원)', '자주양파_1키로_하_평년 평균가격(원)', '양파(햇)_20키로_특_평년 평균가격(원)', '양파_15키로_중_평년 평균가격(원)', '양파_12키로_중_평년 평균가격(원)', '양파_15키로_하_평년 평균가격(원)', '조생양파_12키로_상_평년 평균가격(원)', '저장양파_20키로_특_평년 평균가격(원)', '조생양파_15키로_특_평년 평균가격(원)', '저장양파_15키로_특_평년 평균가격(원)', '저장양파_12키로_중_평년 평균가격(원)', '저장양파_15키로_하_평년 평균가격(원)', '양파_10키로_특_평년 평균가격(원)', '양파(햇)_20키로_하_평년 평균가격(원)', '조생양파_15키로_중_평년 평균가격(원)', '공판장_등급코드', '양파(햇)_12키로_상_평년 평균가격(원)', '조생양파_15키로_상_평균가격(원)', '양파_10키로_상_평년 평균가격(원)', '양파 수입_1키로_특_평년 평균가격(원)', '저장양파_20키로_하_평년 평균가격(원)', '양파(햇)_15키로_상_평년 평균가격(원)', '양파_10키로_하_평년 평균가격(원)', '조생양파_12키로_중_평균가격(원)', '저장양파_12키로_하_평년 평균가격(원)', '저장양파_15키로_중_평년 평균가격(원)', '양파(햇)_12키로_하_평년 평균가격(원)', '양파_12키로_특_평년 평균가격(원)', '조생양파_12키로_상_평균가격(원)', '조생양파_12키로_하_평균가격(원)', '도매_전순 평균가격(원) PreVious SOON', '양파(햇)_15키로_하_평년 평균가격(원)', '양파_10키로_중_평년 평균가격(원)', '자주양파_1키로_상_평년 평균가격(원)', '양파_12키로_하_평년 평균가격(원)', '저장양파_12키로_특_평년 평균가격(원)', '자주양파_1키로_특_평년 평균가격(원)', '자주양파_1키로_중_평년 평균가격(원)', '저장양파_12키로_상_평년 평균가격(원)', '조생양파_12키로_하_평년 평균가격(원)', '조생양파_15키로_하_평년 평균가격(원)', '저장양파_20키로_상_평년 평균가격(원)', '조생양파_15키로_특_평균가격(원)', '저장양파_20키로_중_평년 평균가격(원)', '양파(햇)_20키로_중_평년 평균가격(원)', '양파_15키로_특_평년 평균가격(원)', '조생양파_12키로_특_평균가격(원)', '양파(햇)_12키로_중_평년 평균가격(원)', '저장양파_15키로_상_평년 평균가격(원)', '양파(햇)_12키로_특_평년 평균가격(원)', '양파(햇)_15키로_중_평년 평균가격(원)', '조생양파_15키로_상_평년 평균가격(원)', '조생양파_15키로_하_평균가격(원)', '조생양파_12키로_특_평년 평균가격(원)', '양파_15키로_상_평년 평균가격(원)', '양파(햇)_20키로_상_평년 평균가격(원)', '양파_12키로_상_평년 평균가격(원)', '조생양파_12키로_중_평년 평균가격(원)']\n",
      "대파 ['대파(일반)_10키로묶음_상_평년 평균가격(원)', '대파(일반)_10키로묶음_특_평균가격(원)', '대파(일반)_10키로묶음_중_평년 평균가격(원)', '대파(일반)_10키로묶음_하_평균가격(원)', '대파(일반)_10키로묶음_상_평균가격(원)', '대파(일반)_10키로묶음_하_평년 평균가격(원)', '대파(일반)_10키로묶음_특_평년 평균가격(원)', '대파(일반)_10키로묶음_중_평균가격(원)', '대파 수입_10키로상자_상_평년 평균가격(원)']\n"
     ]
    }
   ],
   "source": [
    "for k,v in 품목별_delcols.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7607a21a049f4a2cb5d077e7b660cfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e250c4e43fa949c3968247ec8ba12706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baae6f474c5545578f46e6344fe8e9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b18fb4fff24f0580a54117ebf64bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ee9fd621884a91aeb75e84a2aa757e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0559b8c5a16c463b91c55f4b286c777a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1685ef0a65a94fd5b20f32e7f367e696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa7689d1a2f428fa83ff65fd25ca1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2506e76b1ac7493e8293f7b1182140d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986a8548b2fe4815956a3e5b7070c02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a13438e461046329e5307f528819dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "품목별_predictions = {}\n",
    "\n",
    "pbar_outer = tqdm(품목_리스트, position=0)\n",
    "for 품목명 in pbar_outer:\n",
    "    pbar_outer.set_description(품목명)\n",
    "    model_path = f'models/SegRNN_{품목명}.pth'\n",
    "\n",
    "    # define model\n",
    "    model = HybridModel(품목별_hyperparams[품목명]).to(CFG.device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # inference\n",
    "    품목_predictions = []\n",
    "    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n",
    "    for i in pbar_inner:\n",
    "        test_file = f\"data/test/TEST_{i:02d}.csv\"\n",
    "        산지공판장_file = f\"data/test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "        전국도매_file = f\"data/test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "\n",
    "        test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scalers=품목별_scalers[품목명])\n",
    "        test_data.drop(품목별_delcols[품목명], axis=1, inplace=True)\n",
    "        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        price_scaler = 품목별_scalers[품목명][test_dataset.price_column]\n",
    "        inverse_transform = lambda x: minmax_inverse_transform(x, price_scaler)\n",
    "\n",
    "        predictions = inference(model, test_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "        predictions = np.concatenate(predictions)\n",
    "        \n",
    "        if np.isnan(predictions).any():\n",
    "            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n",
    "            raise ValueError\n",
    "        else:\n",
    "            pbar_inner.set_postfix({\"상태\": \"정상\"})\n",
    "            품목_predictions.extend(predictions.flatten())\n",
    "\n",
    "    품목별_predictions[품목명] = 품목_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "for 품목명, predictions in 품목별_predictions.items():\n",
    "    sample_submission[품목명] = predictions\n",
    "\n",
    "# 결과 저장\n",
    "save_path = 'out/baseline_submission_11.csv'\n",
    "sample_submission.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시점</th>\n",
       "      <th>감자</th>\n",
       "      <th>건고추</th>\n",
       "      <th>깐마늘(국산)</th>\n",
       "      <th>대파</th>\n",
       "      <th>무</th>\n",
       "      <th>배추</th>\n",
       "      <th>사과</th>\n",
       "      <th>상추</th>\n",
       "      <th>양파</th>\n",
       "      <th>배</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00+1순</td>\n",
       "      <td>37638.113281</td>\n",
       "      <td>673574.8125</td>\n",
       "      <td>149820.968750</td>\n",
       "      <td>1490.765259</td>\n",
       "      <td>15799.216797</td>\n",
       "      <td>10445.493164</td>\n",
       "      <td>30310.820312</td>\n",
       "      <td>1165.058105</td>\n",
       "      <td>989.179993</td>\n",
       "      <td>34405.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00+2순</td>\n",
       "      <td>36364.687500</td>\n",
       "      <td>680988.4375</td>\n",
       "      <td>148774.593750</td>\n",
       "      <td>1533.887939</td>\n",
       "      <td>15262.559570</td>\n",
       "      <td>9474.362305</td>\n",
       "      <td>30380.162109</td>\n",
       "      <td>1137.806396</td>\n",
       "      <td>972.860474</td>\n",
       "      <td>34158.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00+3순</td>\n",
       "      <td>36519.484375</td>\n",
       "      <td>677366.4375</td>\n",
       "      <td>150717.500000</td>\n",
       "      <td>1562.751709</td>\n",
       "      <td>13870.490234</td>\n",
       "      <td>8489.785156</td>\n",
       "      <td>30210.734375</td>\n",
       "      <td>1058.907715</td>\n",
       "      <td>993.200989</td>\n",
       "      <td>34411.808594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_01+1순</td>\n",
       "      <td>40148.707031</td>\n",
       "      <td>640642.1250</td>\n",
       "      <td>146114.656250</td>\n",
       "      <td>1464.198853</td>\n",
       "      <td>9887.664062</td>\n",
       "      <td>6741.364258</td>\n",
       "      <td>27778.847656</td>\n",
       "      <td>935.847229</td>\n",
       "      <td>886.912048</td>\n",
       "      <td>32417.271484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_01+2순</td>\n",
       "      <td>38638.921875</td>\n",
       "      <td>644697.0625</td>\n",
       "      <td>145114.796875</td>\n",
       "      <td>1484.734009</td>\n",
       "      <td>9820.839844</td>\n",
       "      <td>6270.062012</td>\n",
       "      <td>27835.707031</td>\n",
       "      <td>917.861023</td>\n",
       "      <td>880.311096</td>\n",
       "      <td>32158.150391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TEST_23+2순</td>\n",
       "      <td>52417.250000</td>\n",
       "      <td>616652.0000</td>\n",
       "      <td>142978.796875</td>\n",
       "      <td>1463.816040</td>\n",
       "      <td>7978.229980</td>\n",
       "      <td>5547.805176</td>\n",
       "      <td>27665.214844</td>\n",
       "      <td>888.930542</td>\n",
       "      <td>895.202393</td>\n",
       "      <td>32414.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>TEST_23+3순</td>\n",
       "      <td>52649.566406</td>\n",
       "      <td>615174.7500</td>\n",
       "      <td>144501.218750</td>\n",
       "      <td>1457.167725</td>\n",
       "      <td>8201.917969</td>\n",
       "      <td>5644.718750</td>\n",
       "      <td>27554.253906</td>\n",
       "      <td>904.483276</td>\n",
       "      <td>901.814148</td>\n",
       "      <td>32810.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>TEST_24+1순</td>\n",
       "      <td>39406.437500</td>\n",
       "      <td>534214.0625</td>\n",
       "      <td>137894.234375</td>\n",
       "      <td>1413.243042</td>\n",
       "      <td>11422.693359</td>\n",
       "      <td>11168.657227</td>\n",
       "      <td>30491.712891</td>\n",
       "      <td>1081.751099</td>\n",
       "      <td>680.295654</td>\n",
       "      <td>38218.886719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>TEST_24+2순</td>\n",
       "      <td>37659.835938</td>\n",
       "      <td>533976.7500</td>\n",
       "      <td>137193.515625</td>\n",
       "      <td>1431.942261</td>\n",
       "      <td>11553.516602</td>\n",
       "      <td>10361.579102</td>\n",
       "      <td>30513.093750</td>\n",
       "      <td>1088.728394</td>\n",
       "      <td>682.875122</td>\n",
       "      <td>37988.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>TEST_24+3순</td>\n",
       "      <td>37590.292969</td>\n",
       "      <td>534094.8750</td>\n",
       "      <td>138583.343750</td>\n",
       "      <td>1404.594604</td>\n",
       "      <td>11540.862305</td>\n",
       "      <td>9720.382812</td>\n",
       "      <td>30288.714844</td>\n",
       "      <td>1080.772583</td>\n",
       "      <td>688.055725</td>\n",
       "      <td>38178.957031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            시점            감자          건고추        깐마늘(국산)           대파  \\\n",
       "0   TEST_00+1순  37638.113281  673574.8125  149820.968750  1490.765259   \n",
       "1   TEST_00+2순  36364.687500  680988.4375  148774.593750  1533.887939   \n",
       "2   TEST_00+3순  36519.484375  677366.4375  150717.500000  1562.751709   \n",
       "3   TEST_01+1순  40148.707031  640642.1250  146114.656250  1464.198853   \n",
       "4   TEST_01+2순  38638.921875  644697.0625  145114.796875  1484.734009   \n",
       "..         ...           ...          ...            ...          ...   \n",
       "70  TEST_23+2순  52417.250000  616652.0000  142978.796875  1463.816040   \n",
       "71  TEST_23+3순  52649.566406  615174.7500  144501.218750  1457.167725   \n",
       "72  TEST_24+1순  39406.437500  534214.0625  137894.234375  1413.243042   \n",
       "73  TEST_24+2순  37659.835938  533976.7500  137193.515625  1431.942261   \n",
       "74  TEST_24+3순  37590.292969  534094.8750  138583.343750  1404.594604   \n",
       "\n",
       "               무            배추            사과           상추          양파  \\\n",
       "0   15799.216797  10445.493164  30310.820312  1165.058105  989.179993   \n",
       "1   15262.559570   9474.362305  30380.162109  1137.806396  972.860474   \n",
       "2   13870.490234   8489.785156  30210.734375  1058.907715  993.200989   \n",
       "3    9887.664062   6741.364258  27778.847656   935.847229  886.912048   \n",
       "4    9820.839844   6270.062012  27835.707031   917.861023  880.311096   \n",
       "..           ...           ...           ...          ...         ...   \n",
       "70   7978.229980   5547.805176  27665.214844   888.930542  895.202393   \n",
       "71   8201.917969   5644.718750  27554.253906   904.483276  901.814148   \n",
       "72  11422.693359  11168.657227  30491.712891  1081.751099  680.295654   \n",
       "73  11553.516602  10361.579102  30513.093750  1088.728394  682.875122   \n",
       "74  11540.862305   9720.382812  30288.714844  1080.772583  688.055725   \n",
       "\n",
       "               배  \n",
       "0   34405.542969  \n",
       "1   34158.828125  \n",
       "2   34411.808594  \n",
       "3   32417.271484  \n",
       "4   32158.150391  \n",
       "..           ...  \n",
       "70  32414.179688  \n",
       "71  32810.609375  \n",
       "72  38218.886719  \n",
       "73  37988.531250  \n",
       "74  38178.957031  \n",
       "\n",
       "[75 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('data/train/train.csv')\n",
    "tmp.groupby('품목명')['평균가격(원)'].describe().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "품목명 = '무'\n",
    "train_data, scaler = process_data(\"data/train/train.csv\", \"data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \"data/train/meta/TRAIN_전국도매_2018-2021.csv\", 품목명)\n",
    "scaler = 품목별_scalers[품목명]['평균가격(원)']\n",
    "tmp = minmax_inverse_transform(train_data['평균가격(원)'], scaler, is_train=False)\n",
    "tmp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "test_file = f\"data/test/TEST_{i:02d}.csv\"\n",
    "산지공판장_file = f\"data/test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "전국도매_file = f\"data/test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "\n",
    "test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scalers=품목별_scalers[품목명])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train/train.csv')\n",
    "t = train_df[train_df['품목명']==품목명]\n",
    "t['평균가격(원)'].describe().astype(int)\n",
    "\n",
    "# plt.hist(t['평균가격(원)'], bins=50)\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.boxplot(t['평균가격(원)'])\n",
    "plt.show()\n",
    "plt.boxplot(np.log1p(t['평균가격(원)']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[t['평균가격(원)']>10000000]\n",
    "t.groupby('거래단위')['평균가격(원)'].mean().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('data/sample_submission.csv')\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv('out/baseline_submission.csv')\n",
    "# sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
