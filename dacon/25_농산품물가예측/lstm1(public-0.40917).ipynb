{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농산물 가격 예측을 위한 AI 모델 개발 \n",
    "- '2024 농산물 가격 예측 AI 경진대회'는 데이터와 AI 기술을 활용하여 농산물 가격 예측 능력을 향상시키는 것을 목표로 합니다.<br>  이 대회는 농업 분야의 복잡한 시계열 데이터를 효율적으로 분석하고 예측할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br> <br>\n",
    "- 이 대회의 궁극적 목적은 참가자들의 시계열 데이터 분석 및 예측 역량을 강화하고, <br> AI 기술이 실제 농산물 가격 예측과 관련 정책 결정에 어떻게 기여할 수 있는지 탐구하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_dir = \"g:/My Drive/Storage/Github/hyuckjinkim\"\n",
    "sys.path.append(lib_dir)\n",
    "\n",
    "from lib.python.graph import MatplotlibFontManager\n",
    "fm = MatplotlibFontManager()\n",
    "fm.set_korean_font(check=False)\n",
    "\n",
    "from lib.python.torch.build_model import train, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# train_df = pd.read_csv('data/train/train.csv')\n",
    "\n",
    "# train_meta1_df = pd.read_csv('data/train/meta/TRAIN_산지공판장_2018-2021.csv')\n",
    "# train_meta1_df.drop(['품목코드','품종코드','공판장코드'], axis=1, inplace=True)\n",
    "\n",
    "# train_meta2_df = pd.read_csv('data/train/meta/TRAIN_전국도매_2018-2021.csv')\n",
    "# train_meta2_df.drop(['품목코드','품종코드','시장코드']  , axis=1, inplace=True)\n",
    "\n",
    "# train_df.head(2) # ['평년 평균가격(원)','평균가격(원)']\n",
    "# train_meta1_df.head(2)\n",
    "# train_meta2_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from types import SimpleNamespace\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for Feature Engineering\n",
    "- 타겟의 필터 조건을 제외한 메타데이터의 필터 조건은 참가자들 각자의 기준에 맞춰 자유롭게 사용가능 \n",
    "- 밑의 필터 조건은 임의로 제공하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_convert(data):\n",
    "    data['연도'] -= 2018\n",
    "\n",
    "    offset = 0.1\n",
    "    map_dict = {'상순':offset, '중순':offset+1/3, '하순':offset+2/3}\n",
    "    data['연도'] += data['시점'].str.extract(r'(상순|중순|하순)')[0].map(map_dict)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scalers=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 품목코드, 품종코드, 공판장코드, 시장코드 제거\n",
    "    산지공판장.drop(['품목코드','품종코드','공판장코드'], axis=1, inplace=True)\n",
    "    전국도매  .drop(['품목코드','품종코드','시장코드']  , axis=1, inplace=True)\n",
    "\n",
    "    # 연도에 상/중/하순에 대한 정보도 추가\n",
    "    산지공판장 = year_convert(산지공판장)\n",
    "    전국도매 = year_convert(전국도매)\n",
    "\n",
    "    # 이상값(0이하) 처리\n",
    "    for col in ['전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR']:\n",
    "        loc = 전국도매[col] < 0\n",
    "        전국도매.loc[loc,col] = 0\n",
    "\n",
    "    # log변환\n",
    "    raw_cols = ['평년 평균가격(원)', '평균가격(원)']\n",
    "    산지공판장_cols =  ['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '중간가(원/kg)', '최저가(원/kg)', '최고가(원/kg)', '경매 건수', \n",
    "                       '전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR', '평년 평균가격(원) Common Year SOON']\n",
    "    전국도매_cols = ['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '중가(60%) 평균가 ', '저가(20%) 평균가', '중간가(원/kg)', '최저가(원/kg)',\n",
    "                    '최고가(원/kg)', '경매 건수', '전순 평균가격(원) PreVious SOON', '전달 평균가격(원) PreVious MMonth', '전년 평균가격(원) PreVious YeaR', '평년 평균가격(원) Common Year SOON']\n",
    "    for col in raw_cols: raw_data[col] = np.log1p(raw_data[col])\n",
    "    for col in 산지공판장_cols: 산지공판장[col] = np.log1p(산지공판장[col])\n",
    "    for col in 전국도매_cols: 전국도매[col] = np.log1p(전국도매[col])\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # 다른 품종에 대한 파생변수 생성\n",
    "    other_data = raw_품목[~target_mask]\n",
    "    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "        temp_df = other_data[mask]\n",
    "        for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "    # 공판장 데이터 처리\n",
    "    if conditions[품목명]['공판장']:\n",
    "        filtered_공판장 = 산지공판장\n",
    "        for key, value in conditions[품목명]['공판장'].items():\n",
    "            filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "        filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # 도매 데이터 처리\n",
    "    if conditions[품목명]['도매']:\n",
    "        filtered_도매 = 전국도매\n",
    "        for key, value in conditions[품목명]['도매'].items():\n",
    "            filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "        filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "        filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # 정규화 적용\n",
    "    if scalers is None:\n",
    "        scalers = {}\n",
    "        for col in numeric_columns:\n",
    "            scaler = MinMaxScaler()\n",
    "            filtered_data[col] = scaler.fit_transform(filtered_data[col].values.reshape(-1,1))\n",
    "            scalers[col] = scaler\n",
    "    else:\n",
    "        for col in numeric_columns:\n",
    "            scaler = scalers[col]\n",
    "            filtered_data[col] = scaler.transform(filtered_data[col].values.reshape(-1,1))\n",
    "\n",
    "    return filtered_data, scalers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturePriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        self.price_column = '평균가격(원)'\n",
    "        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        self.sequences = []\n",
    "        if not self.is_test:\n",
    "            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n",
    "                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n",
    "                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n",
    "                self.sequences.append((x, y))\n",
    "        else:\n",
    "            self.sequences = [self.data[self.numeric_columns].values]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            x, y = self.sequences[idx]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        else:\n",
    "            return torch.FloatTensor(self.sequences[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricePredictionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0):\n",
    "        super(PricePredictionLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"epoch\": 4048,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_size\": 3,\n",
    "    \"test_size\": 0.2,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']\n",
    "# 품목_리스트 = ['감자']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품목별_scalers[품목명][dataset.price_column].inverse_transform\n",
    "def minmax_inverse_transform(x, scaler, is_train=True):\n",
    "    origin = scaler.data_min_[0] + x * (scaler.data_max_[0] - scaler.data_min_[0])\n",
    "    if is_train:\n",
    "        origin = torch.exp(origin) - 1\n",
    "    else:\n",
    "        origin = np.exp(origin) - 1\n",
    "    return origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================================================================================================\n",
      "> [1/10] 건고추\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 219557.3828, val_loss: 173134.7188, best: 173134.7188(50), elapsed: 3.7s, total: 3.7s, remaining: 295.4s\n",
      "*[0100/4048] tr_loss: 200742.0938, val_loss: 157930.4219, best: 157930.4219(100), elapsed: 3.6s, total: 7.4s, remaining: 287.2s\n",
      "*[0150/4048] tr_loss: 178983.7578, val_loss: 134584.3750, best: 134584.3750(150), elapsed: 3.6s, total: 11.0s, remaining: 282.9s\n",
      "*[0200/4048] tr_loss: 128323.0234, val_loss: 88125.6875, best: 88125.6875(200), elapsed: 3.7s, total: 14.7s, remaining: 282.5s\n",
      "*[0250/4048] tr_loss: 104030.4570, val_loss: 71600.9297, best: 71600.9297(250), elapsed: 3.9s, total: 18.7s, remaining: 296.8s\n",
      "*[0300/4048] tr_loss: 104834.4922, val_loss: 70233.2812, best: 70233.2812(300), elapsed: 4.4s, total: 23.1s, remaining: 327.8s\n",
      "*[0350/4048] tr_loss: 104610.1406, val_loss: 68814.8750, best: 68814.8750(350), elapsed: 4.4s, total: 27.5s, remaining: 325.9s\n",
      "*[0400/4048] tr_loss: 102005.7617, val_loss: 67076.5547, best: 67076.5547(400), elapsed: 3.9s, total: 31.4s, remaining: 283.2s\n",
      "*[0450/4048] tr_loss: 100685.9141, val_loss: 64937.9805, best: 64937.9805(450), elapsed: 3.9s, total: 35.3s, remaining: 279.1s\n",
      "*[0500/4048] tr_loss: 97045.5273, val_loss: 62139.0195, best: 62139.0195(500), elapsed: 3.9s, total: 39.3s, remaining: 277.5s\n",
      "*[0550/4048] tr_loss: 91895.7148, val_loss: 58362.7148, best: 58362.7148(550), elapsed: 4.1s, total: 43.4s, remaining: 286.7s\n",
      "*[0600/4048] tr_loss: 84136.6914, val_loss: 53053.8398, best: 53053.8398(600), elapsed: 4.2s, total: 47.6s, remaining: 290.2s\n",
      "*[0650/4048] tr_loss: 74248.0156, val_loss: 45184.9062, best: 45184.9062(650), elapsed: 4.2s, total: 51.9s, remaining: 288.1s\n",
      "*[0700/4048] tr_loss: 58991.6250, val_loss: 33685.3906, best: 33685.3906(700), elapsed: 4.2s, total: 56.1s, remaining: 282.6s\n",
      "*[0750/4048] tr_loss: 52281.2383, val_loss: 28165.6914, best: 28165.6914(750), elapsed: 4.3s, total: 60.4s, remaining: 281.1s\n",
      " [0800/4048] tr_loss: 46973.1855, val_loss: 26396.0625, best: 26374.0781(798), elapsed: 2.9s, total: 63.4s, remaining: 187.9s\n",
      " [0850/4048] tr_loss: 43451.2236, val_loss: 24970.3574, best: 24797.1074(845), elapsed: 2.2s, total: 65.6s, remaining: 141.5s\n",
      " [0900/4048] tr_loss: 47344.9863, val_loss: 24041.0117, best: 23822.0566(891), elapsed: 1.6s, total: 67.2s, remaining: 102.9s\n",
      " [0950/4048] tr_loss: 44729.4902, val_loss: 24041.8633, best: 23822.0566(891), elapsed: 0.9s, total: 68.1s, remaining: 55.7s\n",
      "<Stopped> tr_loss: 42333.0059, val_loss: 24041.9980, best: 23822.0566(891), elapsed: 0.7s, total: 68.8s, remaining: 41.7s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [2/10] 사과\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 6791.5649, val_loss: 5365.3169, best: 5365.3169(50), elapsed: 4.3s, total: 4.3s, remaining: 340.1s\n",
      "*[0100/4048] tr_loss: 5490.5564, val_loss: 4061.6597, best: 4061.6597(100), elapsed: 4.6s, total: 8.9s, remaining: 362.0s\n",
      "*[0150/4048] tr_loss: 4097.1396, val_loss: 3133.8933, best: 3133.8933(150), elapsed: 4.5s, total: 13.4s, remaining: 349.2s\n",
      "*[0200/4048] tr_loss: 3380.3804, val_loss: 2829.0095, best: 2829.0095(200), elapsed: 4.5s, total: 17.9s, remaining: 343.9s\n",
      "*[0250/4048] tr_loss: 2835.0920, val_loss: 2446.0615, best: 2446.0615(250), elapsed: 4.8s, total: 22.7s, remaining: 365.2s\n",
      "*[0300/4048] tr_loss: 2072.7910, val_loss: 1867.9547, best: 1867.9547(300), elapsed: 4.5s, total: 27.3s, remaining: 340.0s\n",
      "*[0350/4048] tr_loss: 1709.2204, val_loss: 1618.6606, best: 1618.6606(350), elapsed: 4.6s, total: 31.9s, remaining: 338.7s\n",
      "*[0400/4048] tr_loss: 1599.9520, val_loss: 1543.7137, best: 1543.7137(400), elapsed: 3.6s, total: 35.6s, remaining: 264.6s\n",
      "*[0450/4048] tr_loss: 1488.4503, val_loss: 1484.2277, best: 1484.2277(450), elapsed: 3.4s, total: 39.0s, remaining: 243.8s\n",
      "*[0500/4048] tr_loss: 1402.8317, val_loss: 1414.8610, best: 1414.8610(500), elapsed: 3.7s, total: 42.7s, remaining: 261.8s\n",
      " [0550/4048] tr_loss: 1316.9015, val_loss: 1364.0243, best: 1355.5087(542), elapsed: 2.8s, total: 45.6s, remaining: 195.3s\n",
      " [0600/4048] tr_loss: 1314.2599, val_loss: 1358.4099, best: 1355.5087(542), elapsed: 0.9s, total: 46.4s, remaining: 59.4s\n",
      "<Stopped> tr_loss: 1336.2288, val_loss: 1358.4070, best: 1355.5087(542), elapsed: 0.8s, total: 47.2s, remaining: 53.4s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [3/10] 감자\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 16213.4595, val_loss: 14943.7607, best: 14943.7607(50), elapsed: 4.3s, total: 4.3s, remaining: 344.8s\n",
      "*[0100/4048] tr_loss: 13117.9526, val_loss: 12184.9619, best: 12184.9619(100), elapsed: 4.4s, total: 8.8s, remaining: 350.2s\n",
      "*[0150/4048] tr_loss: 10987.3193, val_loss: 10406.4023, best: 10406.4023(150), elapsed: 4.4s, total: 13.2s, remaining: 344.6s\n",
      "*[0200/4048] tr_loss: 10166.0898, val_loss: 9866.5127, best: 9866.5127(200), elapsed: 4.7s, total: 17.9s, remaining: 359.7s\n",
      "*[0250/4048] tr_loss: 8840.1741, val_loss: 9050.3770, best: 9050.3770(250), elapsed: 4.3s, total: 22.3s, remaining: 328.6s\n",
      "*[0300/4048] tr_loss: 7697.1936, val_loss: 7804.8936, best: 7804.8936(300), elapsed: 4.5s, total: 26.8s, remaining: 334.6s\n",
      "*[0350/4048] tr_loss: 6707.3867, val_loss: 6876.7378, best: 6876.7378(350), elapsed: 4.4s, total: 31.2s, remaining: 325.6s\n",
      "*[0400/4048] tr_loss: 5801.4648, val_loss: 5936.4526, best: 5936.4526(400), elapsed: 4.6s, total: 35.9s, remaining: 338.4s\n",
      "*[0450/4048] tr_loss: 4841.8066, val_loss: 4945.3867, best: 4945.3867(450), elapsed: 4.6s, total: 40.5s, remaining: 331.5s\n",
      "*[0500/4048] tr_loss: 4342.0061, val_loss: 4596.7173, best: 4596.7173(500), elapsed: 4.7s, total: 45.3s, remaining: 333.0s\n",
      "*[0550/4048] tr_loss: 3976.9044, val_loss: 4361.9404, best: 4361.9404(550), elapsed: 4.9s, total: 50.3s, remaining: 346.2s\n",
      " [0600/4048] tr_loss: 3391.7701, val_loss: 4213.2686, best: 4195.9629(588), elapsed: 3.5s, total: 53.8s, remaining: 242.9s\n",
      " [0650/4048] tr_loss: 3480.3091, val_loss: 4196.8701, best: 4195.9629(588), elapsed: 1.0s, total: 54.8s, remaining: 66.3s\n",
      "<Stopped> tr_loss: 3507.7202, val_loss: 4196.8721, best: 4195.9629(588), elapsed: 0.7s, total: 55.5s, remaining: 49.5s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [4/10] 배\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 9738.4238, val_loss: 8210.8447, best: 8210.8447(50), elapsed: 4.5s, total: 4.5s, remaining: 357.6s\n",
      "*[0100/4048] tr_loss: 7561.1230, val_loss: 6449.8379, best: 6449.8379(100), elapsed: 4.7s, total: 9.2s, remaining: 367.5s\n",
      "*[0150/4048] tr_loss: 4830.1543, val_loss: 4177.7363, best: 4177.7363(150), elapsed: 4.7s, total: 13.9s, remaining: 364.7s\n",
      "*[0200/4048] tr_loss: 4087.8933, val_loss: 3894.4854, best: 3894.4854(200), elapsed: 4.5s, total: 18.4s, remaining: 347.3s\n",
      "*[0250/4048] tr_loss: 3531.9517, val_loss: 3595.4514, best: 3595.4514(250), elapsed: 4.6s, total: 23.1s, remaining: 351.4s\n",
      "*[0300/4048] tr_loss: 2845.9160, val_loss: 3263.7542, best: 3263.7542(300), elapsed: 4.6s, total: 27.7s, remaining: 344.1s\n",
      "*[0350/4048] tr_loss: 2580.1129, val_loss: 3023.6191, best: 3023.6191(350), elapsed: 4.6s, total: 32.3s, remaining: 340.4s\n",
      "*[0400/4048] tr_loss: 2334.8082, val_loss: 2865.5308, best: 2865.5308(400), elapsed: 4.6s, total: 36.9s, remaining: 332.5s\n",
      "*[0450/4048] tr_loss: 2292.8308, val_loss: 2731.9524, best: 2731.9524(450), elapsed: 4.7s, total: 41.7s, remaining: 341.2s\n",
      "*[0500/4048] tr_loss: 2163.6472, val_loss: 2628.1165, best: 2628.1165(500), elapsed: 4.6s, total: 46.4s, remaining: 328.4s\n",
      "*[0550/4048] tr_loss: 2107.6260, val_loss: 2546.7930, best: 2546.7930(550), elapsed: 4.4s, total: 50.9s, remaining: 310.7s\n",
      "*[0600/4048] tr_loss: 2026.6466, val_loss: 2473.3530, best: 2473.3530(600), elapsed: 5.4s, total: 56.3s, remaining: 373.1s\n",
      "*[0650/4048] tr_loss: 1997.8375, val_loss: 2398.3689, best: 2398.3689(650), elapsed: 5.3s, total: 61.7s, remaining: 361.6s\n",
      "*[0700/4048] tr_loss: 1982.1065, val_loss: 2329.3169, best: 2329.3169(700), elapsed: 4.8s, total: 66.5s, remaining: 319.0s\n",
      "*[0750/4048] tr_loss: 1801.8113, val_loss: 2263.4949, best: 2263.4949(750), elapsed: 4.7s, total: 71.2s, remaining: 310.4s\n",
      "*[0800/4048] tr_loss: 1816.7922, val_loss: 2199.8210, best: 2199.8210(800), elapsed: 4.6s, total: 75.9s, remaining: 300.5s\n",
      "*[0850/4048] tr_loss: 1726.0441, val_loss: 2137.6477, best: 2137.6477(850), elapsed: 4.6s, total: 80.5s, remaining: 293.6s\n",
      "*[0900/4048] tr_loss: 1620.2090, val_loss: 2090.1177, best: 2090.1177(900), elapsed: 4.5s, total: 85.0s, remaining: 281.9s\n",
      "*[0950/4048] tr_loss: 1644.8066, val_loss: 2032.5002, best: 2032.5002(950), elapsed: 4.5s, total: 89.5s, remaining: 277.1s\n",
      "*[1000/4048] tr_loss: 1524.3171, val_loss: 1982.0546, best: 1982.0546(1000), elapsed: 4.6s, total: 94.2s, remaining: 281.4s\n",
      " [1050/4048] tr_loss: 1483.5722, val_loss: 1931.6221, best: 1931.9865(1048), elapsed: 4.3s, total: 98.5s, remaining: 255.6s\n",
      "*[1100/4048] tr_loss: 1415.5895, val_loss: 1858.0754, best: 1858.0754(1100), elapsed: 4.6s, total: 103.1s, remaining: 271.7s\n",
      "*[1150/4048] tr_loss: 1336.5328, val_loss: 1797.2141, best: 1797.2141(1150), elapsed: 4.5s, total: 107.6s, remaining: 259.1s\n",
      " [1200/4048] tr_loss: 1322.1213, val_loss: 1743.4811, best: 1741.4126(1198), elapsed: 4.1s, total: 111.8s, remaining: 236.0s\n",
      "*[1250/4048] tr_loss: 1267.0401, val_loss: 1682.1895, best: 1682.1895(1250), elapsed: 3.7s, total: 115.5s, remaining: 209.0s\n",
      " [1300/4048] tr_loss: 1219.5223, val_loss: 1643.6759, best: 1643.8275(1296), elapsed: 3.2s, total: 118.8s, remaining: 175.9s\n",
      " [1350/4048] tr_loss: 1207.6760, val_loss: 1599.1447, best: 1598.9745(1349), elapsed: 3.6s, total: 122.4s, remaining: 194.8s\n",
      " [1400/4048] tr_loss: 1165.5835, val_loss: 1572.7498, best: 1571.6367(1399), elapsed: 3.0s, total: 125.4s, remaining: 158.1s\n",
      " [1450/4048] tr_loss: 1169.6478, val_loss: 1547.8195, best: 1547.6021(1449), elapsed: 2.8s, total: 128.1s, remaining: 145.0s\n",
      "*[1500/4048] tr_loss: 1068.6754, val_loss: 1521.9783, best: 1521.9783(1500), elapsed: 3.6s, total: 131.7s, remaining: 180.9s\n",
      " [1550/4048] tr_loss: 1031.9379, val_loss: 1503.4518, best: 1501.1302(1545), elapsed: 3.4s, total: 135.1s, remaining: 171.2s\n",
      " [1600/4048] tr_loss: 1123.4170, val_loss: 1478.4622, best: 1478.2061(1596), elapsed: 3.7s, total: 138.8s, remaining: 180.7s\n",
      " [1650/4048] tr_loss: 1052.8680, val_loss: 1453.8456, best: 1452.9131(1648), elapsed: 3.8s, total: 142.7s, remaining: 183.7s\n",
      "*[1700/4048] tr_loss: 1105.6568, val_loss: 1430.1372, best: 1430.1372(1700), elapsed: 3.8s, total: 146.5s, remaining: 178.5s\n",
      "*[1750/4048] tr_loss: 1064.5485, val_loss: 1406.4515, best: 1406.4515(1750), elapsed: 4.0s, total: 150.5s, remaining: 182.3s\n",
      "*[1800/4048] tr_loss: 1038.4309, val_loss: 1395.0825, best: 1395.0825(1800), elapsed: 3.6s, total: 154.1s, remaining: 162.6s\n",
      " [1850/4048] tr_loss: 1060.5385, val_loss: 1394.8975, best: 1394.8979(1835), elapsed: 2.6s, total: 156.8s, remaining: 115.3s\n",
      " [1900/4048] tr_loss: 1068.7991, val_loss: 1394.8977, best: 1394.8987(1896), elapsed: 1.9s, total: 158.7s, remaining: 81.4s\n",
      " [1950/4048] tr_loss: 1062.4781, val_loss: 1394.9003, best: 1394.8987(1896), elapsed: 1.3s, total: 160.0s, remaining: 56.2s\n",
      " [2000/4048] tr_loss: 1073.7858, val_loss: 1394.8989, best: 1394.8997(1953), elapsed: 1.7s, total: 161.7s, remaining: 67.9s\n",
      " [2050/4048] tr_loss: 1034.6443, val_loss: 1394.8977, best: 1394.8969(2041), elapsed: 2.0s, total: 163.6s, remaining: 78.2s\n",
      " [2100/4048] tr_loss: 1050.5927, val_loss: 1394.8983, best: 1394.8969(2041), elapsed: 1.6s, total: 165.2s, remaining: 61.5s\n",
      " [2150/4048] tr_loss: 1042.3443, val_loss: 1394.8989, best: 1394.8999(2115), elapsed: 1.3s, total: 166.5s, remaining: 50.8s\n",
      " [2200/4048] tr_loss: 1016.2406, val_loss: 1394.9004, best: 1394.9004(2192), elapsed: 2.0s, total: 168.6s, remaining: 75.2s\n",
      " [2250/4048] tr_loss: 1023.4995, val_loss: 1394.8973, best: 1394.8982(2248), elapsed: 2.1s, total: 170.7s, remaining: 75.0s\n",
      " [2300/4048] tr_loss: 1070.4541, val_loss: 1394.8964, best: 1394.8964(2299), elapsed: 1.6s, total: 172.3s, remaining: 55.5s\n",
      " [2350/4048] tr_loss: 961.3833, val_loss: 1394.8964, best: 1394.8964(2349), elapsed: 1.5s, total: 173.8s, remaining: 51.4s\n",
      " [2400/4048] tr_loss: 1032.9874, val_loss: 1394.8967, best: 1394.8967(2391), elapsed: 1.8s, total: 175.6s, remaining: 60.1s\n",
      " [2450/4048] tr_loss: 1057.1191, val_loss: 1394.8986, best: 1394.8989(2439), elapsed: 2.0s, total: 177.6s, remaining: 64.1s\n",
      " [2500/4048] tr_loss: 1001.4867, val_loss: 1394.8962, best: 1394.8962(2490), elapsed: 1.6s, total: 179.2s, remaining: 49.8s\n",
      " [2550/4048] tr_loss: 1046.3630, val_loss: 1394.8936, best: 1394.8962(2490), elapsed: 1.4s, total: 180.6s, remaining: 40.6s\n",
      " [2600/4048] tr_loss: 1066.4869, val_loss: 1394.8965, best: 1394.8940(2589), elapsed: 2.1s, total: 182.6s, remaining: 60.2s\n",
      " [2650/4048] tr_loss: 1004.0832, val_loss: 1394.8959, best: 1394.8964(2623), elapsed: 1.4s, total: 184.1s, remaining: 39.8s\n",
      " [2700/4048] tr_loss: 993.8559, val_loss: 1394.8959, best: 1394.8958(2667), elapsed: 1.7s, total: 185.7s, remaining: 45.3s\n",
      " [2750/4048] tr_loss: 971.6221, val_loss: 1394.8956, best: 1394.8949(2734), elapsed: 1.7s, total: 187.4s, remaining: 43.9s\n",
      " [2800/4048] tr_loss: 991.3183, val_loss: 1394.8947, best: 1394.8960(2777), elapsed: 1.6s, total: 189.0s, remaining: 38.9s\n",
      " [2850/4048] tr_loss: 1087.1790, val_loss: 1394.8945, best: 1394.8939(2849), elapsed: 1.7s, total: 190.6s, remaining: 39.6s\n",
      " [2900/4048] tr_loss: 1062.6392, val_loss: 1394.8950, best: 1394.8945(2894), elapsed: 1.8s, total: 192.4s, remaining: 41.0s\n",
      " [2950/4048] tr_loss: 1024.3762, val_loss: 1394.8926, best: 1394.8932(2924), elapsed: 2.2s, total: 194.6s, remaining: 48.6s\n",
      " [3000/4048] tr_loss: 997.7534, val_loss: 1394.8899, best: 1394.8899(2990), elapsed: 2.1s, total: 196.7s, remaining: 43.1s\n",
      " [3050/4048] tr_loss: 1006.1469, val_loss: 1394.8927, best: 1394.8923(3043), elapsed: 1.8s, total: 198.5s, remaining: 35.4s\n",
      " [3100/4048] tr_loss: 1065.4431, val_loss: 1394.8911, best: 1394.8911(3066), elapsed: 1.8s, total: 200.3s, remaining: 34.6s\n",
      " [3150/4048] tr_loss: 1011.0992, val_loss: 1394.8912, best: 1394.8920(3135), elapsed: 2.3s, total: 202.6s, remaining: 40.5s\n",
      " [3200/4048] tr_loss: 1052.8105, val_loss: 1394.8896, best: 1394.8895(3199), elapsed: 2.5s, total: 205.1s, remaining: 42.3s\n",
      " [3250/4048] tr_loss: 1060.5393, val_loss: 1394.8923, best: 1394.8893(3219), elapsed: 1.6s, total: 206.6s, remaining: 25.2s\n",
      " [3300/4048] tr_loss: 1048.7977, val_loss: 1394.8910, best: 1394.8910(3258), elapsed: 1.5s, total: 208.1s, remaining: 22.1s\n",
      " [3350/4048] tr_loss: 996.6390, val_loss: 1394.8899, best: 1394.8896(3319), elapsed: 1.9s, total: 210.0s, remaining: 25.8s\n",
      " [3400/4048] tr_loss: 1054.7708, val_loss: 1394.8875, best: 1394.8895(3378), elapsed: 1.9s, total: 211.9s, remaining: 25.0s\n",
      "*[3450/4048] tr_loss: 1016.1378, val_loss: 1394.8888, best: 1394.8888(3450), elapsed: 2.1s, total: 214.0s, remaining: 25.1s\n",
      " [3500/4048] tr_loss: 1026.5889, val_loss: 1394.8884, best: 1394.8885(3489), elapsed: 2.0s, total: 216.0s, remaining: 21.9s\n",
      " [3550/4048] tr_loss: 1075.7495, val_loss: 1394.8872, best: 1394.8872(3547), elapsed: 1.9s, total: 217.9s, remaining: 18.4s\n",
      " [3600/4048] tr_loss: 1005.2866, val_loss: 1394.8853, best: 1394.8862(3590), elapsed: 2.0s, total: 219.8s, remaining: 17.6s\n",
      " [3650/4048] tr_loss: 1005.4703, val_loss: 1394.8838, best: 1394.8848(3628), elapsed: 2.0s, total: 221.8s, remaining: 15.6s\n",
      " [3700/4048] tr_loss: 1059.6789, val_loss: 1394.8857, best: 1394.8857(3696), elapsed: 1.8s, total: 223.6s, remaining: 12.6s\n",
      " [3750/4048] tr_loss: 989.0582, val_loss: 1394.8855, best: 1394.8848(3734), elapsed: 2.2s, total: 225.8s, remaining: 12.8s\n",
      " [3800/4048] tr_loss: 1011.9532, val_loss: 1394.8850, best: 1394.8857(3756), elapsed: 1.9s, total: 227.6s, remaining: 9.2s\n",
      " [3850/4048] tr_loss: 1082.8688, val_loss: 1394.8839, best: 1394.8839(3847), elapsed: 2.1s, total: 229.7s, remaining: 8.2s\n",
      " [3900/4048] tr_loss: 1037.9197, val_loss: 1394.8844, best: 1394.8839(3851), elapsed: 1.3s, total: 231.0s, remaining: 4.0s\n",
      " [3950/4048] tr_loss: 1049.9781, val_loss: 1394.8844, best: 1394.8853(3915), elapsed: 1.4s, total: 232.5s, remaining: 2.8s\n",
      " [4000/4048] tr_loss: 1059.6255, val_loss: 1394.8831, best: 1394.8829(3994), elapsed: 2.0s, total: 234.5s, remaining: 1.9s\n",
      " [4048/4048] tr_loss: 1018.6784, val_loss: 1394.8839, best: 1394.8837(4017), elapsed: 1.9s, total: 236.5s, remaining: 0.0s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [5/10] 깐마늘(국산)\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 45093.6660, val_loss: 38433.3125, best: 38433.3125(50), elapsed: 4.8s, total: 4.8s, remaining: 384.0s\n",
      "*[0100/4048] tr_loss: 39432.6699, val_loss: 34375.3047, best: 34375.3047(100), elapsed: 4.9s, total: 9.7s, remaining: 384.9s\n",
      "*[0150/4048] tr_loss: 32411.2178, val_loss: 27044.2598, best: 27044.2598(150), elapsed: 4.7s, total: 14.4s, remaining: 366.5s\n",
      "*[0200/4048] tr_loss: 19740.6367, val_loss: 17614.5117, best: 17614.5117(200), elapsed: 4.7s, total: 19.1s, remaining: 357.9s\n",
      "*[0250/4048] tr_loss: 14383.3374, val_loss: 13391.4551, best: 13391.4551(250), elapsed: 5.0s, total: 24.2s, remaining: 380.1s\n",
      "*[0300/4048] tr_loss: 9350.1758, val_loss: 9296.4521, best: 9296.4521(300), elapsed: 4.6s, total: 28.8s, remaining: 345.1s\n",
      "*[0350/4048] tr_loss: 7457.3745, val_loss: 8805.7852, best: 8805.7852(350), elapsed: 3.8s, total: 32.6s, remaining: 278.5s\n",
      "*[0400/4048] tr_loss: 6820.6594, val_loss: 8702.1748, best: 8702.1748(400), elapsed: 2.7s, total: 35.3s, remaining: 193.9s\n",
      "*[0450/4048] tr_loss: 6667.6206, val_loss: 8469.9873, best: 8469.9873(450), elapsed: 2.2s, total: 37.5s, remaining: 156.2s\n",
      " [0500/4048] tr_loss: 6666.1453, val_loss: 8430.1787, best: 8391.2617(460), elapsed: 1.1s, total: 38.7s, remaining: 80.5s\n",
      " [0550/4048] tr_loss: 6665.1040, val_loss: 8430.0791, best: 8391.2617(460), elapsed: 0.9s, total: 39.6s, remaining: 63.9s\n",
      "<Stopped> tr_loss: 6886.7095, val_loss: 8430.0645, best: 8391.2617(460), elapsed: 0.2s, total: 39.8s, remaining: 13.0s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [6/10] 무\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 6577.2439, val_loss: 6500.9624, best: 6500.9624(50), elapsed: 4.2s, total: 4.2s, remaining: 338.4s\n",
      "*[0100/4048] tr_loss: 5567.1077, val_loss: 5282.9365, best: 5282.9365(100), elapsed: 4.4s, total: 8.7s, remaining: 348.4s\n",
      "*[0150/4048] tr_loss: 4042.3026, val_loss: 3545.5691, best: 3545.5691(150), elapsed: 4.6s, total: 13.4s, remaining: 359.8s\n",
      "*[0200/4048] tr_loss: 3764.1088, val_loss: 3345.4834, best: 3345.4834(200), elapsed: 5.1s, total: 18.5s, remaining: 393.2s\n",
      "*[0250/4048] tr_loss: 3798.5873, val_loss: 3257.9885, best: 3257.9885(250), elapsed: 5.4s, total: 23.9s, remaining: 408.9s\n",
      "*[0300/4048] tr_loss: 3631.7299, val_loss: 3209.2678, best: 3209.2678(300), elapsed: 5.3s, total: 29.3s, remaining: 400.5s\n",
      "*[0350/4048] tr_loss: 3568.6116, val_loss: 3171.8589, best: 3171.8589(350), elapsed: 3.8s, total: 33.2s, remaining: 282.4s\n",
      "*[0400/4048] tr_loss: 3526.0652, val_loss: 3110.6606, best: 3110.6606(400), elapsed: 4.4s, total: 37.6s, remaining: 321.7s\n",
      "*[0450/4048] tr_loss: 3415.7323, val_loss: 3000.5837, best: 3000.5837(450), elapsed: 4.5s, total: 42.2s, remaining: 326.3s\n",
      " [0500/4048] tr_loss: 3190.5178, val_loss: 2879.7971, best: 2876.1375(498), elapsed: 4.7s, total: 46.9s, remaining: 331.0s\n",
      " [0550/4048] tr_loss: 3273.7599, val_loss: 2879.7412, best: 2876.5361(518), elapsed: 1.8s, total: 48.7s, remaining: 124.4s\n",
      " [0600/4048] tr_loss: 3149.4327, val_loss: 2879.5457, best: 2879.5457(599), elapsed: 4.2s, total: 52.8s, remaining: 286.9s\n",
      " [0650/4048] tr_loss: 3033.8500, val_loss: 2879.5415, best: 2879.5420(641), elapsed: 4.1s, total: 56.9s, remaining: 276.4s\n",
      " [0700/4048] tr_loss: 3071.5095, val_loss: 2879.5371, best: 2879.5369(698), elapsed: 3.4s, total: 60.3s, remaining: 230.0s\n",
      " [0750/4048] tr_loss: 3238.9453, val_loss: 2879.5334, best: 2879.5334(747), elapsed: 3.8s, total: 64.1s, remaining: 252.0s\n",
      "*[0800/4048] tr_loss: 3148.1970, val_loss: 2879.5281, best: 2879.5281(800), elapsed: 3.6s, total: 67.7s, remaining: 230.9s\n",
      "*[0850/4048] tr_loss: 3061.3925, val_loss: 2879.5239, best: 2879.5239(850), elapsed: 3.5s, total: 71.2s, remaining: 221.7s\n",
      " [0900/4048] tr_loss: 3057.4240, val_loss: 2879.5193, best: 2879.5198(899), elapsed: 3.4s, total: 74.7s, remaining: 214.4s\n",
      " [0950/4048] tr_loss: 3078.9518, val_loss: 2879.5181, best: 2879.5181(945), elapsed: 3.3s, total: 77.9s, remaining: 201.6s\n",
      " [1000/4048] tr_loss: 3178.3448, val_loss: 2879.5146, best: 2879.5151(997), elapsed: 3.4s, total: 81.3s, remaining: 207.0s\n",
      "*[1050/4048] tr_loss: 3154.6699, val_loss: 2879.5098, best: 2879.5098(1050), elapsed: 3.6s, total: 84.9s, remaining: 218.3s\n",
      "*[1100/4048] tr_loss: 3097.6743, val_loss: 2879.5061, best: 2879.5061(1100), elapsed: 3.4s, total: 88.3s, remaining: 198.6s\n",
      " [1150/4048] tr_loss: 3121.4182, val_loss: 2879.5020, best: 2879.5022(1149), elapsed: 3.2s, total: 91.6s, remaining: 187.6s\n",
      " [1200/4048] tr_loss: 3095.1970, val_loss: 2879.5000, best: 2879.5005(1198), elapsed: 3.1s, total: 94.7s, remaining: 175.8s\n",
      "*[1250/4048] tr_loss: 3146.8972, val_loss: 2879.4966, best: 2879.4966(1250), elapsed: 3.7s, total: 98.4s, remaining: 205.8s\n",
      " [1300/4048] tr_loss: 3028.4231, val_loss: 2879.4939, best: 2879.4941(1299), elapsed: 3.0s, total: 101.4s, remaining: 164.7s\n",
      " [1350/4048] tr_loss: 3113.4189, val_loss: 2879.4919, best: 2879.4922(1346), elapsed: 2.5s, total: 103.9s, remaining: 135.4s\n",
      " [1400/4048] tr_loss: 3159.3506, val_loss: 2879.4888, best: 2879.4893(1397), elapsed: 2.5s, total: 106.4s, remaining: 132.5s\n",
      "*[1450/4048] tr_loss: 3001.0833, val_loss: 2879.4854, best: 2879.4854(1450), elapsed: 2.7s, total: 109.1s, remaining: 140.1s\n",
      " [1500/4048] tr_loss: 3099.2343, val_loss: 2879.4807, best: 2879.4812(1495), elapsed: 2.8s, total: 112.0s, remaining: 142.8s\n",
      " [1550/4048] tr_loss: 3181.1395, val_loss: 2879.4802, best: 2879.4805(1546), elapsed: 2.2s, total: 114.2s, remaining: 112.4s\n",
      " [1600/4048] tr_loss: 3032.8704, val_loss: 2879.4775, best: 2879.4780(1598), elapsed: 2.3s, total: 116.5s, remaining: 113.5s\n",
      " [1650/4048] tr_loss: 3188.5422, val_loss: 2879.4756, best: 2879.4753(1649), elapsed: 2.5s, total: 119.0s, remaining: 119.2s\n",
      " [1700/4048] tr_loss: 3217.5544, val_loss: 2879.4714, best: 2879.4719(1697), elapsed: 2.6s, total: 121.7s, remaining: 124.2s\n",
      " [1750/4048] tr_loss: 3067.5352, val_loss: 2879.4683, best: 2879.4683(1749), elapsed: 2.9s, total: 124.5s, remaining: 131.8s\n",
      "*[1800/4048] tr_loss: 3145.5652, val_loss: 2879.4636, best: 2879.4636(1800), elapsed: 3.0s, total: 127.6s, remaining: 136.8s\n",
      "*[1850/4048] tr_loss: 3067.0400, val_loss: 2879.4619, best: 2879.4619(1850), elapsed: 2.8s, total: 130.4s, remaining: 124.0s\n",
      " [1900/4048] tr_loss: 3088.9375, val_loss: 2879.4575, best: 2879.4578(1898), elapsed: 3.1s, total: 133.6s, remaining: 134.8s\n",
      " [1950/4048] tr_loss: 3174.4833, val_loss: 2879.4541, best: 2879.4548(1946), elapsed: 3.1s, total: 136.7s, remaining: 129.8s\n",
      " [2000/4048] tr_loss: 3100.0541, val_loss: 2879.4514, best: 2879.4514(1986), elapsed: 3.2s, total: 139.9s, remaining: 131.8s\n",
      "*[2050/4048] tr_loss: 3018.0293, val_loss: 2879.4468, best: 2879.4468(2050), elapsed: 3.4s, total: 143.3s, remaining: 137.2s\n",
      "*[2100/4048] tr_loss: 3195.9939, val_loss: 2879.4426, best: 2879.4426(2100), elapsed: 3.2s, total: 146.6s, remaining: 125.7s\n",
      "*[2150/4048] tr_loss: 3055.4526, val_loss: 2879.4395, best: 2879.4395(2150), elapsed: 3.1s, total: 149.7s, remaining: 117.3s\n",
      " [2200/4048] tr_loss: 3122.8798, val_loss: 2879.4348, best: 2879.4348(2194), elapsed: 3.1s, total: 152.9s, remaining: 116.3s\n",
      " [2250/4048] tr_loss: 3124.5208, val_loss: 2879.4319, best: 2879.4321(2246), elapsed: 3.2s, total: 156.1s, remaining: 114.1s\n",
      " [2300/4048] tr_loss: 3175.3318, val_loss: 2879.4302, best: 2879.4302(2292), elapsed: 2.5s, total: 158.6s, remaining: 87.9s\n",
      "*[2350/4048] tr_loss: 3190.2441, val_loss: 2879.4258, best: 2879.4258(2350), elapsed: 3.5s, total: 162.1s, remaining: 118.0s\n",
      " [2400/4048] tr_loss: 3106.7321, val_loss: 2879.4226, best: 2879.4226(2398), elapsed: 3.0s, total: 165.2s, remaining: 100.4s\n",
      "*[2450/4048] tr_loss: 3165.5127, val_loss: 2879.4204, best: 2879.4204(2450), elapsed: 2.4s, total: 167.6s, remaining: 76.5s\n",
      " [2500/4048] tr_loss: 3035.3942, val_loss: 2879.4180, best: 2879.4182(2498), elapsed: 3.1s, total: 170.7s, remaining: 95.8s\n",
      " [2550/4048] tr_loss: 3132.2499, val_loss: 2879.4146, best: 2879.4146(2542), elapsed: 3.0s, total: 173.6s, remaining: 88.8s\n",
      "*[2600/4048] tr_loss: 3216.4236, val_loss: 2879.4114, best: 2879.4114(2600), elapsed: 3.0s, total: 176.7s, remaining: 87.8s\n",
      " [2650/4048] tr_loss: 3086.3240, val_loss: 2879.4087, best: 2879.4089(2641), elapsed: 3.1s, total: 179.8s, remaining: 86.1s\n",
      " [2700/4048] tr_loss: 3101.7318, val_loss: 2879.4058, best: 2879.4062(2697), elapsed: 2.8s, total: 182.6s, remaining: 76.0s\n",
      " [2750/4048] tr_loss: 3155.2081, val_loss: 2879.4016, best: 2879.4021(2747), elapsed: 2.6s, total: 185.2s, remaining: 66.7s\n",
      " [2800/4048] tr_loss: 3056.8004, val_loss: 2879.3997, best: 2879.3999(2798), elapsed: 2.6s, total: 187.8s, remaining: 65.7s\n",
      " [2850/4048] tr_loss: 3170.4629, val_loss: 2879.3948, best: 2879.3950(2848), elapsed: 2.5s, total: 190.4s, remaining: 60.9s\n",
      "*[2900/4048] tr_loss: 3148.5946, val_loss: 2879.3901, best: 2879.3901(2900), elapsed: 2.6s, total: 193.0s, remaining: 60.3s\n",
      " [2950/4048] tr_loss: 3047.7933, val_loss: 2879.3877, best: 2879.3882(2946), elapsed: 2.4s, total: 195.4s, remaining: 51.9s\n",
      " [3000/4048] tr_loss: 3088.4719, val_loss: 2879.3838, best: 2879.3838(2999), elapsed: 2.9s, total: 198.3s, remaining: 60.5s\n",
      "*[3050/4048] tr_loss: 3136.1487, val_loss: 2879.3789, best: 2879.3789(3050), elapsed: 3.1s, total: 201.4s, remaining: 61.9s\n",
      " [3100/4048] tr_loss: 3146.7401, val_loss: 2879.3750, best: 2879.3750(3099), elapsed: 2.7s, total: 204.1s, remaining: 51.9s\n",
      " [3150/4048] tr_loss: 3079.2377, val_loss: 2879.3713, best: 2879.3716(3148), elapsed: 2.6s, total: 206.7s, remaining: 45.9s\n",
      " [3200/4048] tr_loss: 3053.1348, val_loss: 2879.3689, best: 2879.3689(3199), elapsed: 2.6s, total: 209.3s, remaining: 44.2s\n",
      "*[3250/4048] tr_loss: 3029.3562, val_loss: 2879.3660, best: 2879.3660(3250), elapsed: 2.6s, total: 211.9s, remaining: 40.9s\n",
      "*[3300/4048] tr_loss: 3079.3591, val_loss: 2879.3630, best: 2879.3630(3300), elapsed: 2.5s, total: 214.4s, remaining: 38.1s\n",
      " [3350/4048] tr_loss: 3068.6571, val_loss: 2879.3599, best: 2879.3606(3347), elapsed: 2.5s, total: 216.9s, remaining: 34.2s\n",
      " [3400/4048] tr_loss: 3087.1644, val_loss: 2879.3589, best: 2879.3584(3392), elapsed: 2.4s, total: 219.3s, remaining: 31.4s\n",
      " [3450/4048] tr_loss: 3129.9780, val_loss: 2879.3552, best: 2879.3560(3447), elapsed: 2.5s, total: 221.9s, remaining: 30.2s\n",
      " [3500/4048] tr_loss: 3100.2275, val_loss: 2879.3518, best: 2879.3513(3492), elapsed: 2.4s, total: 224.3s, remaining: 26.7s\n",
      " [3550/4048] tr_loss: 3111.3333, val_loss: 2879.3469, best: 2879.3469(3546), elapsed: 2.9s, total: 227.2s, remaining: 28.6s\n",
      "*[3600/4048] tr_loss: 3119.1476, val_loss: 2879.3423, best: 2879.3423(3600), elapsed: 2.7s, total: 229.9s, remaining: 24.0s\n",
      " [3650/4048] tr_loss: 3079.3268, val_loss: 2879.3389, best: 2879.3396(3649), elapsed: 2.6s, total: 232.5s, remaining: 21.0s\n",
      " [3700/4048] tr_loss: 3017.8134, val_loss: 2879.3372, best: 2879.3374(3692), elapsed: 2.3s, total: 234.8s, remaining: 15.7s\n",
      " [3750/4048] tr_loss: 3102.1722, val_loss: 2879.3333, best: 2879.3333(3746), elapsed: 2.6s, total: 237.3s, remaining: 15.2s\n",
      " [3800/4048] tr_loss: 3094.6595, val_loss: 2879.3293, best: 2879.3303(3795), elapsed: 2.6s, total: 240.0s, remaining: 13.1s\n",
      " [3850/4048] tr_loss: 3173.3895, val_loss: 2879.3252, best: 2879.3252(3849), elapsed: 3.2s, total: 243.2s, remaining: 12.8s\n",
      " [3900/4048] tr_loss: 3026.9979, val_loss: 2879.3223, best: 2879.3223(3898), elapsed: 2.9s, total: 246.1s, remaining: 8.7s\n",
      " [3950/4048] tr_loss: 3111.2076, val_loss: 2879.3193, best: 2879.3198(3937), elapsed: 3.1s, total: 249.3s, remaining: 6.2s\n",
      " [4000/4048] tr_loss: 3063.9469, val_loss: 2879.3162, best: 2879.3159(3998), elapsed: 3.5s, total: 252.8s, remaining: 3.4s\n",
      " [4048/4048] tr_loss: 2967.5072, val_loss: 2879.3130, best: 2879.3137(4041), elapsed: 2.8s, total: 255.6s, remaining: 0.0s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [7/10] 상추\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 384.3603, val_loss: 420.8978, best: 420.8978(50), elapsed: 3.6s, total: 3.6s, remaining: 286.5s\n",
      "*[0100/4048] tr_loss: 342.2344, val_loss: 370.1941, best: 370.1941(100), elapsed: 3.7s, total: 7.3s, remaining: 294.0s\n",
      "*[0150/4048] tr_loss: 314.0416, val_loss: 309.1873, best: 309.1873(150), elapsed: 4.1s, total: 11.4s, remaining: 318.3s\n",
      "*[0200/4048] tr_loss: 277.4987, val_loss: 279.6979, best: 279.6979(200), elapsed: 4.4s, total: 15.9s, remaining: 336.1s\n",
      "*[0250/4048] tr_loss: 275.6609, val_loss: 274.8020, best: 274.8020(250), elapsed: 4.1s, total: 20.0s, remaining: 313.2s\n",
      "*[0300/4048] tr_loss: 254.9283, val_loss: 269.5404, best: 269.5404(300), elapsed: 4.3s, total: 24.3s, remaining: 321.5s\n",
      "*[0350/4048] tr_loss: 257.5824, val_loss: 263.3886, best: 263.3886(350), elapsed: 3.8s, total: 28.2s, remaining: 280.9s\n",
      "*[0400/4048] tr_loss: 245.3854, val_loss: 257.0753, best: 257.0753(400), elapsed: 3.8s, total: 32.0s, remaining: 277.9s\n",
      "*[0450/4048] tr_loss: 236.1876, val_loss: 250.2909, best: 250.2909(450), elapsed: 4.7s, total: 36.8s, remaining: 341.8s\n",
      "*[0500/4048] tr_loss: 235.0914, val_loss: 242.2346, best: 242.2346(500), elapsed: 4.3s, total: 41.1s, remaining: 306.1s\n",
      "*[0550/4048] tr_loss: 219.8066, val_loss: 231.2468, best: 231.2468(550), elapsed: 4.2s, total: 45.3s, remaining: 292.3s\n",
      "*[0600/4048] tr_loss: 195.7711, val_loss: 215.5143, best: 215.5143(600), elapsed: 4.2s, total: 49.6s, remaining: 290.5s\n",
      "*[0650/4048] tr_loss: 178.7191, val_loss: 196.9125, best: 196.9125(650), elapsed: 5.3s, total: 54.9s, remaining: 361.6s\n",
      "*[0700/4048] tr_loss: 168.0842, val_loss: 185.0011, best: 185.0011(700), elapsed: 4.7s, total: 59.7s, remaining: 314.9s\n",
      "*[0750/4048] tr_loss: 167.0513, val_loss: 179.1391, best: 179.1391(750), elapsed: 4.5s, total: 64.3s, remaining: 299.7s\n",
      "*[0800/4048] tr_loss: 160.6511, val_loss: 174.4312, best: 174.4312(800), elapsed: 4.6s, total: 68.9s, remaining: 298.7s\n",
      "*[0850/4048] tr_loss: 155.5009, val_loss: 170.7828, best: 170.7828(850), elapsed: 4.7s, total: 73.6s, remaining: 298.7s\n",
      "*[0900/4048] tr_loss: 148.3206, val_loss: 167.9400, best: 167.9400(900), elapsed: 4.3s, total: 77.9s, remaining: 268.6s\n",
      "*[0950/4048] tr_loss: 145.2410, val_loss: 164.8523, best: 164.8523(950), elapsed: 4.3s, total: 82.3s, remaining: 268.7s\n",
      "*[1000/4048] tr_loss: 144.6108, val_loss: 162.1785, best: 162.1785(1000), elapsed: 4.3s, total: 86.6s, remaining: 264.2s\n",
      "*[1050/4048] tr_loss: 136.8855, val_loss: 158.9705, best: 158.9705(1050), elapsed: 4.5s, total: 91.2s, remaining: 268.9s\n",
      "*[1100/4048] tr_loss: 137.8124, val_loss: 156.9469, best: 156.9469(1100), elapsed: 4.5s, total: 95.7s, remaining: 265.0s\n",
      "*[1150/4048] tr_loss: 134.7045, val_loss: 155.1334, best: 155.1334(1150), elapsed: 4.6s, total: 100.3s, remaining: 266.2s\n",
      "*[1200/4048] tr_loss: 135.0131, val_loss: 152.8628, best: 152.8628(1200), elapsed: 4.7s, total: 105.0s, remaining: 266.0s\n",
      "*[1250/4048] tr_loss: 129.4546, val_loss: 150.1389, best: 150.1389(1250), elapsed: 4.7s, total: 109.8s, remaining: 262.1s\n",
      "*[1300/4048] tr_loss: 131.7572, val_loss: 146.8726, best: 146.8726(1300), elapsed: 4.0s, total: 113.8s, remaining: 219.6s\n",
      "*[1350/4048] tr_loss: 127.1674, val_loss: 143.1512, best: 143.1512(1350), elapsed: 4.5s, total: 118.4s, remaining: 244.8s\n",
      "*[1400/4048] tr_loss: 123.8046, val_loss: 141.7831, best: 141.7831(1400), elapsed: 3.7s, total: 122.1s, remaining: 194.4s\n",
      "*[1450/4048] tr_loss: 125.2548, val_loss: 140.3194, best: 140.3194(1450), elapsed: 3.6s, total: 125.7s, remaining: 188.2s\n",
      "*[1500/4048] tr_loss: 132.2631, val_loss: 138.6084, best: 138.6084(1500), elapsed: 3.7s, total: 129.5s, remaining: 190.6s\n",
      "*[1550/4048] tr_loss: 126.2061, val_loss: 137.0240, best: 137.0240(1550), elapsed: 4.2s, total: 133.7s, remaining: 207.7s\n",
      " [1600/4048] tr_loss: 123.3567, val_loss: 136.0658, best: 136.0764(1598), elapsed: 3.1s, total: 136.8s, remaining: 151.0s\n",
      "*[1650/4048] tr_loss: 120.4870, val_loss: 135.3720, best: 135.3720(1650), elapsed: 2.4s, total: 139.2s, remaining: 114.4s\n",
      " [1700/4048] tr_loss: 118.8557, val_loss: 134.2316, best: 133.7980(1698), elapsed: 3.0s, total: 142.2s, remaining: 141.8s\n",
      " [1750/4048] tr_loss: 118.2780, val_loss: 132.9729, best: 132.7639(1749), elapsed: 3.0s, total: 145.2s, remaining: 138.6s\n",
      " [1800/4048] tr_loss: 117.2956, val_loss: 131.6266, best: 131.5553(1799), elapsed: 2.6s, total: 147.8s, remaining: 116.2s\n",
      " [1850/4048] tr_loss: 112.7715, val_loss: 130.5375, best: 130.4790(1849), elapsed: 2.3s, total: 150.1s, remaining: 99.8s\n",
      " [1900/4048] tr_loss: 117.5158, val_loss: 130.1476, best: 130.0086(1863), elapsed: 1.4s, total: 151.5s, remaining: 61.1s\n",
      " [1950/4048] tr_loss: 110.7330, val_loss: 130.1468, best: 130.0086(1863), elapsed: 1.0s, total: 152.5s, remaining: 41.4s\n",
      "<Stopped> tr_loss: 116.7199, val_loss: 130.1468, best: 130.0086(1863), elapsed: 0.3s, total: 152.8s, remaining: 10.9s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [8/10] 배추\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 5041.4043, val_loss: 4981.1255, best: 4981.1255(50), elapsed: 4.0s, total: 4.0s, remaining: 316.0s\n",
      "*[0100/4048] tr_loss: 4326.1096, val_loss: 4167.9761, best: 4167.9761(100), elapsed: 4.3s, total: 8.3s, remaining: 341.0s\n",
      "*[0150/4048] tr_loss: 2826.0692, val_loss: 2885.9795, best: 2885.9795(150), elapsed: 4.4s, total: 12.8s, remaining: 344.8s\n",
      "*[0200/4048] tr_loss: 2814.6338, val_loss: 2713.8303, best: 2713.8303(200), elapsed: 4.3s, total: 17.1s, remaining: 328.6s\n",
      "*[0250/4048] tr_loss: 2770.1075, val_loss: 2650.8682, best: 2650.8682(250), elapsed: 4.4s, total: 21.5s, remaining: 331.3s\n",
      "*[0300/4048] tr_loss: 2572.5509, val_loss: 2577.7036, best: 2577.7036(300), elapsed: 4.4s, total: 25.9s, remaining: 327.5s\n",
      "*[0350/4048] tr_loss: 2554.2080, val_loss: 2502.3147, best: 2502.3147(350), elapsed: 4.3s, total: 30.2s, remaining: 315.5s\n",
      "*[0400/4048] tr_loss: 2494.6896, val_loss: 2412.9829, best: 2412.9829(400), elapsed: 4.4s, total: 34.6s, remaining: 322.1s\n",
      "*[0450/4048] tr_loss: 2302.7715, val_loss: 2319.6401, best: 2319.6401(450), elapsed: 4.3s, total: 39.0s, remaining: 310.4s\n",
      "*[0500/4048] tr_loss: 2230.4080, val_loss: 2227.0447, best: 2227.0447(500), elapsed: 4.2s, total: 43.3s, remaining: 300.4s\n",
      "*[0550/4048] tr_loss: 2024.1569, val_loss: 2145.4312, best: 2145.4312(550), elapsed: 4.1s, total: 47.4s, remaining: 290.3s\n",
      "*[0600/4048] tr_loss: 1860.9916, val_loss: 2089.9871, best: 2089.9871(600), elapsed: 3.7s, total: 51.2s, remaining: 255.2s\n",
      "*[0650/4048] tr_loss: 1718.4923, val_loss: 2056.3884, best: 2056.3884(650), elapsed: 2.4s, total: 53.7s, remaining: 166.4s\n",
      "*[0700/4048] tr_loss: 1566.0349, val_loss: 2024.6901, best: 2024.6901(700), elapsed: 2.4s, total: 56.1s, remaining: 161.8s\n",
      " [0750/4048] tr_loss: 1501.5117, val_loss: 1993.7543, best: 1991.2108(747), elapsed: 3.1s, total: 59.3s, remaining: 205.4s\n",
      "*[0800/4048] tr_loss: 1375.4836, val_loss: 1952.3035, best: 1952.3035(800), elapsed: 3.8s, total: 63.1s, remaining: 249.2s\n",
      "*[0850/4048] tr_loss: 1283.3235, val_loss: 1909.0227, best: 1909.0227(850), elapsed: 4.0s, total: 67.1s, remaining: 252.9s\n",
      " [0900/4048] tr_loss: 1288.5017, val_loss: 1875.9534, best: 1867.1975(897), elapsed: 3.0s, total: 70.2s, remaining: 191.9s\n",
      "*[0950/4048] tr_loss: 1249.3841, val_loss: 1819.8881, best: 1819.8881(950), elapsed: 3.1s, total: 73.3s, remaining: 192.7s\n",
      "*[1000/4048] tr_loss: 1192.1995, val_loss: 1772.4313, best: 1772.4313(1000), elapsed: 3.4s, total: 76.7s, remaining: 208.4s\n",
      " [1050/4048] tr_loss: 1149.2716, val_loss: 1721.5232, best: 1720.4395(1049), elapsed: 3.6s, total: 80.4s, remaining: 216.6s\n",
      " [1100/4048] tr_loss: 1101.5345, val_loss: 1665.1357, best: 1659.7466(1099), elapsed: 3.9s, total: 84.2s, remaining: 227.4s\n",
      "*[1150/4048] tr_loss: 1063.7862, val_loss: 1614.5040, best: 1614.5040(1150), elapsed: 3.3s, total: 87.5s, remaining: 191.8s\n",
      " [1200/4048] tr_loss: 1080.6983, val_loss: 1580.6239, best: 1573.8295(1198), elapsed: 3.0s, total: 90.6s, remaining: 172.8s\n",
      " [1250/4048] tr_loss: 1009.4950, val_loss: 1556.1354, best: 1548.0972(1249), elapsed: 3.0s, total: 93.5s, remaining: 165.3s\n",
      "*[1300/4048] tr_loss: 1042.8405, val_loss: 1541.7471, best: 1541.7471(1300), elapsed: 2.2s, total: 95.7s, remaining: 118.4s\n",
      " [1350/4048] tr_loss: 1024.1214, val_loss: 1541.4313, best: 1540.6349(1311), elapsed: 1.5s, total: 97.2s, remaining: 81.1s\n",
      " [1400/4048] tr_loss: 979.4244, val_loss: 1541.4272, best: 1540.6349(1311), elapsed: 1.1s, total: 98.3s, remaining: 55.7s\n",
      "<Stopped> tr_loss: 1052.0057, val_loss: 1541.4264, best: 1540.6349(1311), elapsed: 0.2s, total: 98.5s, remaining: 13.1s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [9/10] 양파\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 456.2206, val_loss: 372.8394, best: 372.8394(50), elapsed: 4.2s, total: 4.2s, remaining: 338.2s\n",
      "*[0100/4048] tr_loss: 306.2691, val_loss: 247.3581, best: 247.3581(100), elapsed: 4.4s, total: 8.7s, remaining: 348.2s\n",
      " [0150/4048] tr_loss: 185.3503, val_loss: 165.2317, best: 165.0529(134), elapsed: 3.4s, total: 12.1s, remaining: 263.8s\n",
      " [0200/4048] tr_loss: 194.8002, val_loss: 165.1011, best: 165.0529(134), elapsed: 1.2s, total: 13.2s, remaining: 88.6s\n",
      "<Stopped> tr_loss: 182.0249, val_loss: 165.1008, best: 165.0529(134), elapsed: 0.8s, total: 14.0s, remaining: 59.2s\n",
      "\n",
      "======================================================================================================================================================\n",
      "> [10/10] 대파\n",
      "======================================================================================================================================================\n",
      "\n",
      "*[0050/4048] tr_loss: 1018.9538, val_loss: 838.7636, best: 838.7636(50), elapsed: 4.0s, total: 4.0s, remaining: 321.3s\n",
      "*[0100/4048] tr_loss: 770.7708, val_loss: 677.4948, best: 677.4948(100), elapsed: 4.2s, total: 8.2s, remaining: 330.8s\n",
      "*[0150/4048] tr_loss: 599.6199, val_loss: 501.4701, best: 501.4701(150), elapsed: 4.2s, total: 12.5s, remaining: 329.9s\n",
      "*[0200/4048] tr_loss: 561.3245, val_loss: 484.6669, best: 484.6669(200), elapsed: 4.1s, total: 16.6s, remaining: 315.9s\n",
      "*[0250/4048] tr_loss: 587.2810, val_loss: 466.6710, best: 466.6710(250), elapsed: 4.6s, total: 21.2s, remaining: 346.0s\n",
      "*[0300/4048] tr_loss: 546.9168, val_loss: 447.3544, best: 447.3544(300), elapsed: 4.7s, total: 25.9s, remaining: 348.7s\n",
      "*[0350/4048] tr_loss: 510.4067, val_loss: 427.8106, best: 427.8106(350), elapsed: 4.5s, total: 30.4s, remaining: 329.2s\n",
      "*[0400/4048] tr_loss: 489.0817, val_loss: 406.6517, best: 406.6517(400), elapsed: 4.2s, total: 34.7s, remaining: 307.3s\n",
      "*[0450/4048] tr_loss: 459.4067, val_loss: 379.3521, best: 379.3521(450), elapsed: 4.4s, total: 39.0s, remaining: 313.3s\n",
      "*[0500/4048] tr_loss: 381.7912, val_loss: 340.6637, best: 340.6637(500), elapsed: 4.3s, total: 43.4s, remaining: 306.8s\n",
      "*[0550/4048] tr_loss: 340.7151, val_loss: 307.7694, best: 307.7694(550), elapsed: 3.8s, total: 47.3s, remaining: 267.8s\n",
      " [0600/4048] tr_loss: 326.8504, val_loss: 305.0385, best: 303.7357(568), elapsed: 1.6s, total: 48.9s, remaining: 109.5s\n",
      " [0650/4048] tr_loss: 310.5896, val_loss: 305.0511, best: 303.7357(568), elapsed: 1.1s, total: 49.9s, remaining: 71.6s\n",
      "<Stopped> tr_loss: 311.5325, val_loss: 305.0514, best: 303.7357(568), elapsed: 0.4s, total: 50.3s, remaining: 26.4s\n"
     ]
    }
   ],
   "source": [
    "품목별_predictions = {}\n",
    "품목별_scalers = {}\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "for i, 품목명 in enumerate(품목_리스트):\n",
    "    model_path = f'models/best_model_{품목명}.pth'\n",
    "    print(f'\\n{'='*150}\\n> [{i+1}/{len(품목_리스트)}] {품목명}\\n{'='*150}\\n')\n",
    "\n",
    "    # preprocessing\n",
    "    train_data, scalers = process_data(\"data/train/train.csv\", \"data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \"data/train/meta/TRAIN_전국도매_2018-2021.csv\", 품목명)\n",
    "    품목별_scalers[품목명] = scalers\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "\n",
    "    # train, validation split\n",
    "    tr_data, val_data = train_test_split(dataset, test_size=CFG.test_size, random_state=CFG.seed, shuffle=True)\n",
    "    train_loader = DataLoader(tr_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    # define model\n",
    "    model = PricePredictionLSTM(\n",
    "        input_size=len(dataset.numeric_columns),\n",
    "        hidden_size=CFG.hidden_size,\n",
    "        num_layers=CFG.num_layers,\n",
    "        output_size=CFG.output_size,\n",
    "    )\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), CFG.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    # scheduler = None\n",
    "\n",
    "    price_scaler = 품목별_scalers[품목명][dataset.price_column]\n",
    "    inverse_transform = lambda x: minmax_inverse_transform(x, price_scaler)\n",
    "    # inverse_transform = None\n",
    "\n",
    "    # train\n",
    "    best_model = train(\n",
    "        model, optimizer, train_loader, val_loader, CFG.epoch,\n",
    "        early_stopping=True, early_stopping_patience=100, early_stopping_verbose=False,\n",
    "        device='cpu', scheduler=scheduler, metric_period=50, \n",
    "        verbose=True, save_model_path=model_path,\n",
    "        inverse_transform=inverse_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(best_model, loader, device, inverse_transform):\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    \n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for data,label in loader:\n",
    "            data = data.float().to(device)\n",
    "\n",
    "            output = best_model(data)\n",
    "            output = inverse_transform(output)\n",
    "            output = output.cpu().numpy().tolist()\n",
    "\n",
    "            label  = inverse_transform(label)\n",
    "            label = label.cpu().numpy().tolist()\n",
    "\n",
    "            true_list += label\n",
    "            pred_list += output\n",
    "\n",
    "    return true_list, pred_list\n",
    "\n",
    "def inference(best_model, loader, device, inverse_transform):\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    \n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.float().to(device)\n",
    "\n",
    "            output = best_model(data)\n",
    "            output = inverse_transform(output)\n",
    "            output = output.cpu().numpy().tolist()\n",
    "\n",
    "            pred_list += output\n",
    "\n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true, pred = predict(best_model, train_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "# print(criterion(torch.tensor(true), torch.tensor(pred)).item())\n",
    "# true[:5], pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4a1097b90445ae96e882b910e0711e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb990347f66403eb219ce1f0b5868b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e66ccc70da455f8c31178dab083ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abd7bdc4f3644a291ebc7ccb3a1527c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c57984658f24c4888c305a1058c82f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018b1aa89d1642da908df252514a4fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9f07912394e63a77efa5db04621ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80ad225c08d41ea84b8b70f53aa5d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30dd4396a6d44b7a710a6ea349e2389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862c8e431fab4c759804519931ed1663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0f8be5fd6c4c9aaed89f83ef1c082f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar_outer = tqdm(품목_리스트, position=0)\n",
    "for 품목명 in pbar_outer:\n",
    "    pbar_outer.set_description(품목명)\n",
    "    model_path = f'models/best_model_{품목명}.pth'\n",
    "\n",
    "    # preprocessing\n",
    "    train_data, scaler = process_data(\"data/train/train.csv\", \"data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \"data/train/meta/TRAIN_전국도매_2018-2021.csv\", 품목명)\n",
    "    품목별_scalers[품목명] = scaler\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "\n",
    "    # train, validation split\n",
    "    tr_data, val_data = train_test_split(dataset, test_size=CFG.test_size, random_state=CFG.seed)\n",
    "    train_loader = DataLoader(tr_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    # define model\n",
    "    model = PricePredictionLSTM(\n",
    "        input_size=len(dataset.numeric_columns),\n",
    "        hidden_size=CFG.hidden_size,\n",
    "        num_layers=CFG.num_layers,\n",
    "        output_size=CFG.output_size,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # inference\n",
    "    품목_predictions = []\n",
    "    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n",
    "    for i in pbar_inner:\n",
    "        test_file = f\"data/test/TEST_{i:02d}.csv\"\n",
    "        산지공판장_file = f\"data/test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "        전국도매_file = f\"data/test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "        \n",
    "        test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scalers=품목별_scalers[품목명])\n",
    "        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        predictions = inference(model, test_loader, device='cpu', inverse_transform=inverse_transform)\n",
    "        predictions_array = np.concatenate(predictions)\n",
    "\n",
    "        # 예측값을 원래 스케일로 복원\n",
    "        price_column_index = test_data.columns.get_loc(test_dataset.price_column)\n",
    "        predictions_reshaped = predictions_array.reshape(-1, 1)\n",
    "        \n",
    "        # 가격 열에 대해서만 inverse_transform 적용\n",
    "        price_scaler = 품목별_scalers[품목명][test_dataset.price_column]\n",
    "        predictions_original_scale = price_scaler.inverse_transform(predictions_reshaped)\n",
    "        #print(predictions_original_scale)\n",
    "        \n",
    "        if np.isnan(predictions_original_scale).any():\n",
    "            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n",
    "        else:\n",
    "            pbar_inner.set_postfix({\"상태\": \"정상\"})\n",
    "            품목_predictions.extend(predictions_original_scale.flatten())\n",
    "\n",
    "    품목별_predictions[품목명] = 품목_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "for 품목명, predictions in 품목별_predictions.items():\n",
    "    sample_submission[품목명] = predictions\n",
    "\n",
    "# 결과 저장\n",
    "sample_submission.to_csv('out/baseline_submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시점</th>\n",
       "      <th>감자</th>\n",
       "      <th>건고추</th>\n",
       "      <th>깐마늘(국산)</th>\n",
       "      <th>대파</th>\n",
       "      <th>무</th>\n",
       "      <th>배추</th>\n",
       "      <th>사과</th>\n",
       "      <th>상추</th>\n",
       "      <th>양파</th>\n",
       "      <th>배</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00+1순</td>\n",
       "      <td>39402.344386</td>\n",
       "      <td>825.519388</td>\n",
       "      <td>40437.412822</td>\n",
       "      <td>1993.361973</td>\n",
       "      <td>183770.685105</td>\n",
       "      <td>3902.466552</td>\n",
       "      <td>440294.429588</td>\n",
       "      <td>12291.798734</td>\n",
       "      <td>9887.388630</td>\n",
       "      <td>20384.453007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00+2순</td>\n",
       "      <td>39478.646135</td>\n",
       "      <td>838.424068</td>\n",
       "      <td>42068.813764</td>\n",
       "      <td>1930.211177</td>\n",
       "      <td>181745.858206</td>\n",
       "      <td>3513.722772</td>\n",
       "      <td>427138.775887</td>\n",
       "      <td>10387.277291</td>\n",
       "      <td>10864.845885</td>\n",
       "      <td>19815.690907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00+3순</td>\n",
       "      <td>38884.611926</td>\n",
       "      <td>860.372464</td>\n",
       "      <td>41275.555334</td>\n",
       "      <td>1919.129537</td>\n",
       "      <td>177245.254816</td>\n",
       "      <td>3121.041671</td>\n",
       "      <td>431831.256138</td>\n",
       "      <td>9567.529182</td>\n",
       "      <td>8834.245243</td>\n",
       "      <td>19423.659943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_01+1순</td>\n",
       "      <td>45454.679849</td>\n",
       "      <td>421263.080302</td>\n",
       "      <td>125303.177261</td>\n",
       "      <td>2894.849287</td>\n",
       "      <td>10568.380954</td>\n",
       "      <td>15688.484209</td>\n",
       "      <td>17209.832390</td>\n",
       "      <td>1104.576767</td>\n",
       "      <td>1184.401613</td>\n",
       "      <td>20981.862262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_01+2순</td>\n",
       "      <td>45910.652578</td>\n",
       "      <td>416158.069756</td>\n",
       "      <td>130844.609961</td>\n",
       "      <td>2975.710887</td>\n",
       "      <td>11417.501638</td>\n",
       "      <td>13759.076211</td>\n",
       "      <td>16779.472052</td>\n",
       "      <td>1009.536278</td>\n",
       "      <td>1269.853558</td>\n",
       "      <td>21072.462074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TEST_23+2순</td>\n",
       "      <td>44761.402274</td>\n",
       "      <td>463844.473299</td>\n",
       "      <td>130664.061836</td>\n",
       "      <td>2370.184123</td>\n",
       "      <td>9777.872170</td>\n",
       "      <td>9966.538805</td>\n",
       "      <td>17140.386976</td>\n",
       "      <td>987.677060</td>\n",
       "      <td>1253.188329</td>\n",
       "      <td>20903.566730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>TEST_23+3순</td>\n",
       "      <td>43942.855160</td>\n",
       "      <td>468823.511117</td>\n",
       "      <td>128008.274095</td>\n",
       "      <td>2508.367281</td>\n",
       "      <td>8440.847760</td>\n",
       "      <td>9403.988863</td>\n",
       "      <td>17345.433497</td>\n",
       "      <td>1001.708176</td>\n",
       "      <td>1084.844786</td>\n",
       "      <td>20741.441249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>TEST_24+1순</td>\n",
       "      <td>44907.821412</td>\n",
       "      <td>444148.625659</td>\n",
       "      <td>105376.220160</td>\n",
       "      <td>2551.209933</td>\n",
       "      <td>16328.456249</td>\n",
       "      <td>22419.594134</td>\n",
       "      <td>20870.917773</td>\n",
       "      <td>1225.121626</td>\n",
       "      <td>832.276808</td>\n",
       "      <td>27396.264443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>TEST_24+2순</td>\n",
       "      <td>42038.049009</td>\n",
       "      <td>445259.760441</td>\n",
       "      <td>111785.083052</td>\n",
       "      <td>2493.045818</td>\n",
       "      <td>16071.094975</td>\n",
       "      <td>19880.580412</td>\n",
       "      <td>20688.325333</td>\n",
       "      <td>1266.507841</td>\n",
       "      <td>673.872516</td>\n",
       "      <td>27363.765844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>TEST_24+3순</td>\n",
       "      <td>38139.537465</td>\n",
       "      <td>445570.232935</td>\n",
       "      <td>107714.751916</td>\n",
       "      <td>2688.146357</td>\n",
       "      <td>15341.245993</td>\n",
       "      <td>22614.462776</td>\n",
       "      <td>20534.620538</td>\n",
       "      <td>1402.583449</td>\n",
       "      <td>867.500142</td>\n",
       "      <td>27553.709876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            시점            감자            건고추        깐마늘(국산)           대파  \\\n",
       "0   TEST_00+1순  39402.344386     825.519388   40437.412822  1993.361973   \n",
       "1   TEST_00+2순  39478.646135     838.424068   42068.813764  1930.211177   \n",
       "2   TEST_00+3순  38884.611926     860.372464   41275.555334  1919.129537   \n",
       "3   TEST_01+1순  45454.679849  421263.080302  125303.177261  2894.849287   \n",
       "4   TEST_01+2순  45910.652578  416158.069756  130844.609961  2975.710887   \n",
       "..         ...           ...            ...            ...          ...   \n",
       "70  TEST_23+2순  44761.402274  463844.473299  130664.061836  2370.184123   \n",
       "71  TEST_23+3순  43942.855160  468823.511117  128008.274095  2508.367281   \n",
       "72  TEST_24+1순  44907.821412  444148.625659  105376.220160  2551.209933   \n",
       "73  TEST_24+2순  42038.049009  445259.760441  111785.083052  2493.045818   \n",
       "74  TEST_24+3순  38139.537465  445570.232935  107714.751916  2688.146357   \n",
       "\n",
       "                무            배추             사과            상추            양파  \\\n",
       "0   183770.685105   3902.466552  440294.429588  12291.798734   9887.388630   \n",
       "1   181745.858206   3513.722772  427138.775887  10387.277291  10864.845885   \n",
       "2   177245.254816   3121.041671  431831.256138   9567.529182   8834.245243   \n",
       "3    10568.380954  15688.484209   17209.832390   1104.576767   1184.401613   \n",
       "4    11417.501638  13759.076211   16779.472052   1009.536278   1269.853558   \n",
       "..            ...           ...            ...           ...           ...   \n",
       "70    9777.872170   9966.538805   17140.386976    987.677060   1253.188329   \n",
       "71    8440.847760   9403.988863   17345.433497   1001.708176   1084.844786   \n",
       "72   16328.456249  22419.594134   20870.917773   1225.121626    832.276808   \n",
       "73   16071.094975  19880.580412   20688.325333   1266.507841    673.872516   \n",
       "74   15341.245993  22614.462776   20534.620538   1402.583449    867.500142   \n",
       "\n",
       "               배  \n",
       "0   20384.453007  \n",
       "1   19815.690907  \n",
       "2   19423.659943  \n",
       "3   20981.862262  \n",
       "4   21072.462074  \n",
       "..           ...  \n",
       "70  20903.566730  \n",
       "71  20741.441249  \n",
       "72  27396.264443  \n",
       "73  27363.765844  \n",
       "74  27553.709876  \n",
       "\n",
       "[75 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv('out/baseline_submission.csv')\n",
    "# sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
