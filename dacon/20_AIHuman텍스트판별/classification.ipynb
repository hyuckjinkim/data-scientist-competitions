{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install pororo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 42\n",
    "    EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Volumes/KHJ/Github/hyuckjinkim/lib-python/torch')\n",
    "\n",
    "from torch_seed import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "데이터를 Pandas의 DataFrame 형식으로 불러오고 어떤 구조인지 확인해 봅니다.  \n",
    "\n",
    "`train_df`의 경우, id, 네 개의 문장, 정답 문장 번호가 포함되어 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence3</th>\n",
       "      <th>sentence4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>직원들 마음에 들지 않는다는 것은 알겠지만, 가지 말아야 할까? 인터넷에서 싸게 살...</td>\n",
       "      <td>직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...</td>\n",
       "      <td>직원들 정말 싸가지 없네요 ㅋㅋㅋㅋ 인터넷에서 더 싸게 구입할 수 있다는 걸 알면서...</td>\n",
       "      <td>직원들의 태도가 정말 별로였어요 ㅋㅋㅋㅋ 가볼만한 가게라는 소문을 듣고 인터넷으로 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>분위기 최고! 2층 창문이 넓어서 공기가 통하는 느낌이에요. 조명도 멋지고 음료와 ...</td>\n",
       "      <td>분위기가 너무 좋아요! 2층 창문이 넓어서 쾌적한 느낌이에요. 조명도 아름답고 음료...</td>\n",
       "      <td>분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...</td>\n",
       "      <td>분위기가 너무 좋아요! 2층 창문이 크고 넓어서 탁 트여있는 느낌이에요. 조명도 예...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>일단, 장사가 잘 되길 바라는 마음에서 별 다섯 개 드립니다. 간도 딱 맞았고, 저...</td>\n",
       "      <td>일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...</td>\n",
       "      <td>일단 저는 장사가 잘되기를 바라는 마음에서 별 다섯 개를 주고 싶어요. 맛도 딱 맞...</td>\n",
       "      <td>먼저, 칭찬과 응원의 의미로 별 다섯 개를 주고 싶습니다. 간도 딱 맞고, 저는 매...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>1편의 독특함 때문에 살짝 뒤로 밀린 느낌이 있지만, 여전히 재미있어요. 게임 시스...</td>\n",
       "      <td>1편의 신선함에 비해 약간 빛이 바래 보이지만, 여전히 재미있게 즐길 수 있어요. ...</td>\n",
       "      <td>1편의 독특함 때문에 약간의 비교가 불가피하지만, 이 게임은 여전히 흥미로워요. 시...</td>\n",
       "      <td>1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...</td>\n",
       "      <td>빵점을 주고 싶지만 참아냈습니다... 이 영화는 사상 유래가 없는 것 같아요. 조지...</td>\n",
       "      <td>빵점 주고 싶을 정도로 엄청 실망했어요... 이 영화는 별들의 전쟁처럼 역사적인 작...</td>\n",
       "      <td>빵점을 주고 싶었는데 참았어요... 이런 영화는 전례가 없는데, 조지 루카스의 스타...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          sentence1  \\\n",
       "0  TRAIN_000  직원들 마음에 들지 않는다는 것은 알겠지만, 가지 말아야 할까? 인터넷에서 싸게 살...   \n",
       "1  TRAIN_001  분위기 최고! 2층 창문이 넓어서 공기가 통하는 느낌이에요. 조명도 멋지고 음료와 ...   \n",
       "2  TRAIN_002  일단, 장사가 잘 되길 바라는 마음에서 별 다섯 개 드립니다. 간도 딱 맞았고, 저...   \n",
       "3  TRAIN_003  1편의 독특함 때문에 살짝 뒤로 밀린 느낌이 있지만, 여전히 재미있어요. 게임 시스...   \n",
       "4  TRAIN_004  빵점 주고 싶은걸 간신히 참았다...이런건 사상 유래가 없는,조지 루카스 영감의 스...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  직원들 진짜 싸가지 없어요 ㅋㅋㅋㅋ 가지 마숑  인터넷이 더 싼거 알면서도 이것저것...   \n",
       "1  분위기가 너무 좋아요! 2층 창문이 넓어서 쾌적한 느낌이에요. 조명도 아름답고 음료...   \n",
       "2  일단 장사가 잘되길 바라는 마음에서 별5개 드립니다 간도 맞았고 매운걸 좋아하는 입...   \n",
       "3  1편의 신선함에 비해 약간 빛이 바래 보이지만, 여전히 재미있게 즐길 수 있어요. ...   \n",
       "4  빵점을 주고 싶지만 참아냈습니다... 이 영화는 사상 유래가 없는 것 같아요. 조지...   \n",
       "\n",
       "                                           sentence3  \\\n",
       "0  직원들 정말 싸가지 없네요 ㅋㅋㅋㅋ 인터넷에서 더 싸게 구입할 수 있다는 걸 알면서...   \n",
       "1  분위기가 짱!! 2층 창문이 커서 탁 트여있는 느낌이에요 ㅎㅎ 조명도 예쁘고 음료랑...   \n",
       "2  일단 저는 장사가 잘되기를 바라는 마음에서 별 다섯 개를 주고 싶어요. 맛도 딱 맞...   \n",
       "3  1편의 독특함 때문에 약간의 비교가 불가피하지만, 이 게임은 여전히 흥미로워요. 시...   \n",
       "4  빵점 주고 싶을 정도로 엄청 실망했어요... 이 영화는 별들의 전쟁처럼 역사적인 작...   \n",
       "\n",
       "                                           sentence4  label  \n",
       "0  직원들의 태도가 정말 별로였어요 ㅋㅋㅋㅋ 가볼만한 가게라는 소문을 듣고 인터넷으로 ...      2  \n",
       "1  분위기가 너무 좋아요! 2층 창문이 크고 넓어서 탁 트여있는 느낌이에요. 조명도 예...      3  \n",
       "2  먼저, 칭찬과 응원의 의미로 별 다섯 개를 주고 싶습니다. 간도 딱 맞고, 저는 매...      2  \n",
       "3  1편이 워낙 참신했던 탓에 좀 묻힌 감이 있긴 하지만 재미는 여전합니다. 시스템도 ...      4  \n",
       "4  빵점을 주고 싶었는데 참았어요... 이런 영화는 전례가 없는데, 조지 루카스의 스타...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 6), (1100, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.copy()\n",
    "data.drop('id',axis=1,inplace=True)\n",
    "\n",
    "new_data = []\n",
    "for d in data.values:\n",
    "    sentence = d[:-1]\n",
    "    label    = d[-1]\n",
    "    \n",
    "    human_sentence = sentence[label-1]\n",
    "    ai_sentence    = sentence[sentence!=human_sentence]\n",
    "    \n",
    "    new_d = pd.concat([\n",
    "        pd.DataFrame([human_sentence],columns=['text']).assign(label=1),\n",
    "        pd.DataFrame(ai_sentence     ,columns=['text']).assign(label=0),\n",
    "    ],axis=0)\n",
    "    new_data.append(new_d)\n",
    "    \n",
    "new_data = pd.concat(new_data,axis=0)\n",
    "new_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pororo import Pororo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khj/anaconda3/envs/torch_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast, GPT2ForSequenceClassification\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text  = self.data.text[index]\n",
    "        label = self.data.label[index]\n",
    "        \n",
    "        encoded_dict = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens = True,\n",
    "            max_length = 512,\n",
    "            pad_to_max_length = True,\n",
    "            truncation = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt',\n",
    "        )\n",
    "        padded_token_list = encoded_dict['input_ids'][0]\n",
    "        att_mask = encoded_dict['attention_mask'][0]\n",
    "\n",
    "        return {'input_ids': padded_token_list, 'attention_mask': att_mask, 'labels': label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 2) (40, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(new_data,test_size=0.2,shuffle=True,random_state=CFG.SEED)\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "val_data  .reset_index(drop=True,inplace=True)\n",
    "print(train_data.shape, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    \"skt/kogpt2-base-v2\",\n",
    "    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "    pad_token='<pad>', mask_token='<mask>',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CompDataset(data=train_data,tokenizer=tokenizer)\n",
    "val_dataset   = CompDataset(val_data  ,tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset  , batch_size=8, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.model = GPT2ForSequenceClassification.from_pretrained(\"skt/kogpt2-base-v2\", num_labels=num_classes, return_dict=True, problem_type=\"single_label_classification\")\n",
    "        # self.model = AutoModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "        # self.model.fc = nn.Linear(self.model.ln_f.normalized_shape[0], num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        # inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        # outputs = self.model(**inputs,return_dict=True)\n",
    "        # return outputs\n",
    "        \n",
    "        outputs = self.model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            labels = labels,\n",
    "        )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 현재 GPU가 사용 가능한지 확인합니다.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at skt/kogpt2-base-v2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (model): GPT2ForSequenceClassification(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(51200, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (score): Linear(in_features=768, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaseModel(num_classes=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khj/anaconda3/envs/torch_env/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Iter:   0%|                                        | 0/20 [00:00<?, ?it/s]/Users/khj/anaconda3/envs/torch_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 10%|████▎                                      | 1/10 [03:25<30:52, 205.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.8239, val_loss=0.4459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [07:10<28:56, 217.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=1.1821, val_loss=1.1697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [10:57<25:50, 221.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.6065, val_loss=0.5278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [14:41<22:14, 222.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.6243, val_loss=1.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [18:25<18:34, 222.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.8064, val_loss=0.4554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [22:10<14:54, 223.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.8100, val_loss=0.9362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [25:55<11:12, 224.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.6110, val_loss=0.6024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [29:40<07:28, 224.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.4587, val_loss=0.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [33:23<03:43, 223.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.8616, val_loss=0.4562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [37:08<00:00, 222.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.3414, val_loss=0.4443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in trange(CFG.EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    pbar = tqdm(train_loader,desc='Train Iter',leave=False,position=0)\n",
    "    for inputs in pbar:\n",
    "        labels  = inputs['labels']\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        #loss = outputs.loss\n",
    "        log_probs = F.log_softmax(outputs.logits, dim=1)\n",
    "        loss = criterion(log_probs, labels)\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        pbar = tqdm(val_loader,desc='Validation Iter',leave=False,position=0)\n",
    "        for inputs in pbar:\n",
    "            labels  = inputs['labels']\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            #loss = outputs.loss\n",
    "            log_probs = F.log_softmax(outputs.logits, dim=1)\n",
    "            loss = criterion(log_probs, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    progress = 'loss={:.4f}, val_loss={:.4f}'.format(np.mean(train_loss),np.mean(val_loss))\n",
    "    print(progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "train_df에서 행 하나를 랜덤하게 추출하여 example로 사용합니다(one-shot)  \n",
    "\n",
    "이때 실제 사람이 작성한 리뷰에 대해서는 '-> O'로 표시하고 그렇지 않은 리뷰에 대해서는 '-> X'로 표기합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence_format = \"\"\"\n",
    "전달하는 4개의 문장 중에서 1개만 사람이 작성한 것이고, 나머지는 AI가 작성한 것입니다.\n",
    "주어진 문장이 사람이 작성한 것이 맞으면 O, 아니면 X를 반환하세요.\n",
    "\n",
    "# 예시는 아래와 같습니다.\n",
    "문장1 : {} -> {}\n",
    "문장2 : {} -> {}\n",
    "문장3 : {} -> {}\n",
    "문장4 : {} -> {}\n",
    "\n",
    "# 문제는 아래와 같습니다.\n",
    "문장 : {}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    # 각 테스트 케이스에 대해\n",
    "    for idx in tqdm(range(len(test_df))):\n",
    "        row = test_df.iloc[idx]\n",
    "        best_score = float('-inf')\n",
    "        best_label = 0\n",
    "        \n",
    "        # train 데이터에서 랜덤하게 문장을 가져옵니다.\n",
    "        random_row = train_df.sample(1).iloc[0]\n",
    "        random_answer = random_row['label']\n",
    "        random_labels = {}\n",
    "        for i in range(1, 5):\n",
    "            random_labels[f'sentence{i}'] = 'O' if i == random_answer else 'X'\n",
    "\n",
    "        # 각 문장에 대한 확률값을 구하고, 가장 높은 확률값을 가진 문장을 선택합니다.\n",
    "        for i in range(1, 5):\n",
    "            # GPT-2에게 제공할 prompt를 작성합니다.\n",
    "            prompt = example_sentence_format.format(\n",
    "                random_row['sentence1'],random_labels['sentence1'],\n",
    "                random_row['sentence2'],random_labels['sentence2'],\n",
    "                random_row['sentence3'],random_labels['sentence3'],\n",
    "                random_row['sentence4'],random_labels['sentence4'],\n",
    "                row[f'sentence{i}']\n",
    "            )\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "            inputs = inputs.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                score = outputs[0][:, -1, :].max().item()\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_label = i\n",
    "\n",
    "        preds.append(best_label)\n",
    "        \n",
    "        ddasfsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "\n",
    "본 대회에서는 각 케이스에 대한 예측값을 두 개 제출할 수 있기 때문에 나머지 하나를 채워줍니다.  \n",
    "\n",
    "베이스라인에서는 1,2,3,4 중에서 4를 예시로 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [str(pred) + '4' for pred in preds]\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "데이터셋에 함께 제공되는 `sample_submission.csv` 파일을 불러와서 `label` 칼럼을 업데이트하고 결과를 제출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env_3.10.13",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
