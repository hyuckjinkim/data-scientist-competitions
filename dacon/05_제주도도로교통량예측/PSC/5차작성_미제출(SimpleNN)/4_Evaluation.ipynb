{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb084c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Setting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64e7b73",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf30c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytimekr\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d MyPython/2_Dacon_JEJU/DAT/\n",
    "# unzip open.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fe = fm.FontEntry(fname='../NanumFont/NanumGothic.ttf',name='NanumGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)  # or append is fine\n",
    "mpl.rcParams['font.family'] = fe.name # = 'your custom ttf font name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18df5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # FutureWarning 제거\n",
    "os.environ['PYTHONWARNINGS']='ignore::FutureWarning'\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "from pytimekr import pytimekr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# import datatable as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab93b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/24983493/tracking-progress-of-joblib-parallel-execution\n",
    "\n",
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6be74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept, color):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--',color=color)\n",
    "    \n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print('Error: Creating directory. ' + directory)\n",
    "        \n",
    "def cnt(x):\n",
    "    vc = x.value_counts().sort_index()\n",
    "    res = pd.DataFrame({\n",
    "        'index' : vc.index,\n",
    "        'freq'  : vc.values,\n",
    "    })\n",
    "    res['rate'] = 100 * res['freq'] / res['freq'].sum()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df448802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# verbose=0로 만들어주는 함수\n",
    "# (참조) https://stackoverflow.com/questions/11130156/suppress-stdout-stderr-print-from-python-functions\n",
    "class suppress_stdout_stderr(object):\n",
    "    '''\n",
    "    A context manager for doing a \"deep suppression\" of stdout and stderr in\n",
    "    Python, i.e. will suppress all print, even if the print originates in a\n",
    "    compiled C/Fortran sub-function.\n",
    "       This will not suppress raised exceptions, since exceptions are printed\n",
    "    to stderr just before a script exits, and after the context manager has\n",
    "    exited (at least, I think that is why it lets exceptions through).\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Open a pair of null files\n",
    "        self.null_fds = [os.open(os.devnull, os.O_RDWR) for x in range(2)]\n",
    "        # Save the actual stdout (1) and stderr (2) file descriptors.\n",
    "        self.save_fds = (os.dup(1), os.dup(2))\n",
    "\n",
    "    def __enter__(self):\n",
    "        # Assign the null pointers to stdout and stderr.\n",
    "        os.dup2(self.null_fds[0], 1)\n",
    "        os.dup2(self.null_fds[1], 2)\n",
    "\n",
    "    def __exit__(self, *_):\n",
    "        # Re-assign the real stdout/stderr back to (1) and (2)\n",
    "        os.dup2(self.save_fds[0], 1)\n",
    "        os.dup2(self.save_fds[1], 2)\n",
    "        # Close the null files\n",
    "        os.close(self.null_fds[0])\n",
    "        os.close(self.null_fds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7d4cc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "User Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.MyModel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a46fac",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Initial Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86796f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAT_PATH = \"../DAT/\"\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_SETTING = '/device:GPU:0' #'/device:CPU:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75d352",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d09b17",
   "metadata": {},
   "source": [
    "---\n",
    "# Modeling\n",
    "---\n",
    "- tf.data.dataset 참조\n",
    "    - [참조1](https://nodoudt.tistory.com/43)\n",
    "    - [참조2](https://ericabae.medium.com/tensorflow-2-0-csv-%ED%8C%8C%EC%9D%BC-%ED%98%95%EC%8B%9D-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0-eddaa88d3112)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59dd83",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.layers import Input, Dense, RepeatVector, LSTM, GRU, TimeDistributed, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(file_path,batch_size,num_epochs,is_pack,shuffle,**kwargs):\n",
    "    \n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_path,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        ignore_errors=True, \n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    def pack(features, label):\n",
    "        return tf.stack(list(features.values()), axis=-1), label\n",
    "    \n",
    "    if is_pack:\n",
    "        dataset = dataset.map(pack)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(500)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4284b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "segment = [path.replace('../MDL/DL/model_','').replace('.h5','') for path in glob.glob('../MDL/DL/*')]\n",
    "segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d85e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = segment[3]\n",
    "\n",
    "train_dataset = get_dataset(\n",
    "    file_path=f'../OUT/segment/{seg}/train_df.csv',\n",
    "    batch_size=16,\n",
    "    num_epochs=1,\n",
    "    label_name='target',\n",
    "    is_pack=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataset = get_dataset(\n",
    "    file_path=f'../OUT/segment/{seg}/test_df.csv',\n",
    "    batch_size=16,\n",
    "    num_epochs=1,\n",
    "    is_pack=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(units=512,activation='elu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units=256,activation='elu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units=1,activation=None,kernel_constraint='non_neg'))\n",
    "# model.compile(optimizer=Adam(learning_rate=0.01),loss='huber',metrics=['mse'])\n",
    "\n",
    "model = tf.keras.models.load_model(f'../MDL/DL/model_{seg}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'../OUT/segment/{seg}/train_df.csv')\n",
    "# test_df  = pd.read_csv(f'../OUT/segment/{seg}/test_df.csv')\n",
    "\n",
    "true = train_df.target\n",
    "pred = model.predict(train_dataset).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fe3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_true=true,y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datatable as dt\n",
    "\n",
    "tr_tmp = dt.fread(f'../OUT/train_fn_oh_noseg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tmp.shape[0]/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7564f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.814814814814814"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25*(65*256/3600/24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
