{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cb2702",
   "metadata": {
    "id": "pYzhJrEibIlq"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1675db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rdkit\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57add532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b58500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21e555ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    SEED = 0\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 1024\n",
    "    LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a1cd5",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984079d6",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab172baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df  = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c45c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             SMILES     MLM  \\\n",
       "0  TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n",
       "1  TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n",
       "2  TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n",
       "3  TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   \n",
       "4  TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n",
       "\n",
       "      HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
       "0  50.680  3.259           400.495                5             2   \n",
       "1  50.590  2.169           301.407                2             1   \n",
       "2  80.892  1.593           297.358                5             0   \n",
       "3   2.000  4.771           494.652                6             0   \n",
       "4  99.990  2.335           268.310                3             0   \n",
       "\n",
       "   Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  \n",
       "0                   8  3.259                      117.37  \n",
       "1                   2  2.172                       73.47  \n",
       "2                   3  1.585                       62.45  \n",
       "3                   5  3.475                       92.60  \n",
       "4                   1  2.337                       42.43  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cee76",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3dc687",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40db90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd0b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = train_df.columns[train_df.dtypes!='object'].tolist()\n",
    "# for i,col in enumerate(num_features):\n",
    "\n",
    "#     fig = plt.figure(figsize=(15,7))\n",
    "#     fig.add_subplot(121)\n",
    "#     sns.histplot(train_df[col],bins=20)\n",
    "#     plt.grid()\n",
    "\n",
    "#     fig.add_subplot(122)\n",
    "#     sns.histplot(np.log(train_df[col]+1e-3),bins=20)\n",
    "#     plt.grid()\n",
    "\n",
    "#     plt.suptitle('[{}/{}] {}'.format(i+1,len(num_features),col))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # -> ['Molecular_Weight','Molecular_PolarSurfaceArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ff85b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "# for col in cols:\n",
    "#     print(col)\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.scatterplot(x=train_df[col],y=train_df['HLM'])\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3824957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds']\n",
    "# for col in cols:\n",
    "#     print(col)\n",
    "#     plt.figure(figsize=(15,7))\n",
    "#     sns.boxplot(x=train_df[col],y=train_df.MLM)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4420697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1721f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists = sorted(train_df['Num_H_Acceptors'].unique())\n",
    "# for v in lists:\n",
    "#     print('########',v)\n",
    "#     d = train_df[train_df['Num_H_Acceptors']==v]\n",
    "    \n",
    "#     cols = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors','Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "#     for col in cols:\n",
    "#         print(col)\n",
    "#         plt.figure(figsize=(15,7))\n",
    "#         sns.scatterplot(x=d[col],y=d['HLM'])\n",
    "#         plt.grid()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef7768",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e266dfe",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd1f24",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8901e1c",
   "metadata": {},
   "source": [
    "## Set target range to [0,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf99075",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['MLM','HLM']\n",
    "for t in targets:\n",
    "    train_df[t] = [0 if x<0 else\n",
    "                   100 if x>100 else\n",
    "                   x for x in train_df[t]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc11232",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb497820",
   "metadata": {},
   "source": [
    "## Make molecule features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6dbcab1",
   "metadata": {
    "id": "oXOFfJVW22DL"
   },
   "outputs": [],
   "source": [
    "# Molecule to MorganFingerprint\n",
    "def mol2fp(mol):\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, 6, nBits=4096)\n",
    "    ar = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0db561",
   "metadata": {
    "id": "7KbqRv6I19Rg"
   },
   "outputs": [],
   "source": [
    "# (1) SMILES를 통해 Molecule(분자구조) 생성\n",
    "PandasTools.AddMoleculeColumnToFrame(train_df,'SMILES','Molecule')\n",
    "PandasTools.AddMoleculeColumnToFrame(test_df ,'SMILES','Molecule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e72296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd86e9dc",
   "metadata": {
    "id": "1MTlg0wx22DM"
   },
   "outputs": [],
   "source": [
    "# (2) Morgan Fingerprint column 추가\n",
    "train_df[\"FPs\"] = train_df.Molecule.apply(mol2fp)\n",
    "test_df [\"FPs\"] = test_df .Molecule.apply(mol2fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af4d96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498\n"
     ]
    }
   ],
   "source": [
    "# (3) Morgan Fingerprint 중, variance가 0.05보다 작은 컬럼들을 지우기\n",
    "feature_select = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "# 일부사용\n",
    "tr_fps_selected = feature_select.fit_transform(np.stack(train_df['FPs']))\n",
    "te_fps_selected = feature_select.transform(np.stack(test_df['FPs']))\n",
    "print(len(tr_fps_selected))\n",
    "\n",
    "# # 전체사용\n",
    "# tr_fps_selected = np.stack(train_df['FPs'])\n",
    "# te_fps_selected = np.stack(test_df ['FPs'])\n",
    "\n",
    "fps_names = ['fps'+str(i+1) for i in range(tr_fps_selected.shape[1])]\n",
    "\n",
    "train_df = pd.concat([\n",
    "    train_df.drop('FPs',axis=1),\n",
    "    pd.DataFrame(tr_fps_selected,columns=fps_names),\n",
    "],axis=1)\n",
    "\n",
    "test_df = pd.concat([\n",
    "    test_df.drop('FPs',axis=1),\n",
    "    pd.DataFrame(te_fps_selected,columns=fps_names),\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20823c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fps_raw_sum'] = np.sum(train_df[fps_names].values,axis=1)\n",
    "test_df ['fps_raw_sum'] = np.sum(test_df [fps_names].values,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc14ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:00<00:00, 1027.46it/s]\n"
     ]
    }
   ],
   "source": [
    "fps_dummy_names = []\n",
    "for col in tqdm(fps_names):\n",
    "    train_df[f'{col}_dmy'] = np.where(train_df[col]==0,0,1)\n",
    "    test_df [f'{col}_dmy'] = np.where(test_df [col]==0,0,1)\n",
    "    fps_dummy_names.append(f'{col}_dmy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c98f3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fps_dummy_sum'] = np.sum(train_df[fps_names].values,axis=1)\n",
    "test_df ['fps_dummy_sum'] = np.sum(test_df [fps_names].values,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ea96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 column만 추출\n",
    "features = ['AlogP','Molecular_Weight','Num_H_Acceptors','Num_H_Donors',\n",
    "            'Num_RotatableBonds','LogD','Molecular_PolarSurfaceArea']\n",
    "fps_features = [col for col in train_df.columns if col.find('fps')==0]\n",
    "smiles_feature = 'SMILES'\n",
    "targets  = ['MLM','HLM']\n",
    "\n",
    "train_df = train_df[features+fps_features+[smiles_feature]+targets]\n",
    "test_df  = test_df[features+fps_features+[smiles_feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7904bb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3498, 514)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515fe47f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb68f7",
   "metadata": {},
   "source": [
    "## Imputaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a450e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccb5ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_check(data):\n",
    "    d = data.copy()\n",
    "    null_info = d.isnull().sum()\n",
    "    null_info = null_info[null_info!=0]\n",
    "    display(null_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b301fc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlogP    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlogP    1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('> train')\n",
    "null_check(train_df)\n",
    "\n",
    "print('> test')\n",
    "null_check(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "194a124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_features = ['AlogP']\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "train_df[null_features] = imputer.fit_transform(train_df[null_features])\n",
    "test_df [null_features] = imputer.transform(test_df[null_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d6ad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('> train')\n",
    "null_check(train_df)\n",
    "\n",
    "print('> test')\n",
    "null_check(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae361d6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f984bedd",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00f2a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de41c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_df, va_df = train_test_split(train_df,test_size=0.1,shuffle=True,random_state=CFG.SEED)\n",
    "# te_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b7acb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tr_df), len(va_df), len(te_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16cd5eb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804a2f3",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa7d336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaling_features = features#+fps_features\n",
    "scalers = {}\n",
    "for f in scaling_features:\n",
    "    scaler = MinMaxScaler()\n",
    "    train_df[f] = scaler.fit_transform(np.array(train_df[f]).reshape(-1,1))\n",
    "    test_df [f] = scaler.transform(np.array(test_df[f]).reshape(-1,1))\n",
    "    scalers[f] = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efe630",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcee91",
   "metadata": {},
   "source": [
    "## Interaction Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2487b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import trange\n",
    "\n",
    "def get_abs_corr(x,y):\n",
    "    return np.abs(np.corrcoef(x,y))[0,1]\n",
    "\n",
    "class InteractionTerm:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,data,num_features,corr_cutoff=0.7):\n",
    "        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        \n",
    "        d = data.copy()\n",
    "        self.interaction_list = []\n",
    "        for i in trange(len(num_features),desc='fitting...'):\n",
    "            for j in range(len(num_features)):\n",
    "                if i>j:\n",
    "                    col_i = num_features[i]\n",
    "                    col_j = num_features[j]\n",
    "                    \n",
    "                    # 상관계수가 cutoff보다 큰 경우에는 interaction을 생성하지 않음\n",
    "                    if (get_abs_corr(d[col_i]*d[col_j],d[col_i])>=corr_cutoff) | (get_abs_corr(d[col_i]*d[col_j],d[col_j])>=corr_cutoff):\n",
    "                        pass\n",
    "                    else:\n",
    "                        self.interaction_list.append(f'{col_i}*{col_j}')\n",
    "    \n",
    "    def transform(self,data):\n",
    "        d = data.copy()\n",
    "        print('> the number of interaction term:',len(self.interaction_list))\n",
    "        for interaction in self.interaction_list:\n",
    "            col_i,col_j = interaction.split('*')\n",
    "            d[interaction] = d[col_i]*d[col_j]\n",
    "        return d\n",
    "    \n",
    "    def fit_transform(self,data,num_features,corr_cutoff=0.7):\n",
    "        self.fit(data,num_features,corr_cutoff)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32205a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = features + fps_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "422c53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction_maker = InteractionTerm()\n",
    "# interaction_maker.fit(\n",
    "#     data=tr_df,\n",
    "#     num_features=num_features,\n",
    "#     corr_cutoff=0.15,\n",
    "# )\n",
    "# tr_df = interaction_maker.transform(tr_df)\n",
    "# va_df = interaction_maker.transform(va_df)\n",
    "# te_df = interaction_maker.transform(te_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62a9dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd533d4f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9397f24",
   "metadata": {},
   "source": [
    "## Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7696394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in targets:\n",
    "#     tr_df[t] = np.log(tr_df[t]+1e-3)\n",
    "#     va_df[t] = np.log(va_df[t]+1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "494b4f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverse_transform(x):\n",
    "#     return torch.exp(x)-1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "831f890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55873417",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaeb792",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1dec697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets, smiles, transforms=None, is_test=False):\n",
    "        self.data = data.copy()\n",
    "        self.targets = targets\n",
    "        self.smiles = smiles\n",
    "        self.transforms = transforms\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        self.smiles_features = []\n",
    "        for s in tqdm(data[smiles].values):\n",
    "            m = Chem.MolFromSmiles(s)\n",
    "            img = Draw.MolToImage(m)#, size=(224,224))\n",
    "            img = np.array(img)\n",
    "            if self.transforms is not None:\n",
    "                img = self.transforms(image=img)['image']\n",
    "            self.smiles_features.append(img)\n",
    "            \n",
    "        if not self.is_test:\n",
    "            self.target_features = self.data[self.targets].values\n",
    "            self.num_features = self.data.drop(columns=targets+[smiles],axis=1).values\n",
    "        else:\n",
    "            self.num_features = self.data.drop(columns=[smiles],axis=1).values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            return (\n",
    "                torch.Tensor(self.num_features[index]),\n",
    "                torch.Tensor(self.smiles_features[index]),\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                torch.Tensor(self.num_features[index]),\n",
    "                torch.Tensor(self.smiles_features[index]),\n",
    "                torch.Tensor(self.target_features[index]),\n",
    "            )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbfe79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "140387a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  이미지 변환\n",
    "transform = A.Compose([\n",
    "    A.Resize(CFG.IMG_SIZE,CFG.IMG_SIZE),\n",
    "    A.ToGray(p=1),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdf7c89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3498/3498 [00:33<00:00, 103.17it/s]\n",
      "100%|██████████| 483/483 [00:04<00:00, 104.23it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_df, ['MLM','HLM'], 'SMILES', transform, False)\n",
    "test_dataset  = CustomDataset(test_df , ['MLM','HLM'], 'SMILES', transform, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "feeb82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset , batch_size=CFG.BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54b758de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.smiles_features[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95f28210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [feat for feat,img,target in train_loader][0]\n",
    "# [img for feat,img in test_loader][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb6c2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# _img = [img for feat,img,target in train_loader][0][0].numpy()\n",
    "# plt.imshow(_img.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13aa860",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6cb1b",
   "metadata": {
    "id": "8CHzFfvrbnOM"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56760691",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53a93346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea38e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, feature_input_size, output_size, hidden_size, dropout_rate):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.image_output_size = 500\n",
    "        self.feature_output_size = 500\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # # efficientnet\n",
    "        # self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        # self.backbone.classifier = nn.Sequential(\n",
    "        #     nn.Dropout(p=0.2,inplace=True),\n",
    "        #     nn.Linear(self.backbone.classifier[-1].in_features,self.image_output_size),\n",
    "        # )\n",
    "        \n",
    "        # resnet\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features,self.image_output_size)\n",
    "        \n",
    "        self.image_layer = nn.Sequential(\n",
    "            self.backbone,\n",
    "            #nn.BatchNorm1d(self.image_output_size),\n",
    "            #nn.SiLU(),\n",
    "            #nn.Dropout(self.dropout_rate),\n",
    "        )\n",
    "        \n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(feature_input_size,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(hidden_size,self.feature_output_size),\n",
    "        )\n",
    "        \n",
    "        fc_input_size = self.image_output_size+self.feature_output_size\n",
    "        self.fc_1 = nn.Sequential(\n",
    "            nn.Linear(fc_input_size,fc_input_size//2),\n",
    "            nn.BatchNorm1d(fc_input_size//2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//2,fc_input_size//4),\n",
    "            nn.BatchNorm1d(fc_input_size//4),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//4,fc_input_size//8),\n",
    "            nn.BatchNorm1d(fc_input_size//8),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//8,fc_input_size//16),\n",
    "        )\n",
    "        self.fc_2 = nn.Sequential(\n",
    "            nn.Linear(fc_input_size,fc_input_size//2),\n",
    "            nn.BatchNorm1d(fc_input_size//2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//2,fc_input_size//4),\n",
    "            nn.BatchNorm1d(fc_input_size//4),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//4,fc_input_size//8),\n",
    "            nn.BatchNorm1d(fc_input_size//8),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//8,fc_input_size//16),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*(fc_input_size//16),fc_input_size//16),\n",
    "            nn.BatchNorm1d(fc_input_size//16),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//16,fc_input_size//32),\n",
    "            nn.BatchNorm1d(fc_input_size//32),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(self.dropout_rate),\n",
    "            nn.Linear(fc_input_size//32,output_size),\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, feature):\n",
    "        image_output = self.image_layer(image)\n",
    "        feature_output = self.feature_layer(feature)\n",
    "        combined = torch.cat((image_output,feature_output),dim=1)\n",
    "        output1 = self.fc_1(combined)\n",
    "        output2 = self.fc_2(combined)\n",
    "        output = torch.cat((output1,output2),dim=1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f0945",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177cf1e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca006173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiRMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        loss1 = torch.sqrt(torch.mean((output[:,0]-target[:,0])**2))\n",
    "        loss2 = torch.sqrt(torch.mean((output[:,1]-target[:,1])**2))\n",
    "        loss = 0.5*loss1+0.5*loss2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ddc4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        if self.path!='':\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "        \n",
    "def train(\n",
    "    model, criterion, optimizer, train_loader, valid_loader, epochs,\n",
    "    early_stopping, device='cpu', scheduler=None, metric_period=1, \n",
    "    verbose=True, save_model_path = './mc/best_model.pt',\n",
    "    use_best_model=True,\n",
    "    inverse_transform=None,\n",
    "):  \n",
    "    seed_everything(CFG.SEED)\n",
    "    model.to(device)\n",
    "\n",
    "    best_loss  = 999999999\n",
    "    best_epoch = 1\n",
    "    best_model = None\n",
    "    is_best    = np.nan\n",
    "    \n",
    "    start_time = time.time()\n",
    "    epoch_s = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        gc.collect()\n",
    "        \n",
    "        #model.train()\n",
    "        train_loss = []\n",
    "        for feat,img,target in train_loader:\n",
    "            feat = feat.to(device)\n",
    "            img = img.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img,feat)#.float()\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()  # Getting gradients\n",
    "            optimizer.step() # Updating parameters\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            valid_loss = validation(model, valid_loader, criterion, device, inverse_transform)\n",
    "        else:\n",
    "            valid_loss = np.mean(train_loss)\n",
    "            \n",
    "        epoch_e = time.time()\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        # update the best epoch & best loss\n",
    "        if (best_loss > valid_loss) | (epoch==1):\n",
    "            best_epoch = epoch\n",
    "            best_loss = valid_loss\n",
    "            best_model = model\n",
    "            is_best = 1\n",
    "            torch.save(best_model.state_dict(), save_model_path)\n",
    "        else:\n",
    "            is_best = 0\n",
    "            if not use_best_model:\n",
    "                torch.save(best_model.state_dict(), save_model_path)\n",
    "            \n",
    "        # 결과물 printing\n",
    "        if (verbose) & (epoch % metric_period == 0):\n",
    "            mark = '*' if is_best else ' '\n",
    "            epoch_str = str(epoch).zfill(len(str(epochs)))\n",
    "            if valid_loader is not None:\n",
    "                progress = '{}[{}/{}] loss: {:.5f}, val_loss: {:.5f}, best_epoch: {}, elapsed: {:.2f}s, total: {:.2f}s, remaining: {:.2f}s'\\\n",
    "                    .format(\n",
    "                        mark,\n",
    "                        epoch_str,\n",
    "                        epochs,\n",
    "                        np.mean(train_loss),\n",
    "                        valid_loss,\n",
    "                        best_epoch,\n",
    "                        epoch_e-epoch_s,\n",
    "                        epoch_e-start_time,\n",
    "                        (epoch_e-epoch_s)*(epochs-epoch)/metric_period,\n",
    "                    )\n",
    "            else:\n",
    "                progress = '{}[{}/{}] loss: {:.5f}, best_epoch: {}, elapsed: {:.2f}s, total: {:.2f}s, remaining: {:.2f}s'\\\n",
    "                    .format(\n",
    "                        mark,\n",
    "                        epoch_str,\n",
    "                        epochs,\n",
    "                        np.mean(train_loss),\n",
    "                        best_epoch,\n",
    "                        epoch_e-epoch_s,\n",
    "                        epoch_e-start_time,\n",
    "                        (epoch_e-epoch_s)*(epochs-epoch)/metric_period,\n",
    "                    )\n",
    "            epoch_s = time.time()\n",
    "            print(progress)\n",
    "\n",
    "        # early stopping 여부를 체크. 현재 과적합 상황 추적\n",
    "        if early_stopping is not None:\n",
    "            early_stopping(valid_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def validation(model, valid_loader, criterion, device, inverse_transform):\n",
    "    valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for feat,img,target in valid_loader:\n",
    "            feat = feat.to(device)\n",
    "            img = img.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(img,feat)#.float()\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            valid_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(valid_loss)\n",
    "\n",
    "def predict(best_model,loader,device,inverse_transform):\n",
    "    best_model.to(device)\n",
    "\n",
    "    true_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for feat,img,target in iter(loader):\n",
    "            feat = feat.to(device)\n",
    "            img = img.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = best_model(img,feat)\n",
    "            \n",
    "            if inverse_transform is not None:\n",
    "                output = inverse_transform(output)\n",
    "                target = inverse_transform(target)\n",
    "\n",
    "            true_list.append(target)\n",
    "            pred_list.append(output)\n",
    "\n",
    "    trues = torch.cat(true_list,dim=0)\n",
    "    preds = torch.cat(pred_list,dim=0)\n",
    "\n",
    "    trues = trues.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "\n",
    "    return trues, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39e203da",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_input_size = [feat for feat,smiles,target in train_dataset][0].shape[0]\n",
    "output_size = 2\n",
    "hidden_size = 64\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c67d8d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07f0254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskModel(feature_input_size,output_size,hidden_size,dropout_rate)\n",
    "criterion = MultiRMSELoss()\n",
    "# optimizer= torch.optim.Adam(model.parameters(), lr=CFG.LEARNING_RATE)#, weight_decay=5e-4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.LEARNING_RATE)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=CFG.LEARNING_RATE, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-7, verbose=False)\n",
    "# early_stopping = EarlyStopping(patience=10,verbose=False,path='')\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d91fd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb7f3465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[0001/1024] loss: 56.78814, best_epoch: 1, elapsed: 10.36s, total: 10.36s, remaining: 10603.07s\n",
      "*[0002/1024] loss: 53.07925, best_epoch: 2, elapsed: 10.34s, total: 20.85s, remaining: 10563.62s\n",
      "*[0003/1024] loss: 46.55030, best_epoch: 3, elapsed: 10.38s, total: 31.37s, remaining: 10597.42s\n",
      "*[0004/1024] loss: 39.23457, best_epoch: 4, elapsed: 10.37s, total: 41.88s, remaining: 10575.64s\n",
      "*[0005/1024] loss: 34.18843, best_epoch: 5, elapsed: 10.36s, total: 52.39s, remaining: 10560.33s\n",
      "*[0006/1024] loss: 31.96935, best_epoch: 6, elapsed: 10.38s, total: 62.93s, remaining: 10563.18s\n",
      "*[0007/1024] loss: 30.72663, best_epoch: 7, elapsed: 10.39s, total: 73.46s, remaining: 10564.19s\n",
      "*[0008/1024] loss: 29.73492, best_epoch: 8, elapsed: 10.40s, total: 84.00s, remaining: 10564.66s\n",
      "*[0009/1024] loss: 29.25053, best_epoch: 9, elapsed: 10.41s, total: 94.55s, remaining: 10567.86s\n",
      "*[0010/1024] loss: 28.47272, best_epoch: 10, elapsed: 10.40s, total: 105.09s, remaining: 10541.28s\n",
      "*[0011/1024] loss: 27.67727, best_epoch: 11, elapsed: 10.41s, total: 115.64s, remaining: 10548.03s\n",
      "*[0012/1024] loss: 27.20847, best_epoch: 12, elapsed: 10.42s, total: 126.20s, remaining: 10548.21s\n",
      "*[0013/1024] loss: 26.91842, best_epoch: 13, elapsed: 10.47s, total: 136.81s, remaining: 10584.35s\n",
      "*[0014/1024] loss: 26.22153, best_epoch: 14, elapsed: 10.49s, total: 147.46s, remaining: 10590.30s\n",
      " [0015/1024] loss: 26.25330, best_epoch: 14, elapsed: 10.44s, total: 158.04s, remaining: 10534.35s\n",
      "*[0016/1024] loss: 25.42049, best_epoch: 16, elapsed: 10.44s, total: 168.48s, remaining: 10523.09s\n",
      "*[0017/1024] loss: 25.02985, best_epoch: 17, elapsed: 10.44s, total: 179.06s, remaining: 10518.10s\n",
      "*[0018/1024] loss: 24.78433, best_epoch: 18, elapsed: 10.45s, total: 191.33s, remaining: 10508.19s\n",
      "*[0019/1024] loss: 24.70871, best_epoch: 19, elapsed: 10.43s, total: 203.92s, remaining: 10482.99s\n",
      "*[0020/1024] loss: 24.03401, best_epoch: 20, elapsed: 10.43s, total: 215.03s, remaining: 10474.25s\n",
      "*[0021/1024] loss: 23.63862, best_epoch: 21, elapsed: 10.44s, total: 225.61s, remaining: 10473.29s\n",
      "*[0022/1024] loss: 23.36365, best_epoch: 22, elapsed: 10.44s, total: 236.20s, remaining: 10463.24s\n",
      "*[0023/1024] loss: 22.89878, best_epoch: 23, elapsed: 10.45s, total: 246.78s, remaining: 10457.59s\n",
      "*[0024/1024] loss: 22.86361, best_epoch: 24, elapsed: 10.45s, total: 258.80s, remaining: 10445.52s\n",
      "*[0025/1024] loss: 22.70893, best_epoch: 25, elapsed: 10.44s, total: 271.08s, remaining: 10428.65s\n",
      "*[0026/1024] loss: 22.49173, best_epoch: 26, elapsed: 10.44s, total: 282.27s, remaining: 10419.38s\n",
      " [0027/1024] loss: 22.54427, best_epoch: 26, elapsed: 10.36s, total: 292.77s, remaining: 10329.25s\n",
      "*[0028/1024] loss: 22.08322, best_epoch: 28, elapsed: 10.27s, total: 303.04s, remaining: 10228.71s\n",
      "*[0029/1024] loss: 22.07227, best_epoch: 29, elapsed: 10.20s, total: 313.38s, remaining: 10152.56s\n",
      "*[0030/1024] loss: 21.51992, best_epoch: 30, elapsed: 10.23s, total: 323.74s, remaining: 10164.21s\n",
      " [0031/1024] loss: 21.52805, best_epoch: 30, elapsed: 10.14s, total: 334.03s, remaining: 10070.54s\n",
      "*[0032/1024] loss: 21.06548, best_epoch: 32, elapsed: 10.13s, total: 344.15s, remaining: 10045.25s\n",
      " [0033/1024] loss: 21.41485, best_epoch: 32, elapsed: 10.11s, total: 354.41s, remaining: 10023.63s\n",
      " [0034/1024] loss: 21.20499, best_epoch: 32, elapsed: 10.13s, total: 364.54s, remaining: 10031.88s\n",
      "*[0035/1024] loss: 20.66534, best_epoch: 35, elapsed: 10.12s, total: 374.66s, remaining: 10008.39s\n",
      " [0036/1024] loss: 21.09978, best_epoch: 35, elapsed: 10.10s, total: 384.90s, remaining: 9983.73s\n",
      " [0037/1024] loss: 20.66816, best_epoch: 35, elapsed: 10.10s, total: 394.99s, remaining: 9966.02s\n",
      "*[0038/1024] loss: 20.60239, best_epoch: 38, elapsed: 10.10s, total: 405.09s, remaining: 9954.37s\n",
      "*[0039/1024] loss: 20.45060, best_epoch: 39, elapsed: 10.12s, total: 415.35s, remaining: 9965.74s\n",
      " [0040/1024] loss: 20.47154, best_epoch: 39, elapsed: 10.10s, total: 427.23s, remaining: 9935.70s\n",
      "*[0041/1024] loss: 20.23136, best_epoch: 41, elapsed: 10.11s, total: 437.34s, remaining: 9933.97s\n",
      "*[0042/1024] loss: 19.98505, best_epoch: 42, elapsed: 10.11s, total: 449.39s, remaining: 9932.39s\n",
      " [0043/1024] loss: 20.12352, best_epoch: 42, elapsed: 10.12s, total: 460.39s, remaining: 9931.37s\n",
      "*[0044/1024] loss: 19.79690, best_epoch: 44, elapsed: 10.17s, total: 470.57s, remaining: 9971.06s\n",
      " [0045/1024] loss: 19.89503, best_epoch: 44, elapsed: 10.17s, total: 480.88s, remaining: 9956.25s\n",
      "*[0046/1024] loss: 19.70516, best_epoch: 46, elapsed: 10.17s, total: 491.05s, remaining: 9946.53s\n",
      "*[0047/1024] loss: 19.69501, best_epoch: 47, elapsed: 10.27s, total: 502.48s, remaining: 10034.99s\n",
      "*[0048/1024] loss: 19.57628, best_epoch: 48, elapsed: 10.19s, total: 514.70s, remaining: 9946.49s\n",
      " [0049/1024] loss: 19.78676, best_epoch: 48, elapsed: 10.21s, total: 526.28s, remaining: 9954.10s\n",
      "*[0050/1024] loss: 19.28193, best_epoch: 50, elapsed: 10.22s, total: 536.51s, remaining: 9957.08s\n",
      "*[0051/1024] loss: 19.18174, best_epoch: 51, elapsed: 10.25s, total: 546.89s, remaining: 9971.18s\n",
      " [0052/1024] loss: 19.51875, best_epoch: 51, elapsed: 10.28s, total: 557.31s, remaining: 9989.48s\n",
      " [0053/1024] loss: 19.50617, best_epoch: 51, elapsed: 10.29s, total: 567.60s, remaining: 9989.19s\n",
      " [0054/1024] loss: 19.20070, best_epoch: 51, elapsed: 10.34s, total: 577.93s, remaining: 10026.98s\n",
      "*[0055/1024] loss: 18.84716, best_epoch: 55, elapsed: 10.36s, total: 588.30s, remaining: 10041.94s\n",
      "*[0056/1024] loss: 18.47729, best_epoch: 56, elapsed: 10.40s, total: 598.83s, remaining: 10063.92s\n",
      "*[0057/1024] loss: 18.36013, best_epoch: 57, elapsed: 10.41s, total: 609.38s, remaining: 10066.24s\n",
      " [0058/1024] loss: 18.60965, best_epoch: 57, elapsed: 10.46s, total: 619.97s, remaining: 10106.27s\n",
      " [0059/1024] loss: 18.37123, best_epoch: 57, elapsed: 10.47s, total: 630.44s, remaining: 10100.53s\n",
      "*[0060/1024] loss: 18.32047, best_epoch: 60, elapsed: 10.50s, total: 640.94s, remaining: 10121.29s\n",
      "*[0061/1024] loss: 18.30051, best_epoch: 61, elapsed: 10.51s, total: 651.58s, remaining: 10116.80s\n",
      "*[0062/1024] loss: 18.19160, best_epoch: 62, elapsed: 10.53s, total: 662.25s, remaining: 10128.85s\n",
      " [0063/1024] loss: 18.39721, best_epoch: 62, elapsed: 10.56s, total: 672.95s, remaining: 10145.68s\n",
      "*[0064/1024] loss: 18.11992, best_epoch: 64, elapsed: 10.64s, total: 683.59s, remaining: 10212.85s\n",
      " [0065/1024] loss: 18.12348, best_epoch: 64, elapsed: 10.62s, total: 694.34s, remaining: 10181.42s\n",
      "*[0066/1024] loss: 17.89617, best_epoch: 66, elapsed: 10.63s, total: 704.97s, remaining: 10183.25s\n",
      " [0067/1024] loss: 18.08649, best_epoch: 66, elapsed: 10.60s, total: 715.71s, remaining: 10141.90s\n",
      " [0068/1024] loss: 18.16795, best_epoch: 66, elapsed: 10.56s, total: 726.26s, remaining: 10092.23s\n",
      " [0069/1024] loss: 18.27771, best_epoch: 66, elapsed: 10.52s, total: 736.78s, remaining: 10042.16s\n",
      " [0070/1024] loss: 18.13736, best_epoch: 66, elapsed: 10.50s, total: 747.28s, remaining: 10020.24s\n",
      "*[0071/1024] loss: 17.78494, best_epoch: 71, elapsed: 10.48s, total: 757.76s, remaining: 9986.82s\n",
      " [0072/1024] loss: 17.97373, best_epoch: 71, elapsed: 10.48s, total: 768.37s, remaining: 9972.21s\n",
      " [0073/1024] loss: 17.84661, best_epoch: 71, elapsed: 10.39s, total: 778.77s, remaining: 9884.98s\n",
      "*[0074/1024] loss: 17.67718, best_epoch: 74, elapsed: 10.27s, total: 789.04s, remaining: 9759.89s\n",
      " [0075/1024] loss: 17.70511, best_epoch: 74, elapsed: 10.20s, total: 799.39s, remaining: 9683.41s\n",
      "*[0076/1024] loss: 17.58626, best_epoch: 76, elapsed: 10.17s, total: 809.56s, remaining: 9640.87s\n",
      " [0077/1024] loss: 17.61545, best_epoch: 76, elapsed: 10.15s, total: 819.85s, remaining: 9612.85s\n",
      "*[0078/1024] loss: 17.33127, best_epoch: 78, elapsed: 10.12s, total: 829.97s, remaining: 9575.26s\n",
      " [0079/1024] loss: 17.68170, best_epoch: 78, elapsed: 10.11s, total: 840.22s, remaining: 9558.07s\n",
      " [0080/1024] loss: 17.63531, best_epoch: 78, elapsed: 10.13s, total: 850.35s, remaining: 9561.19s\n",
      " [0081/1024] loss: 17.45434, best_epoch: 78, elapsed: 10.19s, total: 860.55s, remaining: 9612.67s\n",
      " [0082/1024] loss: 17.35726, best_epoch: 78, elapsed: 10.11s, total: 870.66s, remaining: 9526.04s\n",
      "*[0083/1024] loss: 17.11312, best_epoch: 83, elapsed: 10.09s, total: 880.75s, remaining: 9498.61s\n",
      " [0084/1024] loss: 17.30327, best_epoch: 83, elapsed: 10.08s, total: 890.98s, remaining: 9479.10s\n",
      " [0085/1024] loss: 17.40909, best_epoch: 83, elapsed: 10.09s, total: 901.08s, remaining: 9476.88s\n",
      " [0086/1024] loss: 17.20342, best_epoch: 83, elapsed: 10.11s, total: 911.18s, remaining: 9482.34s\n",
      "*[0087/1024] loss: 17.04055, best_epoch: 87, elapsed: 10.11s, total: 921.29s, remaining: 9468.76s\n",
      " [0088/1024] loss: 17.26947, best_epoch: 87, elapsed: 10.09s, total: 931.52s, remaining: 9444.94s\n",
      "*[0089/1024] loss: 17.03629, best_epoch: 89, elapsed: 10.09s, total: 941.61s, remaining: 9436.54s\n",
      " [0090/1024] loss: 17.08351, best_epoch: 89, elapsed: 10.10s, total: 951.85s, remaining: 9433.40s\n",
      " [0091/1024] loss: 17.10493, best_epoch: 89, elapsed: 10.11s, total: 961.96s, remaining: 9432.22s\n",
      " [0092/1024] loss: 17.06190, best_epoch: 89, elapsed: 10.09s, total: 972.05s, remaining: 9406.24s\n",
      " [0093/1024] loss: 17.10143, best_epoch: 89, elapsed: 10.11s, total: 982.16s, remaining: 9408.87s\n",
      " [0094/1024] loss: 17.26928, best_epoch: 89, elapsed: 10.10s, total: 992.26s, remaining: 9393.70s\n",
      " [0095/1024] loss: 17.04591, best_epoch: 89, elapsed: 10.09s, total: 1002.35s, remaining: 9376.68s\n",
      " [0096/1024] loss: 17.16074, best_epoch: 89, elapsed: 10.09s, total: 1012.44s, remaining: 9363.47s\n",
      " [0097/1024] loss: 17.10245, best_epoch: 89, elapsed: 10.09s, total: 1022.53s, remaining: 9353.85s\n",
      " [0098/1024] loss: 17.05456, best_epoch: 89, elapsed: 10.09s, total: 1032.62s, remaining: 9340.82s\n",
      " [0099/1024] loss: 17.10039, best_epoch: 89, elapsed: 10.21s, total: 1042.83s, remaining: 9441.68s\n",
      " [0100/1024] loss: 17.11074, best_epoch: 89, elapsed: 10.15s, total: 1052.97s, remaining: 9376.55s\n",
      "*[0101/1024] loss: 16.76893, best_epoch: 101, elapsed: 10.10s, total: 1063.07s, remaining: 9321.03s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./mc/best_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 100\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, epochs, early_stopping, device, scheduler, metric_period, verbose, save_model_path, use_best_model, inverse_transform)\u001b[0m\n\u001b[1;32m     97\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Getting gradients\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Updating parameters\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m validation(model, valid_loader, criterion, device, inverse_transform)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = train(\n",
    "    model, criterion, optimizer, train_loader, None,\n",
    "    CFG.EPOCHS, early_stopping,\n",
    "    device=device, scheduler=scheduler, \n",
    "    metric_period=1, verbose=True,\n",
    "    save_model_path='./mc/best_model.pt',\n",
    "    use_best_model=True,\n",
    "    inverse_transform=inverse_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1fd7d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2534213",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MultiTaskModel(feature_input_size,output_size,hidden_size,dropout_rate)\n",
    "best_model.load_state_dict(torch.load('./mc/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc68771",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_true, tr_pred = predict(best_model,train_loader,device,inverse_transform)\n",
    "va_true, va_pred = predict(best_model,val_loader,device,inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37362721",
   "metadata": {},
   "outputs": [],
   "source": [
    "(MultiRMSELoss()(torch.tensor(tr_true),torch.tensor(tr_pred)),\n",
    " MultiRMSELoss()(torch.tensor(va_true),torch.tensor(va_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_true[:10].round(1), tr_pred[:10].round(1)\n",
    "# va_true[:10].round(1), va_pred[:10].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041fa5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(intercept,slope):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, linestyle='--', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57382e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "fig.add_subplot(121)\n",
    "sns.scatterplot(x=tr_true[:,0],y=tr_pred[:,0])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "fig.add_subplot(122)\n",
    "sns.scatterplot(x=tr_true[:,1],y=tr_pred[:,1])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.suptitle('train',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "fig.add_subplot(121)\n",
    "sns.scatterplot(x=va_true[:,0],y=va_pred[:,0])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "fig.add_subplot(122)\n",
    "sns.scatterplot(x=va_true[:,1],y=va_pred[:,1])\n",
    "abline(0,1)\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('pred')\n",
    "plt.grid()\n",
    "plt.suptitle('validation',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f5062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "88a5da79f9030d36a713e3ceec9ed9a47a216907c035af9944c458137c4e5cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
